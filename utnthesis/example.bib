@online{abdinPhi3TechnicalReport2024,
  title = {Phi-3 {{Technical Report}}: {{A Highly Capable Language Model Locally}} on {{Your Phone}}},
  shorttitle = {Phi-3 {{Technical Report}}},
  author = {Abdin, Marah and Jacobs, Sam Ade and Awan, Ammar Ahmad and Aneja, Jyoti and Awadallah, Ahmed and Awadalla, Hany and Bach, Nguyen and Bahree, Amit and Bakhtiari, Arash and Behl, Harkirat and Benhaim, Alon and Bilenko, Misha and Bjorck, Johan and Bubeck, Sébastien and Cai, Martin and Mendes, Caio César Teodoro and Chen, Weizhu and Chaudhary, Vishrav and Chopra, Parul and Del Giorno, Allie and family=Rosa, given=Gustavo, prefix=de, useprefix=true and Dixon, Matthew and Eldan, Ronen and Iter, Dan and Garg, Amit and Goswami, Abhishek and Gunasekar, Suriya and Haider, Emman and Hao, Junheng and Hewett, Russell J. and Huynh, Jamie and Javaheripi, Mojan and Jin, Xin and Kauffmann, Piero and Karampatziakis, Nikos and Kim, Dongwoo and Khademi, Mahoud and Kurilenko, Lev and Lee, James R. and Lee, Yin Tat and Li, Yuanzhi and Liang, Chen and Liu, Weishung and Lin, Eric and Lin, Zeqi and Madan, Piyush and Mitra, Arindam and Modi, Hardik and Nguyen, Anh and Norick, Brandon and Patra, Barun and Perez-Becker, Daniel and Portet, Thomas and Pryzant, Reid and Qin, Heyang and Radmilac, Marko and Rosset, Corby and Roy, Sambudha and Ruwase, Olatunji and Saarikivi, Olli and Saied, Amin and Salim, Adil and Santacroce, Michael and Shah, Shital and Shang, Ning and Sharma, Hiteshi and Song, Xia and Tanaka, Masahiro and Wang, Xin and Ward, Rachel and Wang, Guanhua and Witte, Philipp and Wyatt, Michael and Xu, Can and Xu, Jiahang and Yadav, Sonali and Yang, Fan and Yang, Ziyi and Yu, Donghan and Zhang, Chengruidong and Zhang, Cyril and Zhang, Jianwen and Zhang, Li Lyna and Zhang, Yi and Zhang, Yue and Zhang, Yunan and Zhou, Xiren},
  date = {2024-04-23},
  eprint = {2404.14219},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2404.14219},
  urldate = {2024-04-24},
  abstract = {We introduce phi-3-mini, a 3.8 billion parameter language model trained on 3.3 trillion tokens, whose overall performance, as measured by both academic benchmarks and internal testing, rivals that of models such as Mixtral 8x7B and GPT-3.5 (e.g., phi-3-mini achieves 69\% on MMLU and 8.38 on MT-bench), despite being small enough to be deployed on a phone. The innovation lies entirely in our dataset for training, a scaled-up version of the one used for phi-2, composed of heavily filtered web data and synthetic data. The model is also further aligned for robustness, safety, and chat format. We also provide some initial parameter-scaling results with a 7B and 14B models trained for 4.8T tokens, called phi-3-small and phi-3-medium, both significantly more capable than phi-3-mini (e.g., respectively 75\% and 78\% on MMLU, and 8.7 and 8.9 on MT-bench).},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/43U3DVYX/Abdin et al. - 2024 - Phi-3 Technical Report A Highly Capable Language .pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/TSEYSCBS/2404.html}
}

@online{abdinPhi3TechnicalReport2024a,
  title = {Phi-3 {{Technical Report}}: {{A Highly Capable Language Model Locally}} on {{Your Phone}}},
  shorttitle = {Phi-3 {{Technical Report}}},
  author = {Abdin, Marah and Jacobs, Sam Ade and Awan, Ammar Ahmad and Aneja, Jyoti and Awadallah, Ahmed and Awadalla, Hany and Bach, Nguyen and Bahree, Amit and Bakhtiari, Arash and Behl, Harkirat and Benhaim, Alon and Bilenko, Misha and Bjorck, Johan and Bubeck, Sébastien and Cai, Martin and Mendes, Caio César Teodoro and Chen, Weizhu and Chaudhary, Vishrav and Chopra, Parul and Del Giorno, Allie and family=Rosa, given=Gustavo, prefix=de, useprefix=true and Dixon, Matthew and Eldan, Ronen and Iter, Dan and Garg, Amit and Goswami, Abhishek and Gunasekar, Suriya and Haider, Emman and Hao, Junheng and Hewett, Russell J. and Huynh, Jamie and Javaheripi, Mojan and Jin, Xin and Kauffmann, Piero and Karampatziakis, Nikos and Kim, Dongwoo and Khademi, Mahoud and Kurilenko, Lev and Lee, James R. and Lee, Yin Tat and Li, Yuanzhi and Liang, Chen and Liu, Weishung and Lin, Eric and Lin, Zeqi and Madan, Piyush and Mitra, Arindam and Modi, Hardik and Nguyen, Anh and Norick, Brandon and Patra, Barun and Perez-Becker, Daniel and Portet, Thomas and Pryzant, Reid and Qin, Heyang and Radmilac, Marko and Rosset, Corby and Roy, Sambudha and Ruwase, Olatunji and Saarikivi, Olli and Saied, Amin and Salim, Adil and Santacroce, Michael and Shah, Shital and Shang, Ning and Sharma, Hiteshi and Song, Xia and Tanaka, Masahiro and Wang, Xin and Ward, Rachel and Wang, Guanhua and Witte, Philipp and Wyatt, Michael and Xu, Can and Xu, Jiahang and Yadav, Sonali and Yang, Fan and Yang, Ziyi and Yu, Donghan and Zhang, Chengruidong and Zhang, Cyril and Zhang, Jianwen and Zhang, Li Lyna and Zhang, Yi and Zhang, Yue and Zhang, Yunan and Zhou, Xiren},
  date = {2024-04-23},
  eprint = {2404.14219},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2404.14219},
  urldate = {2024-04-24},
  abstract = {We introduce phi-3-mini, a 3.8 billion parameter language model trained on 3.3 trillion tokens, whose overall performance, as measured by both academic benchmarks and internal testing, rivals that of models such as Mixtral 8x7B and GPT-3.5 (e.g., phi-3-mini achieves 69\% on MMLU and 8.38 on MT-bench), despite being small enough to be deployed on a phone. The innovation lies entirely in our dataset for training, a scaled-up version of the one used for phi-2, composed of heavily filtered web data and synthetic data. The model is also further aligned for robustness, safety, and chat format. We also provide some initial parameter-scaling results with a 7B and 14B models trained for 4.8T tokens, called phi-3-small and phi-3-medium, both significantly more capable than phi-3-mini (e.g., respectively 75\% and 78\% on MMLU, and 8.7 and 8.9 on MT-bench).},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/HHYRD6CI/Abdin et al. - 2024 - Phi-3 Technical Report A Highly Capable Language .pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/NEAHPCGV/2404.html}
}

@article{agrawalMetaheuristicAlgorithmsFeature2021,
  title = {Metaheuristic {{Algorithms}} on {{Feature Selection}}: {{A Survey}} of {{One Decade}} of {{Research}} (2009-2019)},
  shorttitle = {Metaheuristic {{Algorithms}} on {{Feature Selection}}},
  author = {Agrawal, Prachi and Abutarboush, Hattan F. and Ganesh, Talari and Mohamed, Ali Wagdy},
  date = {2021},
  journaltitle = {IEEE Access},
  shortjournal = {IEEE Access},
  volume = {9},
  pages = {26766--26791},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2021.3056407},
  url = {https://ieeexplore.ieee.org/document/9344597/},
  urldate = {2023-08-26},
  abstract = {Feature selection is a critical and prominent task in machine learning. To reduce the dimension of the feature set while maintaining the accuracy of the performance is the main aim of the feature selection problem. Various methods have been developed to classify the datasets. However, metaheuristic algorithms have achieved great attention in solving numerous optimization problem. Therefore, this paper presents an extensive literature review on solving feature selection problem using metaheuristic algorithms which are developed in the ten years (2009-2019). Further, metaheuristic algorithms have been classified into four categories based on their behaviour. Moreover, a categorical list of more than a hundred metaheuristic algorithms is presented. To solve the feature selection problem, only binary variants of metaheuristic algorithms have been reviewed and corresponding to their categories, a detailed description of them explained. The metaheuristic algorithms in solving feature selection problem are given with their binary classification, name of the classifier used, datasets and the evaluation metrics. After reviewing the papers, challenges and issues are also identified in obtaining the best feature subset using different metaheuristic algorithms. Finally, some research gaps are also highlighted for the researchers who want to pursue their research in developing or modifying metaheuristic algorithms for classification. For an application, a case study is presented in which datasets are adopted from the UCI repository and numerous metaheuristic algorithms are employed to obtain the optimal feature subset.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/4E5WGBCA/Agrawal et al. - 2021 - Metaheuristic Algorithms on Feature Selection A S.pdf}
}

@inproceedings{ahmedImprovingNeuralSequence2018,
  title = {Improving {{Neural Sequence Labelling Using Additional Linguistic Information}}},
  author = {Ahmed, Mahtab and Samee, Muhammad Rifayat and Mercer, Robert},
  date = {2018-12-01},
  pages = {650--657},
  doi = {10.1109/ICMLA.2018.00104},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/N6MPY2BX/Ahmed et al. - 2018 - Improving Neural Sequence Labelling Using Addition.pdf}
}

@online{aiGenerativeOversamplingImbalanced2023,
  title = {Generative {{Oversampling}} for {{Imbalanced Data}} via {{Majority-Guided VAE}}},
  author = {Ai, Qingzhong and Wang, Pengyun and He, Lirong and Wen, Liangjian and Pan, Lujia and Xu, Zenglin},
  date = {2023-02-14},
  eprint = {2302.10910},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2302.10910},
  urldate = {2023-09-15},
  abstract = {Learning with imbalanced data is a challenging problem in deep learning. Over-sampling is a widely used technique to re-balance the sampling distribution of training data. However, most existing over-sampling methods only use intra-class information of minority classes to augment the data but ignore the inter-class relationships with the majority ones, which is prone to overfitting, especially when the imbalance ratio is large. To address this issue, we propose a novel over-sampling model, called Majority-Guided VAE\textasciitilde (MGVAE), which generates new minority samples under the guidance of a majority-based prior. In this way, the newly generated minority samples can inherit the diversity and richness of the majority ones, thus mitigating overfitting in downstream tasks. Furthermore, to prevent model collapse under limited data, we first pre-train MGVAE on sufficient majority samples and then fine-tune based on minority samples with Elastic Weight Consolidation(EWC) regularization. Experimental results on benchmark image datasets and real-world tabular data show that MGVAE achieves competitive improvements over other over-sampling methods in downstream classification tasks, demonstrating the effectiveness of our method.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/8TLIU8VC/Ai et al. - 2023 - Generative Oversampling for Imbalanced Data via Ma.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/SABVVB5M/2302.html}
}

@inproceedings{akbikPooledContextualizedEmbeddings2019,
  title = {Pooled {{Contextualized Embeddings}} for {{Named Entity Recognition}}},
  booktitle = {Proceedings of the 2019 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}, {{Volume}} 1 ({{Long}} and {{Short Papers}})},
  author = {Akbik, Alan and Bergmann, Tanja and Vollgraf, Roland},
  date = {2019-06},
  pages = {724--728},
  publisher = {Association for Computational Linguistics},
  location = {Minneapolis, Minnesota},
  doi = {10.18653/v1/N19-1078},
  url = {https://aclanthology.org/N19-1078},
  urldate = {2022-11-03},
  abstract = {Contextual string embeddings are a recent type of contextualized word embedding that were shown to yield state-of-the-art results when utilized in a range of sequence labeling tasks. They are based on character-level language models which treat text as distributions over characters and are capable of generating embeddings for any string of characters within any textual context. However, such purely character-based approaches struggle to produce meaningful embeddings if a rare string is used in a underspecified context. To address this drawback, we propose a method in which we dynamically aggregate contextualized embeddings of each unique string that we encounter. We then use a pooling operation to distill a ”global” word representation from all contextualized instances. We evaluate these ”pooled contextualized embeddings” on common named entity recognition (NER) tasks such as CoNLL-03 and WNUT and show that our approach significantly improves the state-of-the-art for NER. We make all code and pre-trained models available to the research community for use and reproduction.},
  eventtitle = {{{NAACL-HLT}} 2019},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/2A9SIPQ2/Akbik et al. - 2019 - Pooled Contextualized Embeddings for Named Entity .pdf}
}

@online{akhundovSequenceLabelingPractical2018,
  title = {Sequence {{Labeling}}: {{A Practical Approach}}},
  shorttitle = {Sequence {{Labeling}}},
  author = {Akhundov, Adnan and Trautmann, Dietrich and Groh, Georg},
  date = {2018-08-12},
  eprint = {1808.03926},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1808.03926},
  urldate = {2022-11-19},
  abstract = {We take a practical approach to solving sequence labeling problem assuming unavailability of domain expertise and scarcity of informational and computational resources. To this end, we utilize a universal end-to-end Bi-LSTM-based neural sequence labeling model applicable to a wide range of NLP tasks and languages. The model combines morphological, semantic, and structural cues extracted from data to arrive at informed predictions. The model's performance is evaluated on eight benchmark datasets (covering three tasks: POS-tagging, NER, and Chunking, and four languages: English, German, Dutch, and Spanish). We observe state-of-the-art results on four of them: CoNLL-2012 (English NER), CoNLL-2002 (Dutch NER), GermEval 2014 (German NER), Tiger Corpus (German POS-tagging), and competitive performance on the rest.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/R4T8YURY/Akhundov et al. - 2018 - Sequence Labeling A Practical Approach.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ZIUAM2QV/1808.html}
}

@online{akibaEvolutionaryOptimizationModel2024,
  title = {Evolutionary {{Optimization}} of {{Model Merging Recipes}}},
  author = {Akiba, Takuya and Shing, Makoto and Tang, Yujin and Sun, Qi and Ha, David},
  date = {2024-03-19},
  eprint = {2403.13187},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2403.13187},
  urldate = {2024-03-22},
  abstract = {We present a novel application of evolutionary algorithms to automate the creation of powerful foundation models. While model merging has emerged as a promising approach for LLM development due to its cost-effectiveness, it currently relies on human intuition and domain knowledge, limiting its potential. Here, we propose an evolutionary approach that overcomes this limitation by automatically discovering effective combinations of diverse open-source models, harnessing their collective intelligence without requiring extensive additional training data or compute. Our approach operates in both parameter space and data flow space, allowing for optimization beyond just the weights of the individual models. This approach even facilitates cross-domain merging, generating models like a Japanese LLM with Math reasoning capabilities. Surprisingly, our Japanese Math LLM achieved state-of-the-art performance on a variety of established Japanese LLM benchmarks, even surpassing models with significantly more parameters, despite not being explicitly trained for such tasks. Furthermore, a culturally-aware Japanese VLM generated through our approach demonstrates its effectiveness in describing Japanese culture-specific content, outperforming previous Japanese VLMs. This work not only contributes new state-of-the-art models back to the open-source community, but also introduces a new paradigm for automated model composition, paving the way for exploring alternative, efficient approaches to foundation model development.},
  pubstate = {preprint},
  keywords = {Computer Science - Neural and Evolutionary Computing},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/BPNAYRX6/Akiba et al. - 2024 - Evolutionary Optimization of Model Merging Recipes.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/HMG5QEGF/2403.html}
}

@online{aksitovReSTMeetsReAct2023,
  title = {{{ReST}} Meets {{ReAct}}: {{Self-Improvement}} for {{Multi-Step Reasoning LLM Agent}}},
  shorttitle = {{{ReST}} Meets {{ReAct}}},
  author = {Aksitov, Renat and Miryoosefi, Sobhan and Li, Zonglin and Li, Daliang and Babayan, Sheila and Kopparapu, Kavya and Fisher, Zachary and Guo, Ruiqi and Prakash, Sushant and Srinivasan, Pranesh and Zaheer, Manzil and Yu, Felix and Kumar, Sanjiv},
  date = {2023-12-15},
  eprint = {2312.10003},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2312.10003},
  url = {http://arxiv.org/abs/2312.10003},
  urldate = {2023-12-26},
  abstract = {Answering complex natural language questions often necessitates multi-step reasoning and integrating external information. Several systems have combined knowledge retrieval with a large language model (LLM) to answer such questions. These systems, however, suffer from various failure cases, and we cannot directly train them end-to-end to fix such failures, as interaction with external knowledge is non-differentiable. To address these deficiencies, we define a ReAct-style LLM agent with the ability to reason and act upon external knowledge. We further refine the agent through a ReST-like method that iteratively trains on previous trajectories, employing growing-batch reinforcement learning with AI feedback for continuous self-improvement and self-distillation. Starting from a prompted large model and after just two iterations of the algorithm, we can produce a fine-tuned small model that achieves comparable performance on challenging compositional question-answering benchmarks with two orders of magnitude fewer parameters.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/65SHSJUR/Aksitov et al. - 2023 - ReST meets ReAct Self-Improvement for Multi-Step .pdf}
}

@online{akterIndepthLookGemini2023,
  title = {An {{In-depth Look}} at {{Gemini}}'s {{Language Abilities}}},
  author = {Akter, Syeda Nahida and Yu, Zichun and Muhamed, Aashiq and Ou, Tianyue and Bäuerle, Alex and Cabrera, Ángel Alexander and Dholakia, Krish and Xiong, Chenyan and Neubig, Graham},
  date = {2023-12-18},
  eprint = {2312.11444},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2312.11444},
  url = {http://arxiv.org/abs/2312.11444},
  urldate = {2023-12-26},
  abstract = {The recently released Google Gemini class of models are the first to comprehensively report results that rival the OpenAI GPT series across a wide variety of tasks. In this paper, we do an in-depth exploration of Gemini's language abilities, making two contributions. First, we provide a third-party, objective comparison of the abilities of the OpenAI GPT and Google Gemini models with reproducible code and fully transparent results. Second, we take a closer look at the results, identifying areas where one of the two model classes excels. We perform this analysis over 10 datasets testing a variety of language abilities, including reasoning, answering knowledge-based questions, solving math problems, translating between languages, generating code, and acting as instruction-following agents. From this analysis, we find that Gemini Pro achieves accuracy that is close but slightly inferior to the corresponding GPT 3.5 Turbo on all tasks that we benchmarked. We further provide explanations for some of this under-performance, including failures in mathematical reasoning with many digits, sensitivity to multiple-choice answer ordering, aggressive content filtering, and others. We also identify areas where Gemini demonstrates comparably high performance, including generation into non-English languages, and handling longer and more complex reasoning chains. Code and data for reproduction can be found at https://github.com/neulab/gemini-benchmark},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/QZDA6UN3/Akter et al. - 2023 - An In-depth Look at Gemini's Language Abilities.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/XKADQRML/2312.html}
}

@article{alirezanejadHeuristicFilterFeature2020,
  title = {Heuristic Filter Feature Selection Methods for Medical Datasets},
  author = {Alirezanejad, Mehdi and Enayatifar, Rasul and Motameni, Homayun and Nematzadeh, Hossein},
  date = {2020-03},
  journaltitle = {Genomics},
  shortjournal = {Genomics},
  volume = {112},
  number = {2},
  pages = {1173--1181},
  issn = {08887543},
  doi = {10.1016/j.ygeno.2019.07.002},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0888754319301399},
  urldate = {2023-08-26},
  abstract = {Gene selection is the process of selecting the optimal feature subset in an arbitrary dataset. The significance of gene selection is in high dimensional datasets in which the number of samples and features are low and high respectively. The major goals of gene selection are increasing the accuracy, finding the minimal effective feature subset, and increasing the performance of evaluations. This paper proposed two heuristic methods for gene selection, namely, Xvariance against Mutual Congestion. Xvariance tries to classify labels using internal attributes of features however Mutual Congestion is frequency based. The proposed methods have been conducted on eight binary medical datasets. Results reveal that Xvariance works well with standard datasets, however Mutual Congestion improves the accuracy of high dimensional datasets considerably.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/YV76LHIK/Alirezanejad et al. - 2020 - Heuristic filter feature selection methods for med.pdf}
}

@article{almugrenSurveyHybridFeature2019,
  title = {A {{Survey}} on {{Hybrid Feature Selection Methods}} in {{Microarray Gene Expression Data}} for {{Cancer Classification}}},
  author = {Almugren, Nada and Alshamlan, Hala},
  date = {2019},
  journaltitle = {IEEE Access},
  shortjournal = {IEEE Access},
  volume = {7},
  pages = {78533--78548},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2019.2922987},
  url = {https://ieeexplore.ieee.org/document/8736725/},
  urldate = {2023-08-26},
  abstract = {The emergence of DNA Microarray technology has enabled researchers to analyze the expression level of thousands of genes simultaneously. The Microarray data analysis is the process of finding the most informative genes as well as remove redundant and irrelevant genes. One of the most important applications of the Microarray data analysis is cancer classification. However, the curse of dimensionality and the curse of sparsity make classifying gene expression profiles a challenging task. One of the most effective methods to overcome these challenges is feature (gene) selection. In this paper, we aim to review and compare the most recent hybrid approaches that employ bio-inspired evolutionary methods as the wrapper method.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/77WDLNX6/Almugren y Alshamlan - 2019 - A Survey on Hybrid Feature Selection Methods in Mi.pdf}
}

@online{altuncuImprovingPerformanceAutomatic2022,
  title = {Improving {{Performance}} of {{Automatic Keyword Extraction}} ({{AKE}}) {{Methods Using PoS-Tagging}} and {{Enhanced Semantic-Awareness}}},
  author = {Altuncu, Enes and Nurse, Jason R. C. and Xu, Yang and Guo, Jie and Li, Shujun},
  date = {2022-11-09},
  eprint = {2211.05031},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2211.05031},
  urldate = {2022-11-19},
  abstract = {Automatic keyword extraction (AKE) has gained more importance with the increasing amount of digital textual data that modern computing systems process. It has various applications in information retrieval (IR) and natural language processing (NLP), including text summarisation, topic analysis and document indexing. This paper proposes a simple but effective post-processing-based universal approach to improve the performance of any AKE methods, via an enhanced level of semantic-awareness supported by PoS-tagging. To demonstrate the performance of the proposed approach, we considered word types retrieved from a PoS-tagging step and two representative sources of semantic information -- specialised terms defined in one or more context-dependent thesauri, and named entities in Wikipedia. The above three steps can be simply added to the end of any AKE methods as part of a post-processor, which simply re-evaluate all candidate keywords following some context-specific and semantic-aware criteria. For five state-of-the-art (SOTA) AKE methods, our experimental results with 17 selected datasets showed that the proposed approach improved their performances both consistently (up to 100\textbackslash\% in terms of improved cases) and significantly (between 10.2\textbackslash\% and 53.8\textbackslash\%, with an average of 25.8\textbackslash\%, in terms of F1-score and across all five methods), especially when all the three enhancement steps are used. Our results have profound implications considering the ease to apply our proposed approach to any AKE methods and to further extend it.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/PWCV99JU/Altuncu et al. - 2022 - Improving Performance of Automatic Keyword Extract.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ZD5A5ZZV/2211.html}
}

@article{alvaradoUHMAJAKDEHealthKDChallenge2019,
  title = {{{UH-MAJA-KD}} at {{eHealth-KD Challenge}} 2019},
  author = {Alvarado, Jorge Mederos and Caballero, Ernesto Quevedo and Rodrıguez, Alejandro and Linares, Rocıo Cruz},
  date = {2019},
  pages = {10},
  abstract = {This paper describes the solution presented by the UH-MAJAKD team in IberLEF eHealth-KD 2019: eHealth Knowledge Discovery challenge. Separate strategies were developed to solve substasks A and B, both based on deep learning models using domain-specific word embeddings, and architectures using Bidirectional Long-Short Term Memory (BiLSTM) cells. In the case of Subtask A, Conditional Random Field was used to produce an output in BMEWO-V tag system to extract keyphrases. For Subtask B, two stacked BiLSTM layers are used along with Shortest Dependency Path in-between a pair of keyphrases to determine possible relationships between them.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/GWBSM4XW/Alvarado et al. - 2019 - UH-MAJA-KD at eHealth-KD Challenge 2019.pdf}
}

@article{alvaradoUHMAJAKDEHealthKDChallenge2019a,
  title = {{{UH-MAJA-KD}} at {{eHealth-KD Challenge}} 2019},
  author = {Alvarado, Jorge Mederos and Caballero, Ernesto Quevedo and Rodrıguez, Alejandro and Linares, Rocıo Cruz},
  date = {2019},
  pages = {10},
  abstract = {This paper describes the solution presented by the UH-MAJAKD team in IberLEF eHealth-KD 2019: eHealth Knowledge Discovery challenge. Separate strategies were developed to solve substasks A and B, both based on deep learning models using domain-specific word embeddings, and architectures using Bidirectional Long-Short Term Memory (BiLSTM) cells. In the case of Subtask A, Conditional Random Field was used to produce an output in BMEWO-V tag system to extract keyphrases. For Subtask B, two stacked BiLSTM layers are used along with Shortest Dependency Path in-between a pair of keyphrases to determine possible relationships between them.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ETRDB4P4/Alvarado et al. - 2019 - UH-MAJA-KD at eHealth-KD Challenge 2019.pdf}
}

@article{alzubaidiSurveyDeepLearning2023,
  title = {A Survey on Deep Learning Tools Dealing with Data Scarcity: Definitions, Challenges, Solutions, Tips, and Applications},
  shorttitle = {A Survey on Deep Learning Tools Dealing with Data Scarcity},
  author = {Alzubaidi, Laith and Bai, Jinshuai and Al-Sabaawi, Aiman and Santamaría, Jose and Albahri, A. S. and Al-dabbagh, Bashar Sami Nayyef and Fadhel, Mohammed A. and Manoufali, Mohamed and Zhang, Jinglan and Al-Timemy, Ali H. and Duan, Ye and Abdullah, Amjed and Farhan, Laith and Lu, Yi and Gupta, Ashish and Albu, Felix and Abbosh, Amin and Gu, Yuantong},
  date = {2023-04-14},
  journaltitle = {Journal of Big Data},
  shortjournal = {J Big Data},
  volume = {10},
  number = {1},
  pages = {46},
  issn = {2196-1115},
  doi = {10.1186/s40537-023-00727-2},
  url = {https://journalofbigdata.springeropen.com/articles/10.1186/s40537-023-00727-2},
  urldate = {2023-09-15},
  abstract = {Data scarcity is a major challenge when training deep learning (DL) models. DL demands a large amount of data to achieve exceptional performance. Unfortunately, many applications have small or inadequate data to train DL frameworks. Usually, manual labeling is needed to provide labeled data, which typically involves human annotators with a vast background of knowledge. This annotation process is costly, time-consuming, and error-prone. Usually, every DL framework is fed by a significant amount of labeled data to automatically learn representations. Ultimately, a larger amount of data would generate a better DL model and its performance is also applica‑tion dependent. This issue is the main barrier for many applications dismissing the use of DL. Having sufficient data is the first step toward any successful and trustworthy DL application. This paper presents a holistic survey on state-of-the-art techniques to deal with training DL models to overcome three challenges including small, imbalanced datasets, and lack of generalization. This survey starts by listing the learning techniques. Next, the types of DL architectures are introduced. After that, state-of-the-art solu‑tions to address the issue of lack of training data are listed, such as Transfer Learning (TL), Self-Supervised Learning (SSL), Generative Adversarial Networks (GANs), Model Architecture (MA), Physics-Informed Neural Network (PINN), and Deep Synthetic Minor‑ity Oversampling Technique (DeepSMOTE). Then, these solutions were followed by some related tips about data acquisition needed prior to training purposes, as well as recommendations for ensuring the trustworthiness of the training dataset. The survey ends with a list of applications that suffer from data scarcity, several alternatives are proposed in order to generate more data in each application including Electromag‑netic Imaging (EMI), Civil Structural Health Monitoring, Medical imaging, Meteorol‑ogy, Wireless Communications, Fluid Mechanics, Microelectromechanical system, and Cybersecurity. To the best of the authors’ knowledge, this is the first review that offers a comprehensive overview on strategies to tackle data scarcity in DL.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/I6AZ3U29/Alzubaidi et al. - 2023 - A survey on deep learning tools dealing with data .pdf}
}

@online{AnnotatedTransformer,
  title = {The {{Annotated Transformer}}},
  url = {http://nlp.seas.harvard.edu/annotated-transformer/},
  urldate = {2022-11-02},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/AH9CHVLF/annotated-transformer.html}
}

@article{aranaRedesNeuronalesRecurrentes,
  title = {Redes Neuronales Recurrentes: Análisis de los Modelos Especializados en Datos Secuenciales},
  author = {Arana, Carlos},
  pages = {25},
  langid = {spanish},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/42VDS4UL/Arana - Redes Neuronales Recurrentes Análisis de los Mode.pdf}
}

@online{ArtificialIntelligenceAI2023,
  title = {Artificial {{Intelligence}} ({{AI}}) - {{Judicial Guidance}}},
  date = {2023-12-12},
  url = {https://www.judiciary.uk/guidance-and-resources/artificial-intelligence-ai-judicial-guidance/},
  urldate = {2024-03-04},
  abstract = {This guidance was produced by a cross-jurisdictional judicial group to assist the judiciary, their clerks, and other support staff on the use of AI},
  langid = {american},
  organization = {Courts and Tribunals Judiciary},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/BJR2KKIW/2023 - Artificial Intelligence (AI) - Judicial Guidance.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/G6KVTBNG/artificial-intelligence-ai-judicial-guidance.html}
}

@online{ArtificialIntelligenceBayesian,
  title = {Artificial {{Intelligence}} {$>$} {{Bayesian Nets}} ({{Stanford Encyclopedia}} of {{Philosophy}})},
  url = {https://plato.stanford.edu/entries/artificial-intelligence/bayesian-nets.html},
  urldate = {2023-05-29},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/NUA6P8NH/bayesian-nets.html}
}

@online{asaiSelfRAGLearningRetrieve2023,
  title = {Self-{{RAG}}: {{Learning}} to {{Retrieve}}, {{Generate}}, and {{Critique}} through {{Self-Reflection}}},
  shorttitle = {Self-{{RAG}}},
  author = {Asai, Akari and Wu, Zeqiu and Wang, Yizhong and Sil, Avirup and Hajishirzi, Hannaneh},
  date = {2023-10-17},
  eprint = {2310.11511},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2310.11511},
  url = {http://arxiv.org/abs/2310.11511},
  urldate = {2024-01-10},
  abstract = {Despite their remarkable capabilities, large language models (LLMs) often produce responses containing factual inaccuracies due to their sole reliance on the parametric knowledge they encapsulate. Retrieval-Augmented Generation (RAG), an ad hoc approach that augments LMs with retrieval of relevant knowledge, decreases such issues. However, indiscriminately retrieving and incorporating a fixed number of retrieved passages, regardless of whether retrieval is necessary, or passages are relevant, diminishes LM versatility or can lead to unhelpful response generation. We introduce a new framework called Self-Reflective Retrieval-Augmented Generation (Self-RAG) that enhances an LM's quality and factuality through retrieval and self-reflection. Our framework trains a single arbitrary LM that adaptively retrieves passages on-demand, and generates and reflects on retrieved passages and its own generations using special tokens, called reflection tokens. Generating reflection tokens makes the LM controllable during the inference phase, enabling it to tailor its behavior to diverse task requirements. Experiments show that Self-RAG (7B and 13B parameters) significantly outperforms state-of-the-art LLMs and retrieval-augmented models on a diverse set of tasks. Specifically, Self-RAG outperforms ChatGPT and retrieval-augmented Llama2-chat on Open-domain QA, reasoning and fact verification tasks, and it shows significant gains in improving factuality and citation accuracy for long-form generations relative to these models.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/BXKQFHUN/Asai et al. - 2023 - Self-RAG Learning to Retrieve, Generate, and Crit.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/JL9NE3MB/2310.html}
}

@online{ashokPromptNERPromptingNamed2023,
  title = {{{PromptNER}}: {{Prompting For Named Entity Recognition}}},
  shorttitle = {{{PromptNER}}},
  author = {Ashok, Dhananjay and Lipton, Zachary C.},
  date = {2023-06-20},
  eprint = {2305.15444},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2305.15444},
  urldate = {2024-01-08},
  abstract = {In a surprising turn, Large Language Models (LLMs) together with a growing arsenal of prompt-based heuristics now offer powerful off-the-shelf approaches providing few-shot solutions to myriad classic NLP problems. However, despite promising early results, these LLM-based few-shot methods remain far from the state of the art in Named Entity Recognition (NER), where prevailing methods include learning representations via end-to-end structural understanding and fine-tuning on standard labeled corpora. In this paper, we introduce PromptNER, a new state-of-the-art algorithm for few-Shot and cross-domain NER. To adapt to any new NER task PromptNER requires a set of entity definitions in addition to the standard few-shot examples. Given a sentence, PromptNER prompts an LLM to produce a list of potential entities along with corresponding explanations justifying their compatibility with the provided entity type definitions. Remarkably, PromptNER achieves state-of-the-art performance on few-shot NER, achieving a 4\% (absolute) improvement in F1 score on the ConLL dataset, a 9\% (absolute) improvement on the GENIA dataset, and a 4\% (absolute) improvement on the FewNERD dataset. PromptNER also moves the state of the art on Cross Domain NER, outperforming prior methods (including those not limited to the few-shot setting), setting a new mark on 3/5 CrossNER target domains, with an average F1 gain of 3\%, despite using less than 2\% of the available data.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/FJDUIWSU/Ashok y Lipton - 2023 - PromptNER Prompting For Named Entity Recognition.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/Q5VI5XUV/2305.html}
}

@online{assefaGeneratingSyntheticData2020,
  type = {SSRN Scholarly Paper},
  title = {Generating {{Synthetic Data}} in {{Finance}}: {{Opportunities}}, {{Challenges}} and {{Pitfalls}}},
  shorttitle = {Generating {{Synthetic Data}} in {{Finance}}},
  author = {Assefa, Samuel},
  date = {2020-06-23},
  number = {3634235},
  location = {Rochester, NY},
  doi = {10.2139/ssrn.3634235},
  url = {https://papers.ssrn.com/abstract=3634235},
  urldate = {2023-12-14},
  abstract = {Financial services generate a huge volume of data that is extremely complex and varied. These datasets are often stored in silos within organisations for various reasons, including but not limited to, regulatory requirements and business needs. As a result, data sharing within different lines of business as well as outside of the organisation (e.g. to the research community) is severely limited. It is therefore critical to investigate methods for synthesising financial datasets that follow the same properties of the real data while respecting the need for privacy of the parties involved in a particular dataset.This introductory paper aims to highlight the growing need for effective synthetic data generation in the financial domain. We highlight three main areas of focus for the academic community: 1) Generating realistic synthetic datasets. 2) Measuring the similarities between real and generated datasets 3) Ensuring the generative process satisfies any privacy constraints.Although these challenges are also present in other domains, the extra regulatory and privacy requirements add another dimension of complexity and offer a unique opportunity to study the topic in financial services. Finally, we aim to develop a shared vocabulary and context for generating synthetic financial data using two types of financial datasets as examples.},
  langid = {english},
  pubstate = {preprint},
  keywords = {generative models,privacy},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/DXIACKPM/Assefa - 2020 - Generating Synthetic Data in Finance Opportunitie.pdf}
}

@article{backEvolutionaryComputationComments1997,
  title = {Evolutionary Computation: Comments on the History and Current State},
  shorttitle = {Evolutionary Computation},
  author = {Back, T. and Hammel, U. and Schwefel, H.-P.},
  date = {1997-04},
  journaltitle = {IEEE Transactions on Evolutionary Computation},
  shortjournal = {IEEE Trans. Evol. Computat.},
  volume = {1},
  number = {1},
  pages = {3--17},
  issn = {1089778X},
  doi = {10.1109/4235.585888},
  url = {http://ieeexplore.ieee.org/document/585888/},
  urldate = {2023-09-05},
  abstract = {Evolutionary computation has started to receive significant attention during the last decade, although the origins can be traced back to the late 1950’s. This article surveys the history as well as the current state of this rapidly growing field. We describe the purpose, the general structure, and the working principles of different approaches, including genetic algorithms (GA) [with links to genetic programming (GP) and classifier systems (CS)], evolution strategies (ES), and evolutionary programming (EP) by analysis and comparison of their most important constituents (i.e., representations, variation operators, reproduction, and selection mechanism). Finally, we give a brief overview on the manifold of application domains, although this necessarily must remain incomplete.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/IMFGKT8H/Back et al. - 1997 - Evolutionary computation comments on the history .pdf}
}

@article{badjiLegalEntityExtraction2018,
  title = {Legal Entity Extraction with {{NERSystems}}},
  author = {Badji, Inés},
  date = {2018-06-01},
  abstract = {Named Entity Recognition over texts belonging to the legal domain focuses on cat- egories (legal entities) like references to specific laws, judgments, name of courts or stages in a legal process. Although there is a rich choice of libraries for implementing NER systems, these late ones are not domain specific and do not work well on text pertaining to the Legal domain. Similarly, little focus is given to Spanish since most research is done on the English language. The objective of the work presented in this thesis is the identification of legal entities in Spanish and English texts, with a main focus on informal references to legislative documents found in news, Twitter, contracts or journal articles. The work is framed in the H2020 Lynx project, aimed at creating a Legal Knowledge Graph enabling the provision of compliance-related services. A Rule Based approach can be used to recognize references to norms in Spanish and English documents belonging to the legal domain applied on top of a combination of Natural Language Processing Tools. To recognize the mentions in documents of a less formal nature, a number of vulgar variants for the names of the public acts or judgments is necessary. By querying on Wikidata, DBpedia and BOE a table of synonyms is produced. These resources have been published along with a small annotated data set taken as gold standard.},
  annotation = {MAG ID: 2891239721\\
S2ID: a842960783d6b734eeb18ec6173218d7d34d6bbb}
}

@online{baiConstitutionalAIHarmlessness2022,
  title = {Constitutional {{AI}}: {{Harmlessness}} from {{AI Feedback}}},
  shorttitle = {Constitutional {{AI}}},
  author = {Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and Chen, Carol and Olsson, Catherine and Olah, Christopher and Hernandez, Danny and Drain, Dawn and Ganguli, Deep and Li, Dustin and Tran-Johnson, Eli and Perez, Ethan and Kerr, Jamie and Mueller, Jared and Ladish, Jeffrey and Landau, Joshua and Ndousse, Kamal and Lukosuite, Kamile and Lovitt, Liane and Sellitto, Michael and Elhage, Nelson and Schiefer, Nicholas and Mercado, Noemi and DasSarma, Nova and Lasenby, Robert and Larson, Robin and Ringer, Sam and Johnston, Scott and Kravec, Shauna and Showk, Sheer El and Fort, Stanislav and Lanham, Tamera and Telleen-Lawton, Timothy and Conerly, Tom and Henighan, Tom and Hume, Tristan and Bowman, Samuel R. and Hatfield-Dodds, Zac and Mann, Ben and Amodei, Dario and Joseph, Nicholas and McCandlish, Sam and Brown, Tom and Kaplan, Jared},
  date = {2022-12-15},
  eprint = {2212.08073},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2212.08073},
  url = {http://arxiv.org/abs/2212.08073},
  urldate = {2023-11-16},
  abstract = {As AI systems become more capable, we would like to enlist their help to supervise other AIs. We experiment with methods for training a harmless AI assistant through self-improvement, without any human labels identifying harmful outputs. The only human oversight is provided through a list of rules or principles, and so we refer to the method as 'Constitutional AI'. The process involves both a supervised learning and a reinforcement learning phase. In the supervised phase we sample from an initial model, then generate self-critiques and revisions, and then finetune the original model on revised responses. In the RL phase, we sample from the finetuned model, use a model to evaluate which of the two samples is better, and then train a preference model from this dataset of AI preferences. We then train with RL using the preference model as the reward signal, i.e. we use 'RL from AI Feedback' (RLAIF). As a result we are able to train a harmless but non-evasive AI assistant that engages with harmful queries by explaining its objections to them. Both the SL and RL methods can leverage chain-of-thought style reasoning to improve the human-judged performance and transparency of AI decision making. These methods make it possible to control AI behavior more precisely and with far fewer human labels.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/JX9S6AKX/Bai et al. - 2022 - Constitutional AI Harmlessness from AI Feedback.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/E4CC7UY6/2212.html}
}

@online{balaguerRAGVsFinetuning2024,
  title = {{{RAG}} vs {{Fine-tuning}}: {{Pipelines}}, {{Tradeoffs}}, and a {{Case Study}} on {{Agriculture}}},
  shorttitle = {{{RAG}} vs {{Fine-tuning}}},
  author = {Balaguer, Angels and Benara, Vinamra and Cunha, Renato Luiz de Freitas and Filho, Roberto de M. Estevão and Hendry, Todd and Holstein, Daniel and Marsman, Jennifer and Mecklenburg, Nick and Malvar, Sara and Nunes, Leonardo O. and Padilha, Rafael and Sharp, Morris and Silva, Bruno and Sharma, Swati and Aski, Vijay and Chandra, Ranveer},
  date = {2024-01-17},
  eprint = {2401.08406},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2401.08406},
  url = {http://arxiv.org/abs/2401.08406},
  urldate = {2024-01-28},
  abstract = {There are two common ways in which developers are incorporating proprietary and domain-specific data when building applications of Large Language Models (LLMs): Retrieval-Augmented Generation (RAG) and Fine-Tuning. RAG augments the prompt with the external data, while fine-Tuning incorporates the additional knowledge into the model itself. However, the pros and cons of both approaches are not well understood. In this paper, we propose a pipeline for fine-tuning and RAG, and present the tradeoffs of both for multiple popular LLMs, including Llama2-13B, GPT-3.5, and GPT-4. Our pipeline consists of multiple stages, including extracting information from PDFs, generating questions and answers, using them for fine-tuning, and leveraging GPT-4 for evaluating the results. We propose metrics to assess the performance of different stages of the RAG and fine-Tuning pipeline. We conduct an in-depth study on an agricultural dataset. Agriculture as an industry has not seen much penetration of AI, and we study a potentially disruptive application - what if we could provide location-specific insights to a farmer? Our results show the effectiveness of our dataset generation pipeline in capturing geographic-specific knowledge, and the quantitative and qualitative benefits of RAG and fine-tuning. We see an accuracy increase of over 6 p.p. when fine-tuning the model and this is cumulative with RAG, which increases accuracy by 5 p.p. further. In one particular experiment, we also demonstrate that the fine-tuned model leverages information from across geographies to answer specific questions, increasing answer similarity from 47\% to 72\%. Overall, the results point to how systems built using LLMs can be adapted to respond and incorporate knowledge across a dimension that is critical for a specific industry, paving the way for further applications of LLMs in other industrial domains.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/UPNYAXG2/Balaguer et al. - 2024 - RAG vs Fine-tuning Pipelines, Tradeoffs, and a Ca.pdf}
}

@online{barnettSevenFailurePoints2024,
  title = {Seven {{Failure Points When Engineering}} a {{Retrieval Augmented Generation System}}},
  author = {Barnett, Scott and Kurniawan, Stefanus and Thudumu, Srikanth and Brannelly, Zach and Abdelrazek, Mohamed},
  date = {2024-01-11},
  eprint = {2401.05856},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2401.05856},
  url = {http://arxiv.org/abs/2401.05856},
  urldate = {2024-01-15},
  abstract = {Software engineers are increasingly adding semantic search capabilities to applications using a strategy known as Retrieval Augmented Generation (RAG). A RAG system involves finding documents that semantically match a query and then passing the documents to a large language model (LLM) such as ChatGPT to extract the right answer using an LLM. RAG systems aim to: a) reduce the problem of hallucinated responses from LLMs, b) link sources/references to generated responses, and c) remove the need for annotating documents with meta-data. However, RAG systems suffer from limitations inherent to information retrieval systems and from reliance on LLMs. In this paper, we present an experience report on the failure points of RAG systems from three case studies from separate domains: research, education, and biomedical. We share the lessons learned and present 7 failure points to consider when designing a RAG system. The two key takeaways arising from our work are: 1) validation of a RAG system is only feasible during operation, and 2) the robustness of a RAG system evolves rather than designed in at the start. We conclude with a list of potential research directions on RAG systems for the software engineering community.},
  pubstate = {preprint},
  keywords = {Computer Science - Software Engineering},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/MPXFYKL7/Barnett et al. - 2024 - Seven Failure Points When Engineering a Retrieval .pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/IRT73ZMW/2401.html}
}

@online{barnettSevenFailurePoints2024a,
  title = {Seven {{Failure Points When Engineering}} a {{Retrieval Augmented Generation System}}},
  author = {Barnett, Scott and Kurniawan, Stefanus and Thudumu, Srikanth and Brannelly, Zach and Abdelrazek, Mohamed},
  date = {2024-01-11},
  eprint = {2401.05856},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2401.05856},
  url = {http://arxiv.org/abs/2401.05856},
  urldate = {2024-01-28},
  abstract = {Software engineers are increasingly adding semantic search capabilities to applications using a strategy known as Retrieval Augmented Generation (RAG). A RAG system involves finding documents that semantically match a query and then passing the documents to a large language model (LLM) such as ChatGPT to extract the right answer using an LLM. RAG systems aim to: a) reduce the problem of hallucinated responses from LLMs, b) link sources/references to generated responses, and c) remove the need for annotating documents with meta-data. However, RAG systems suffer from limitations inherent to information retrieval systems and from reliance on LLMs. In this paper, we present an experience report on the failure points of RAG systems from three case studies from separate domains: research, education, and biomedical. We share the lessons learned and present 7 failure points to consider when designing a RAG system. The two key takeaways arising from our work are: 1) validation of a RAG system is only feasible during operation, and 2) the robustness of a RAG system evolves rather than designed in at the start. We conclude with a list of potential research directions on RAG systems for the software engineering community.},
  pubstate = {preprint},
  keywords = {Computer Science - Software Engineering},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/PH84SFES/Barnett et al. - 2024 - Seven Failure Points When Engineering a Retrieval .pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/224N9BB8/2401.html}
}

@online{barriereMayCheckAgain2019,
  title = {May {{I Check Again}}? -- {{A}} Simple but Efficient Way to Generate and Use Contextual Dictionaries for {{Named Entity Recognition}}. {{Application}} to {{French Legal Texts}}},
  shorttitle = {May {{I Check Again}}?},
  author = {Barriere, Valentin and Fouret, Amaury},
  date = {2019-09-08},
  eprint = {1909.03453},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1909.03453},
  urldate = {2022-11-09},
  abstract = {In this paper we present a new method to learn a model robust to typos for a Named Entity Recognition task. Our improvement over existing methods helps the model to take into account the context of the sentence inside a court decision in order to recognize an entity with a typo. We used state-of-the-art models and enriched the last layer of the neural network with high-level information linked with the potential of the word to be a certain type of entity. More precisely, we utilized the similarities between the word and the potential entity candidates in the tagged sentence context. The experiments on a dataset of French court decisions show a reduction of the relative F1-score error of 32\%, upgrading the score obtained with the most competitive fine-tuned state-of-the-art system from 94.85\% to 96.52\%.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/GHSX6JWA/Barriere y Fouret - 2019 - May I Check Again -- A simple but efficient way t.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/IZ75WDIN/1909.html}
}

@article{bateniAIFairnessPrinciples,
  title = {{{AI Fairness}}: From {{Principles}} to {{Practice}}},
  author = {Bateni, Arash and Chan, Matthew C},
  abstract = {This paper summarizes and evaluates various approaches, methods, and techniques for pursuing fairness in artificial intelligence (AI) systems. It examines the merits and shortcomings of these measures and proposes practical guidelines for defining, measuring, and preventing bias in AI. In particular, it cautions against some of the simplistic, yet common, methods for evaluating bias in AI systems, and offers more sophisticated and effective alternatives. The paper also addresses widespread controversies and confusions in the field by providing a common language among different stakeholders of high-impact AI systems. It describes various trade-offs involving AI fairness, and provides practical recommendations for balancing them. It offers techniques for evaluating the costs and benefits of fairness targets, and defines the role of human judgment in setting these targets. This paper provides discussions and guidelines for AI practitioners, organization leaders, and policymakers, as well as various links to additional materials for a more technical audience. Numerous realworld examples are provided to clarify the concepts, challenges, and recommendations from a practical perspective.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/VJLPBHPM/Bateni y Chan - AI Fairness from Principles to Practice.pdf}
}

@online{bechardReducingHallucinationStructured2024,
  title = {Reducing Hallucination in Structured Outputs via {{Retrieval-Augmented Generation}}},
  author = {Béchard, Patrice and Ayala, Orlando Marquez},
  date = {2024-04-11},
  eprint = {2404.08189},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2404.08189},
  url = {http://arxiv.org/abs/2404.08189},
  urldate = {2024-04-18},
  abstract = {A common and fundamental limitation of Generative AI (GenAI) is its propensity to hallucinate. While large language models (LLM) have taken the world by storm, without eliminating or at least reducing hallucinations, real-world GenAI systems may face challenges in user adoption. In the process of deploying an enterprise application that produces workflows based on natural language requirements, we devised a system leveraging Retrieval Augmented Generation (RAG) to greatly improve the quality of the structured output that represents such workflows. Thanks to our implementation of RAG, our proposed system significantly reduces hallucinations in the output and improves the generalization of our LLM in out-of-domain settings. In addition, we show that using a small, well-trained retriever encoder can reduce the size of the accompanying LLM, thereby making deployments of LLM-based systems less resource-intensive.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Information Retrieval,Computer Science - Machine Learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/6BB8SICJ/Béchard y Ayala - 2024 - Reducing hallucination in structured outputs via R.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/9P3L8BHC/2404.html}
}

@article{bellamyAIFairness360,
  title = {{{AI Fairness}} 360: {{An Extensible Toolkit}} for {{Detecting}}, {{Understanding}}, and {{Mitigating Unwanted Algorithmic Bias}}},
  author = {Bellamy, Rachel K E and Dey, Kuntal and Hind, Michael and Hoffman, Samuel C and Houde, Stephanie and Kannan, Kalapriya and Lohia, Pranay and Martino, Jacquelyn and Mehta, Sameep and Mojsilovic, Aleksandra and Nagar, Seema and Ramamurthy, Karthikeyan Natesan and Richards, John and Saha, Diptikalyan and Sattigeri, Prasanna and Singh, Moninder and Varshney, Kush R and Zhang, Yunfeng},
  abstract = {Fairness is an increasingly important concern as machine learning models are used to support decision making in high-stakes applications such as mortgage lending, hiring, and prison sentencing. This paper introduces a new open source Python toolkit for algorithmic fairness, AI Fairness 360 (AIF360), released under an Apache v2.0 license (https://github.com/ibm/aif360). The main objectives of this toolkit are to help facilitate the transition of fairness research algorithms to use in an industrial setting and to provide a common framework for fairness researchers to share and evaluate algorithms.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/G9USLTHW/Bellamy et al. - AI Fairness 360 An Extensible Toolkit for Detecti.pdf}
}

@inproceedings{benderDangersStochasticParrots2021,
  title = {On the {{Dangers}} of {{Stochastic Parrots}}: {{Can Language Models Be Too Big}}? 🦜},
  shorttitle = {On the {{Dangers}} of {{Stochastic Parrots}}},
  booktitle = {Proceedings of the 2021 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Bender, Emily M. and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  date = {2021-03-03},
  pages = {610--623},
  publisher = {ACM},
  location = {Virtual Event Canada},
  doi = {10.1145/3442188.3445922},
  url = {https://dl.acm.org/doi/10.1145/3442188.3445922},
  urldate = {2023-05-29},
  eventtitle = {{{FAccT}} '21: 2021 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  isbn = {978-1-4503-8309-7},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/RKFC6XW3/Bender et al. - 2021 - On the Dangers of Stochastic Parrots Can Language.pdf}
}

@inproceedings{bentleyCOILConstrainedOptimization2022,
  title = {{{COIL}}: {{Constrained Optimization}} in {{Learned Latent Space}}: {{Learning Representations}} for {{Valid Solutions}}},
  shorttitle = {{{COIL}}},
  booktitle = {Proceedings of the {{Genetic}} and {{Evolutionary Computation Conference Companion}}},
  author = {Bentley, Peter J. and Lim, Soo Ling and Gaier, Adam and Tran, Linh},
  date = {2022-07-09},
  eprint = {2202.02163},
  eprinttype = {arxiv},
  eprintclass = {cs},
  pages = {1870--1877},
  doi = {10.1145/3520304.3533993},
  url = {http://arxiv.org/abs/2202.02163},
  urldate = {2023-09-12},
  abstract = {Constrained optimization problems can be difficult because their search spaces have properties not conducive to search, e.g., multimodality, discontinuities, or deception. To address such difficulties, considerable research has been performed on creating novel evolutionary algorithms or specialized genetic operators. However, if the representation that defined the search space could be altered such that it only permitted valid solutions that satisfied the constraints, the task of finding the optimal would be made more feasible without any need for specialized optimization algorithms. We propose Constrained Optimization in Latent Space (COIL), which uses a VAE to generate a learned latent representation from a dataset comprising samples from the valid region of the search space according to a constraint, thus enabling the optimizer to find the objective in the new space defined by the learned representation. Preliminary experiments show promise: compared to an identical GA using a standard representation that cannot meet the constraints or find fit solutions, COIL with its learned latent representation can perfectly satisfy different types of constraints while finding high-fitness solutions.},
  keywords = {G.1.6,I.2.6},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/EAKCGQCE/Bentley et al. - 2022 - COIL Constrained Optimization in Learned Latent S.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/HY6FNWPG/2202.html}
}

@inproceedings{bentleyEvolvingLookingGlass2022,
  title = {Evolving {{Through}} the {{Looking Glass}}: {{Learning Improved Search Spaces}} with {{Variational Autoencoders}}},
  shorttitle = {Evolving {{Through}} the {{Looking Glass}}},
  booktitle = {Parallel {{Problem Solving}} from {{Nature}} – {{PPSN XVII}}},
  author = {Bentley, Peter J. and Lim, Soo Ling and Gaier, Adam and Tran, Linh},
  editor = {Rudolph, Günter and Kononova, Anna V. and Aguirre, Hernán and Kerschke, Pascal and Ochoa, Gabriela and Tušar, Tea},
  date = {2022},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {371--384},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-031-14714-2_26},
  abstract = {Nature has spent billions of years perfecting our genetic representations, making them evolvable and expressive. Generative machine learning offers a shortcut: learn an evolvable latent space with implicit biases towards better solutions. We present SOLVE: Search space Optimization with Latent Variable Evolution, which creates a dataset of solutions that satisfy extra problem criteria or heuristics, generates a new latent search space, and uses a genetic algorithm to search within this new space to find solutions that meet the overall objective. We investigate SOLVE on five sets of criteria designed to detrimentally affect the search space and explain how this approach can be easily extended as the problems become more complex. We show that, compared to an identical GA using a standard representation, SOLVE with its learned latent representation can meet extra criteria and find solutions with distance to optimal up to two orders of magnitude closer. We demonstrate that SOLVE achieves its results by creating better search spaces that focus on desirable regions, reduce discontinuities, and enable improved search by the genetic algorithm.Fig. 1.Search space Optimization with Latent Variable Evolution (SOLVE). An optimizer produces a dataset of random solutions satisfying an extra criterion (e.g., constraint or secondary objective). A variational autoencoder learns this dataset and produces a learned latent representation biased towards the desired region of the search space. This learned representation is then used by a genetic algorithm to find solutions that meet the objective and extra criterion together.},
  isbn = {978-3-031-14714-2},
  langid = {english},
  keywords = {Generative machine learning,Genetic algorithm,Latent variable evolution,Variational autoencoder},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/32DQ5AM5/Bentley et al. - 2022 - Evolving Through the Looking Glass Learning Impro.pdf}
}

@book{bermanFinancialIntelligenceManger,
  title = {Financial {{Intelligence}}: {{A Manger}}'s {{Guide}} to {{Knowing What}} the Numbers Really Mean},
  author = {Berman, Karen},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/UKSR394D/Berman - Financial Intelligence A Manger's Guide to Knowin.pdf}
}

@online{BetterCallGPT,
  title = {Better {{Call GPT}}, {{Comparing Large Language Models Against Lawyers}}},
  url = {https://arxiv.org/html/2401.16212v1},
  urldate = {2024-03-05},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/K7P65A4G/2401.html}
}

@inproceedings{bhiksharajLecture21222021,
  title = {Lecture 21 and 22 on {{Variational Autoencoders}}},
  author = {{Bhiksha Raj}},
  date = {2021},
  publisher = {Carnegie Mellon University Deep Learning},
  url = {https://www.youtube.com/watch?v=LzEywGCT7-A},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/9EAEKYIY/lec21.VAE_1.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/AH9F4XJ8/lec22.VAE_2.pdf}
}

@inproceedings{blaauwModelingTransformingSpeech2016,
  title = {Modeling and {{Transforming Speech Using Variational Autoencoders}}},
  booktitle = {Interspeech 2016},
  author = {Blaauw, Merlijn and Bonada, Jordi},
  date = {2016-09-08},
  pages = {1770--1774},
  publisher = {ISCA},
  doi = {10.21437/Interspeech.2016-1183},
  url = {https://www.isca-speech.org/archive/interspeech_2016/blaauw16_interspeech.html},
  urldate = {2023-09-29},
  abstract = {Latent generative models can learn higher-level underlying factors from complex data in an unsupervised manner. Such models can be used in a wide range of speech processing applications, including synthesis, transformation and classification. While there have been many advances in this field in recent years, the application of the resulting models to speech processing tasks is generally not explicitly considered. In this paper we apply the variational autoencoder (VAE) to the task of modeling frame-wise spectral envelopes. The VAE model has many attractive properties such as continuous latent variables, prior probability over these latent variables, a tractable lower bound on the marginal log likelihood, both generative and recognition models, and end-to-end training of deep models. We consider different aspects of training such models for speech data and compare them to more conventional models such as the Restricted Boltzmann Machine (RBM). While evaluating generative models is difficult, we try to obtain a balanced picture by considering both performance in terms of reconstruction error and when applying the model to a series of modeling and transformation tasks to get an idea of the quality of the learned features.},
  eventtitle = {Interspeech 2016},
  langid = {english},
  keywords = {estado_arte},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/T6GNE2G5/Blaauw y Bonada - 2016 - Modeling and Transforming Speech Using Variational.pdf}
}

@article{blagusSMOTEHighdimensionalClassimbalanced2013,
  title = {{{SMOTE}} for High-Dimensional Class-Imbalanced Data},
  author = {Blagus, Rok and Lusa, Lara},
  date = {2013-12},
  journaltitle = {BMC Bioinformatics},
  shortjournal = {BMC Bioinformatics},
  volume = {14},
  number = {1},
  pages = {106},
  issn = {1471-2105},
  doi = {10.1186/1471-2105-14-106},
  url = {https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-14-106},
  urldate = {2023-08-27},
  abstract = {Background: Classification using class-imbalanced data is biased in favor of the majority class. The bias is even larger for high-dimensional data, where the number of variables greatly exceeds the number of samples. The problem can be attenuated by undersampling or oversampling, which produce class-balanced data. Generally undersampling is helpful, while random oversampling is not. Synthetic Minority Oversampling TEchnique (SMOTE) is a very popular oversampling method that was proposed to improve random oversampling but its behavior on high-dimensional data has not been thoroughly investigated. In this paper we investigate the properties of SMOTE from a theoretical and empirical point of view, using simulated and real high-dimensional data. Results: While in most cases SMOTE seems beneficial with low-dimensional data, it does not attenuate the bias towards the classification in the majority class for most classifiers when data are high-dimensional, and it is less effective than random undersampling. SMOTE is beneficial for k-NN classifiers for high-dimensional data if the number of variables is reduced performing some type of variable selection; we explain why, otherwise, the k-NN classification is biased towards the minority class. Furthermore, we show that on high-dimensional data SMOTE does not change the class-specific mean values while it decreases the data variability and it introduces correlation between samples. We explain how our findings impact the class-prediction for high-dimensional data. Conclusions: In practice, in the high-dimensional setting only k-NN classifiers based on the Euclidean distance seem to benefit substantially from the use of SMOTE, provided that variable selection is performed before using SMOTE; the benefit is larger if more neighbors are used. SMOTE for k-NN without variable selection should not be used, because it strongly biases the classification towards the minority class.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/F5PDJAT7/Blagus y Lusa - 2013 - SMOTE for high-dimensional class-imbalanced data.pdf}
}

@article{bolon-canedoEnsemblesFeatureSelection2019,
  title = {Ensembles for Feature Selection: {{A}} Review and Future Trends},
  shorttitle = {Ensembles for Feature Selection},
  author = {Bolón-Canedo, Verónica and Alonso-Betanzos, Amparo},
  date = {2019-12},
  journaltitle = {Information Fusion},
  shortjournal = {Information Fusion},
  volume = {52},
  pages = {1--12},
  issn = {15662535},
  doi = {10.1016/j.inffus.2018.11.008},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1566253518303440},
  urldate = {2023-08-26},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/CW2WXH6T/Bolón-Canedo y Alonso-Betanzos - 2019 - Ensembles for feature selection A review and futu.pdf}
}

@book{bolon-canedoFeatureSelectionHighDimensional2015,
  title = {Feature {{Selection}} for {{High-Dimensional Data}}},
  author = {Bolón-Canedo, Verónica and Sánchez-Maroño, Noelia and Alonso-Betanzos, Amparo},
  date = {2015},
  series = {Artificial {{Intelligence}}: {{Foundations}}, {{Theory}}, and {{Algorithms}}},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-21858-8},
  url = {https://link.springer.com/10.1007/978-3-319-21858-8},
  urldate = {2023-09-05},
  isbn = {978-3-319-21857-1 978-3-319-21858-8},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/N49FHVGZ/KramerO_2017_Genetic Algorithm Essentials.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/TJGPV7Z6/Bolón-Canedo et al. - 2015 - Feature Selection for High-Dimensional Data.pdf}
}

@article{bommertBenchmarkFilterMethods2020,
  title = {Benchmark for Filter Methods for Feature Selection in High-Dimensional Classification Data},
  author = {Bommert, Andrea and Sun, Xudong and Bischl, Bernd and Rahnenführer, Jörg and Lang, Michel},
  date = {2020-03},
  journaltitle = {Computational Statistics \& Data Analysis},
  shortjournal = {Computational Statistics \& Data Analysis},
  volume = {143},
  pages = {106839},
  issn = {01679473},
  doi = {10.1016/j.csda.2019.106839},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S016794731930194X},
  urldate = {2023-08-26},
  abstract = {Feature selection is one of the most fundamental problems in machine learning and has drawn increasing attention due to high-dimensional data sets emerging from different fields like bioinformatics. For feature selection, filter methods play an important role, since they can be combined with any machine learning model and can heavily reduce run time of machine learning algorithms. The aim of the analyses is to review how different filter methods work, to compare their performance with respect to both run time and predictive accuracy, and to provide guidance for applications. Based on 16 highdimensional classification data sets, 22 filter methods are analyzed with respect to run time and accuracy when combined with a classification method. It is concluded that there is no group of filter methods that always outperforms all other methods, but recommendations on filter methods that perform well on many of the data sets are made. Also, groups of filters that are similar with respect to the order in which they rank the features are found. For the analyses, the R machine learning package mlr is used. It provides a uniform programming API and therefore is a convenient tool to conduct feature selection using filter methods.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/QAUM24C3/Bommert et al. - 2020 - Benchmark for filter methods for feature selection.pdf}
}

@online{bontragerDeepMasterPrintsGeneratingMasterPrints2018,
  title = {{{DeepMasterPrints}}: {{Generating MasterPrints}} for {{Dictionary Attacks}} via {{Latent Variable Evolution}}},
  shorttitle = {{{DeepMasterPrints}}},
  author = {Bontrager, Philip and Roy, Aditi and Togelius, Julian and Memon, Nasir and Ross, Arun},
  date = {2018-10-18},
  eprint = {1705.07386},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1705.07386},
  url = {http://arxiv.org/abs/1705.07386},
  urldate = {2023-09-12},
  abstract = {Recent research has demonstrated the vulnerability of fingerprint recognition systems to dictionary attacks based on MasterPrints. MasterPrints are real or synthetic fingerprints that can fortuitously match with a large number of fingerprints thereby undermining the security afforded by fingerprint systems. Previous work by Roy et al. generated synthetic MasterPrints at the feature-level. In this work we generate complete image-level MasterPrints known as DeepMasterPrints, whose attack accuracy is found to be much superior than that of previous methods. The proposed method, referred to as Latent Variable Evolution, is based on training a Generative Adversarial Network on a set of real fingerprint images. Stochastic search in the form of the Covariance Matrix Adaptation Evolution Strategy is then used to search for latent input variables to the generator network that can maximize the number of impostor matches as assessed by a fingerprint recognizer. Experiments convey the efficacy of the proposed method in generating DeepMasterPrints. The underlying method is likely to have broad applications in fingerprint security as well as fingerprint synthesis.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/3KBD59K8/Bontrager et al. - 2018 - DeepMasterPrints Generating MasterPrints for Dict.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/Q4V9FIY9/1705.html}
}

@inproceedings{boserTrainingAlgorithmOptimal1992,
  title = {A Training Algorithm for Optimal Margin Classifiers},
  booktitle = {Proceedings of the Fifth Annual Workshop on {{Computational}} Learning Theory},
  author = {Boser, Bernhard E. and Guyon, Isabelle M. and Vapnik, Vladimir N.},
  date = {1992-07-01},
  series = {{{COLT}} '92},
  pages = {144--152},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/130385.130401},
  url = {https://dl.acm.org/doi/10.1145/130385.130401},
  urldate = {2023-09-27},
  abstract = {A training algorithm that maximizes the margin between the training patterns and the decision boundary is presented. The technique is applicable to a wide variety of the classification functions, including Perceptrons, polynomials, and Radial Basis Functions. The effective number of parameters is adjusted automatically to match the complexity of the problem. The solution is expressed as a linear combination of supporting patterns. These are the subset of training patterns that are closest to the decision boundary. Bounds on the generalization performance based on the leave-one-out method and the VC-dimension are given. Experimental results on optical character recognition problems demonstrate the good generalization obtained when compared with other learning algorithms.},
  isbn = {978-0-89791-497-0},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/J3E6BGUB/Boser et al. - 1992 - A training algorithm for optimal margin classifier.pdf}
}

@article{bourgonjeDomainspecificEntitySpotting,
  title = {Domain-Specific {{Entity Spotting}}: {{Curation Technologies}} for {{Digital Humanities}} and {{Text Analytics}}},
  author = {Bourgonje, Peter and Moreno-Schneider, Julian and Rehm, Georg},
  pages = {6},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/Z39ZBZ6J/Bourgonje et al. - Domain-speciﬁc Entity Spotting Curation Technolog.pdf}
}

@article{breimanRandomForests2001,
  title = {Random {{Forests}}},
  author = {Breiman, Leo},
  date = {2001-10-01},
  journaltitle = {Machine Learning},
  shortjournal = {Machine Learning},
  volume = {45},
  number = {1},
  pages = {5--32},
  issn = {1573-0565},
  doi = {10.1023/A:1010933404324},
  url = {https://doi.org/10.1023/A:1010933404324},
  urldate = {2023-09-27},
  abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148–156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
  langid = {english},
  keywords = {classification,ensemble,regression},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/RD9MWSCM/Breiman - 2001 - Random Forests.pdf}
}

@incollection{bringsjordArtificialIntelligence2022,
  title = {Artificial {{Intelligence}}},
  booktitle = {The {{Stanford Encyclopedia}} of {{Philosophy}}},
  author = {Bringsjord, Selmer and Govindarajulu, Naveen Sundar},
  editor = {Zalta, Edward N. and Nodelman, Uri},
  date = {2022},
  edition = {Fall 2022},
  publisher = {Metaphysics Research Lab, Stanford University},
  url = {https://plato.stanford.edu/archives/fall2022/entries/artificial-intelligence/},
  urldate = {2023-05-29},
  abstract = {Artificial intelligence (AI) is the field devoted to buildingartificial animals (or at least artificial creatures that – insuitable contexts – appear to be animals) and, formany, artificial persons (or at least artificial creatures that– in suitable contexts – appear to be persons).[1] Such goals immediately ensure that AI is a discipline of considerableinterest to many philosophers, and this has been confirmed (e.g.) bythe energetic attempt, on the part of numerous philosophers, to showthat these goals are in fact un/attainable. On the constructive side,many of the core formalisms and techniques used in AI come out of, andare indeed still much used and refined in, philosophy: first-orderlogic and its extensions; intensional logics suitable for the modelingof doxastic attitudes and deontic reasoning; inductive logic,probability theory, and probabilistic reasoning; practical reasoningand planning, and so on. In light of this, some philosophers conductAI research and development as philosophy.},
  keywords = {artificial intelligence: logic and,causation: probabilistic,Chinese room argument,cognitive science,computability and complexity,computing: modern history of,connectionism,epistemology: Bayesian,frame problem,information technology: and moral values,language of thought hypothesis,learning theory formal,linguistics: computational,mind: computational theory of,reasoning: automated,reasoning: defeasible,statistics philosophy of,Turing test},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ME22LSMK/artificial-intelligence.html}
}

@online{bubeckSparksArtificialGeneral2023,
  title = {Sparks of {{Artificial General Intelligence}}: {{Early}} Experiments with {{GPT-4}}},
  shorttitle = {Sparks of {{Artificial General Intelligence}}},
  author = {Bubeck, Sébastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and Nori, Harsha and Palangi, Hamid and Ribeiro, Marco Tulio and Zhang, Yi},
  date = {2023-04-13},
  eprint = {2303.12712},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2303.12712},
  urldate = {2023-05-17},
  abstract = {Artificial intelligence (AI) researchers have been developing and refining large language models (LLMs) that exhibit remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. The latest model developed by OpenAI, GPT-4, was trained using an unprecedented scale of compute and data. In this paper, we report on our investigation of an early version of GPT-4, when it was still in active development by OpenAI. We contend that (this early version of) GPT-4 is part of a new cohort of LLMs (along with ChatGPT and Google's PaLM for example) that exhibit more general intelligence than previous AI models. We discuss the rising capabilities and implications of these models. We demonstrate that, beyond its mastery of language, GPT-4 can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more, without needing any special prompting. Moreover, in all of these tasks, GPT-4's performance is strikingly close to human-level performance, and often vastly surpasses prior models such as ChatGPT. Given the breadth and depth of GPT-4's capabilities, we believe that it could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system. In our exploration of GPT-4, we put special emphasis on discovering its limitations, and we discuss the challenges ahead for advancing towards deeper and more comprehensive versions of AGI, including the possible need for pursuing a new paradigm that moves beyond next-word prediction. We conclude with reflections on societal influences of the recent technological leap and future research directions.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/I57CTQAU/Bubeck et al. - 2023 - Sparks of Artificial General Intelligence Early e.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/SUQWAWJR/2303.html}
}

@article{bustosENTRENAMIENTOEVALUACIONMODELOS,
  title = {ENTRENAMIENTO Y EVALUACIÓN DE MODELOS PEQUEÑOS DE LENGUAJE NATURAL BASADO EN MÉTODOS DE AUTOATENCIÓN},
  author = {Bustos, Sebastián Alejandro Donoso and Rojas, Jorge Pérez and Mendoza, Iván Sipiran and Gerosa, Daniel Perovich},
  pages = {41},
  langid = {spanish},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/B5ND88VL/Bustos et al. - ENTRENAMIENTO Y EVALUACIÓN DE MODELOS PEQUEÑOS DE .pdf}
}

@online{caliskanDetectingMitigatingBias2021,
  title = {Detecting and Mitigating Bias in Natural Language Processing},
  author = {Caliskan, Aylin},
  date = {2021-05-10T12:47:50+00:00},
  url = {https://www.brookings.edu/research/detecting-and-mitigating-bias-in-natural-language-processing/},
  urldate = {2023-05-30},
  abstract = {Another front in the fight against AI bias.},
  langid = {american},
  organization = {Brookings},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/D3GWYNQ3/detecting-and-mitigating-bias-in-natural-language-processing.html}
}

@inproceedings{cardellinoLowcostHighcoverageLegal2017,
  title = {A {{Low-cost}}, {{High-coverage Legal Named Entity Recognizer}}, {{Classifier}} and {{Linker}}},
  booktitle = {{{ICAIL-2017}} - 16th {{International Conference}} on {{Artificial Intelligence}} and {{Law}}},
  author = {Cardellino, Cristian and Teruel, Milagro and Alonso Alemany, Laura and Villata, Serena},
  date = {2017-06-01},
  pages = {22},
  location = {Londres, United Kingdom},
  url = {https://hal.archives-ouvertes.fr/hal-01541446},
  urldate = {2022-11-03},
  abstract = {In this paper, we try to improve Information Extraction in legal texts by creating a legal Named Entity Recognizer, Classifier and Linker. With this tool, we can identify relevant parts of texts and connect them to a structured knowledge representation, the LKIF ontology. More interestingly, this tool has been developed with relatively little effort, by mapping the LKIF ontology to the YAGO ontology and through it, taking advantage of the mentions of entities in the Wikipedia. These mentions are used as manually annotated examples to train the Named Entity Recognizer, Classifier and Linker. We have evaluated the approach on holdout texts from the Wikipedia and also on a small sample of judgments of the European Court of Human Rights, resulting in a very good performance, i.e., around 80\% F-measure for different levels of granularity. We present an extensive error analysis to direct further developments, and we expect that this approach can be successfully ported to other legal subdomains, represented by different ontologies.},
  keywords = {Legal information extraction,legal ontologies,NER},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/I8UJZXLX/Cardellino et al. - 2017 - A Low-cost, High-coverage Legal Named Entity Recog.pdf}
}

@online{carliniStealingPartProduction2024,
  title = {Stealing {{Part}} of a {{Production Language Model}}},
  author = {Carlini, Nicholas and Paleka, Daniel and Dvijotham, Krishnamurthy Dj and Steinke, Thomas and Hayase, Jonathan and Cooper, A. Feder and Lee, Katherine and Jagielski, Matthew and Nasr, Milad and Conmy, Arthur and Wallace, Eric and Rolnick, David and Tramèr, Florian},
  date = {2024-03-11},
  eprint = {2403.06634},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2403.06634},
  urldate = {2024-03-12},
  abstract = {We introduce the first model-stealing attack that extracts precise, nontrivial information from black-box production language models like OpenAI's ChatGPT or Google's PaLM-2. Specifically, our attack recovers the embedding projection layer (up to symmetries) of a transformer model, given typical API access. For under \textbackslash\$20 USD, our attack extracts the entire projection matrix of OpenAI's Ada and Babbage language models. We thereby confirm, for the first time, that these black-box models have a hidden dimension of 1024 and 2048, respectively. We also recover the exact hidden dimension size of the gpt-3.5-turbo model, and estimate it would cost under \textbackslash\$2,000 in queries to recover the entire projection matrix. We conclude with potential defenses and mitigations, and discuss the implications of possible future work that could extend our attack.},
  pubstate = {preprint},
  keywords = {Computer Science - Cryptography and Security},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/HV3I3M3U/Carlini et al. - 2024 - Stealing Part of a Production Language Model.pdf}
}

@software{castilloDataAugmentationVariational2023,
  title = {Data {{Augmentation}} with {{Variational Autoencoders}} and {{Manifold Sampling}}},
  author = {Castillo, Claudio Sebastián},
  date = {2023-09-29T10:29:37Z},
  origdate = {2023-09-29T10:29:37Z},
  url = {https://github.com/castillosebastian/Data_Augmentation_with_VAE-DALI},
  urldate = {2023-09-29},
  keywords = {va_implementacion}
}

@software{castilloGenProtEA2023,
  title = {{{GenProtEA}}},
  author = {Castillo, Claudio Sebastián},
  date = {2023-09-29T14:38:16Z},
  origdate = {2023-09-29T14:38:16Z},
  url = {https://github.com/castillosebastian/GenProtEA},
  urldate = {2023-09-29},
  abstract = {Framework implementing deep learning generative models for novel enzyme design}
}

@online{chadebecDataAugmentationVariational2021,
  title = {Data {{Augmentation}} with {{Variational Autoencoders}} and {{Manifold Sampling}}},
  author = {Chadebec, Clément and Allassonnière, Stéphanie},
  date = {2021-09-28},
  eprint = {2103.13751},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2103.13751},
  urldate = {2023-09-28},
  abstract = {We propose a new efficient way to sample from a Variational Autoencoder in the challenging low sample size setting. This method reveals particularly well suited to perform data augmentation in such a low data regime and is validated across various standard and real-life data sets. In particular, this scheme allows to greatly improve classification results on the OASIS database where balanced accuracy jumps from 80.7\% for a classifier trained with the raw data to 88.6\% when trained only with the synthetic data generated by our method. Such results were also observed on 3 standard data sets and with other classifiers. A code is available at https://github.com/clementchadebec/Data\_Augmentation\_with\_VAE-DALI.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/FR4HY9MW/Chadebec y Allassonnière - 2021 - Data Augmentation with Variational Autoencoders an.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/FPJK7A9L/2103.html}
}

@online{chadebecDataAugmentationVariational2021a,
  title = {Data {{Augmentation}} with {{Variational Autoencoders}} and {{Manifold Sampling}}},
  author = {Chadebec, Clément and Allassonnière, Stéphanie},
  date = {2021-09-28},
  eprint = {2103.13751},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.2103.13751},
  url = {http://arxiv.org/abs/2103.13751},
  urldate = {2023-09-28},
  abstract = {We propose a new efficient way to sample from a Variational Autoencoder in the challenging low sample size setting. This method reveals particularly well suited to perform data augmentation in such a low data regime and is validated across various standard and real-life data sets. In particular, this scheme allows to greatly improve classification results on the OASIS database where balanced accuracy jumps from 80.7\% for a classifier trained with the raw data to 88.6\% when trained only with the synthetic data generated by our method. Such results were also observed on 3 standard data sets and with other classifiers. A code is available at https://github.com/clementchadebec/Data\_Augmentation\_with\_VAE-DALI.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/9PFVRFPZ/Chadebec y Allassonnière - 2021 - Data Augmentation with Variational Autoencoders an.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/QA5DJLJ7/2103.html}
}

@online{chalkidisNeuralContractElement2021,
  title = {Neural {{Contract Element Extraction Revisited}}: {{Letters}} from {{Sesame Street}}},
  shorttitle = {Neural {{Contract Element Extraction Revisited}}},
  author = {Chalkidis, Ilias and Fergadiotis, Manos and Malakasiotis, Prodromos and Androutsopoulos, Ion},
  date = {2021-02-22},
  eprint = {2101.04355},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2101.04355},
  urldate = {2022-11-08},
  abstract = {We investigate contract element extraction. We show that LSTM-based encoders perform better than dilated CNNs, Transformers, and BERT in this task. We also find that domain-specific WORD2VEC embeddings outperform generic pre-trained GLOVE embeddings. Morpho-syntactic features in the form of POS tag and token shape embeddings, as well as context-aware ELMO embeddings do not improve performance. Several of these observations contradict choices or findings of previous work on contract element extraction and generic sequence labeling tasks, indicating that contract element extraction requires careful task-specific choices. Analyzing the results of (i) plain TRANSFORMER-based and (ii) BERT-based models, we find that in the examined task, where the entities are highly context-sensitive, the lack of recurrency in TRANSFORMERs greatly affects their performance.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/SDJQZ7QA/Chalkidis et al. - 2021 - Neural Contract Element Extraction Revisited Lett.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/2QCA2QK5/2101.html}
}

@book{chayerNuevaGestionJudicial2017,
  title = {Nueva gestión judicial: oralidad en los procesos civiles},
  shorttitle = {Nueva gestión judicial},
  editor = {Chayer, Héctor Mario and Marcet, Juan Pablo},
  date = {2017},
  edition = {2da. edición corregida y aumentada},
  publisher = {SAIJ Ediciones},
  location = {Buenos Aires},
  isbn = {978-987-46271-9-3},
  langid = {spanish},
  pagetotal = {108},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/H8SD7P9M/Chayer y Marcet - 2017 - Nueva gestión judicial oralidad en los procesos c.pdf}
}

@online{chenBGEM3EmbeddingMultiLingual2024,
  title = {{{BGE M3-Embedding}}: {{Multi-Lingual}}, {{Multi-Functionality}}, {{Multi-Granularity Text Embeddings Through Self-Knowledge Distillation}}},
  shorttitle = {{{BGE M3-Embedding}}},
  author = {Chen, Jianlv and Xiao, Shitao and Zhang, Peitian and Luo, Kun and Lian, Defu and Liu, Zheng},
  date = {2024-02-10},
  eprint = {2402.03216},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2402.03216},
  urldate = {2024-04-19},
  abstract = {In this paper, we present a new embedding model, called M3-Embedding, which is distinguished for its versatility in Multi-Linguality, Multi-Functionality, and Multi-Granularity. It can support more than 100 working languages, leading to new state-of-the-art performances on multi-lingual and cross-lingual retrieval tasks. It can simultaneously perform the three common retrieval functionalities of embedding model: dense retrieval, multi-vector retrieval, and sparse retrieval, which provides a unified model foundation for real-world IR applications. It is able to process inputs of different granularities, spanning from short sentences to long documents of up to 8192 tokens. The effective training of M3-Embedding involves the following technical contributions. We propose a novel self-knowledge distillation approach, where the relevance scores from different retrieval functionalities can be integrated as the teacher signal to enhance the training quality. We also optimize the batching strategy, enabling a large batch size and high training throughput to ensure the discriminativeness of embeddings. To the best of our knowledge, M3-Embedding is the first embedding model which realizes such a strong versatility. The model and code will be publicly available at https://github.com/FlagOpen/FlagEmbedding.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/NUS9769B/Chen et al. - 2024 - BGE M3-Embedding Multi-Lingual, Multi-Functionali.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/U6FQE529/2402.html}
}

@inproceedings{chenFinQADatasetNumerical2021,
  title = {{{FinQA}}: {{A Dataset}} of {{Numerical Reasoning}} over {{Financial Data}}},
  shorttitle = {{{FinQA}}},
  booktitle = {Proceedings of the 2021 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Chen, Zhiyu and Chen, Wenhu and Smiley, Charese and Shah, Sameena and Borova, Iana and Langdon, Dylan and Moussa, Reema and Beane, Matt and Huang, Ting-Hao and Routledge, Bryan and Wang, William Yang},
  editor = {Moens, Marie-Francine and Huang, Xuanjing and Specia, Lucia and Yih, Scott Wen-tau},
  date = {2021-11},
  pages = {3697--3711},
  publisher = {Association for Computational Linguistics},
  location = {Online and Punta Cana, Dominican Republic},
  doi = {10.18653/v1/2021.emnlp-main.300},
  url = {https://aclanthology.org/2021.emnlp-main.300},
  urldate = {2023-12-24},
  abstract = {The sheer volume of financial statements makes it difficult for humans to access and analyze a business's financials. Robust numerical reasoning likewise faces unique challenges in this domain. In this work, we focus on answering deep questions over financial data, aiming to automate the analysis of a large corpus of financial documents. In contrast to existing tasks on general domain, the finance domain includes complex numerical reasoning and understanding of heterogeneous representations. To facilitate analytical progress, we propose a new large-scale dataset, FinQA, with Question-Answering pairs over Financial reports, written by financial experts. We also annotate the gold reasoning programs to ensure full explainability. We further introduce baselines and conduct comprehensive experiments in our dataset. The results demonstrate that popular, large, pre-trained models fall far short of expert humans in acquiring finance knowledge and in complex multi-step numerical reasoning on that knowledge. Our dataset – the first of its kind – should therefore enable significant, new community research into complex application domains. The dataset and code are publicly available at https://github.com/czyssrs/FinQA.},
  eventtitle = {{{EMNLP}} 2021},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/JP2GMBQT/Chen et al. - 2021 - FinQA A Dataset of Numerical Reasoning over Finan.pdf}
}

@online{chengAdaptingLargeLanguage2023,
  title = {Adapting {{Large Language Models}} via {{Reading Comprehension}}},
  author = {Cheng, Daixuan and Huang, Shaohan and Wei, Furu},
  date = {2023-09-18},
  eprint = {2309.09530},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2309.09530},
  urldate = {2023-12-04},
  abstract = {We explore how continued pre-training on domain-specific corpora influences large language models, revealing that training on the raw corpora endows the model with domain knowledge, but drastically hurts its prompting ability for question answering. Taken inspiration from human learning via reading comprehension--practice after reading improves the ability to answer questions based on the learned knowledge--we propose a simple method for transforming raw corpora into reading comprehension texts. Each raw text is enriched with a series of tasks related to its content. Our method, highly scalable and applicable to any pre-training corpora, consistently enhances performance across various tasks in three different domains: biomedicine, finance, and law. Notably, our 7B language model achieves competitive performance with domain-specific models of much larger scales, such as BloombergGPT-50B. Furthermore, we demonstrate that domain-specific reading comprehension texts can improve the model's performance even on general benchmarks, showing the potential to develop a general model across even more domains. Our model, code, and data will be available at https://github.com/microsoft/LMOps.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/TBGZ2YVK/Cheng et al. - 2023 - Adapting Large Language Models via Reading Compreh.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/LI6JVLFG/2309.html}
}

@online{chengAdaptingLargeLanguage2023a,
  title = {Adapting {{Large Language Models}} via {{Reading Comprehension}}},
  author = {Cheng, Daixuan and Huang, Shaohan and Wei, Furu},
  date = {2023-09-18},
  eprint = {2309.09530},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2309.09530},
  url = {http://arxiv.org/abs/2309.09530},
  urldate = {2023-12-30},
  abstract = {We explore how continued pre-training on domain-specific corpora influences large language models, revealing that training on the raw corpora endows the model with domain knowledge, but drastically hurts its prompting ability for question answering. Taken inspiration from human learning via reading comprehension--practice after reading improves the ability to answer questions based on the learned knowledge--we propose a simple method for transforming raw corpora into reading comprehension texts. Each raw text is enriched with a series of tasks related to its content. Our method, highly scalable and applicable to any pre-training corpora, consistently enhances performance across various tasks in three different domains: biomedicine, finance, and law. Notably, our 7B language model achieves competitive performance with domain-specific models of much larger scales, such as BloombergGPT-50B. Furthermore, we demonstrate that domain-specific reading comprehension texts can improve the model's performance even on general benchmarks, showing the potential to develop a general model across even more domains. Our model, code, and data will be available at https://github.com/microsoft/LMOps.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/HBQUVQP8/Cheng et al. - 2023 - Adapting Large Language Models via Reading Compreh.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/U63JCTZ9/2309.html}
}

@article{chenMeasuringCurseDimensionality2015,
  title = {Measuring the Curse of Dimensionality and Its Effects on Particle Swarm Optimization and Differential Evolution},
  author = {Chen, Stephen and Montgomery, James and Bolufé-Röhler, Antonio},
  date = {2015-04-01},
  journaltitle = {Applied Intelligence},
  shortjournal = {Applied Intelligence},
  volume = {42},
  doi = {10.1007/s10489-014-0613-2},
  abstract = {The existence of the curse of dimensionality is well known, and its general effects are well acknowledged. However, and perhaps due to this colloquial understanding, specific measurements on the curse of dimensionality and its effects are not as extensive. In continuous domains, the volume of the search space grows exponentially with dimensionality. Conversely, the number of function evaluations budgeted to explore this search space usually grows only linearly. The divergence of these growth rates has important effects on the parameters used in particle swarm optimization and differential evolution as dimensionality increases. New experiments focus on the effects of population size and key changes to the search characteristics of these popular metaheuristics when population size is less than the dimensionality of the search space. Results show how design guidelines developed for low-dimensional implementations can become unsuitable for high-dimensional search spaces.},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/52F39LLW/Chen et al. - 2015 - Measuring the curse of dimensionality and its effe.pdf}
}

@online{chenMTGBenchmarkSuite2022,
  title = {{{MTG}}: {{A Benchmark Suite}} for {{Multilingual Text Generation}}},
  shorttitle = {{{MTG}}},
  author = {Chen, Yiran and Song, Zhenqiao and Wu, Xianze and Wang, Danqing and Xu, Jingjing and Chen, Jiaze and Zhou, Hao and Li, Lei},
  date = {2022-06-09},
  eprint = {2108.07140},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2108.07140},
  urldate = {2022-11-15},
  abstract = {We introduce MTG, a new benchmark suite for training and evaluating multilingual text generation. It is the first-proposed multilingual multiway text generation dataset with the largest human-annotated data (400k). It includes four generation tasks (story generation, question generation, title generation and text summarization) across five languages (English, German, French, Spanish and Chinese). The multiway setup enables testing knowledge transfer capabilities for a model across languages and tasks. Using MTG, we train and analyze several popular multilingual generation models from different aspects. Our benchmark suite fosters model performance enhancement with more human-annotated parallel data. It provides comprehensive evaluations with diverse generation scenarios. Code and data are available at \textbackslash url\{https://github.com/zide05/MTG\}.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/RARVYXIP/Chen et al. - 2022 - MTG A Benchmark Suite for Multilingual Text Gener.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/G65TD8V4/2108.html}
}

@online{chenReConcileRoundTableConference2023,
  title = {{{ReConcile}}: {{Round-Table Conference Improves Reasoning}} via {{Consensus}} among {{Diverse LLMs}}},
  shorttitle = {{{ReConcile}}},
  author = {Chen, Justin Chih-Yao and Saha, Swarnadeep and Bansal, Mohit},
  date = {2023-09-22},
  eprint = {2309.13007},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2309.13007},
  url = {http://arxiv.org/abs/2309.13007},
  urldate = {2023-12-24},
  abstract = {Large Language Models (LLMs) still struggle with complex reasoning tasks. Motivated by the society of minds (Minsky, 1988), we propose ReConcile, a multi-model multi-agent framework designed as a round table conference among diverse LLM agents to foster diverse thoughts and discussion for improved consensus. ReConcile enhances the reasoning capabilities of LLMs by holding multiple rounds of discussion, learning to convince other agents to improve their answers, and employing a confidence-weighted voting mechanism. In each round, ReConcile initiates discussion between agents via a 'discussion prompt' that consists of (a) grouped answers and explanations generated by each agent in the previous round, (b) their uncertainties, and (c) demonstrations of answer-rectifying human explanations, used for convincing other agents. This discussion prompt enables each agent to revise their responses in light of insights from other agents. Once a consensus is reached and the discussion ends, ReConcile determines the final answer by leveraging the confidence of each agent in a weighted voting scheme. We implement ReConcile with ChatGPT, Bard, and Claude2 as the three agents. Our experimental results on various benchmarks demonstrate that ReConcile significantly enhances the reasoning performance of the agents (both individually and as a team), surpassing prior single-agent and multi-agent baselines by 7.7\% and also outperforming GPT-4 on some of these datasets. We also experiment with GPT-4 itself as one of the agents in ReConcile and demonstrate that its initial performance also improves by absolute 10.0\% through discussion and feedback from other agents. Finally, we also analyze the accuracy after every round and observe that ReConcile achieves better and faster consensus between agents, compared to a multi-agent debate baseline. Our code is available at: https://github.com/dinobby/ReConcile},
  pubstate = {preprint},
  keywords = {strategies_LLMs-roundtable_deliberation},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/AMN8GPLV/Chen et al. - 2023 - ReConcile Round-Table Conference Improves Reasoni.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ER8ZF9ZU/2309.html}
}

@article{chenSelectingCriticalFeatures2020,
  title = {Selecting Critical Features for Data Classification Based on Machine Learning Methods},
  author = {Chen, Rung-Ching and Dewi, Christine and Huang, Su-Wen and Caraka, Rezzy Eko},
  date = {2020-12},
  journaltitle = {Journal of Big Data},
  shortjournal = {J Big Data},
  volume = {7},
  number = {1},
  pages = {52},
  issn = {2196-1115},
  doi = {10.1186/s40537-020-00327-4},
  url = {https://journalofbigdata.springeropen.com/articles/10.1186/s40537-020-00327-4},
  urldate = {2023-08-26},
  abstract = {Feature selection becomes prominent, especially in the data sets with many variables and features. It will eliminate unimportant variables and improve the accuracy as well as the performance of classification. Random Forest has emerged as a quite useful algorithm that can handle the feature selection issue even with a higher number of variables. In this paper, we use three popular datasets with a higher number of vari‑ables (Bank Marketing, Car Evaluation Database, Human Activity Recognition Using Smartphones) to conduct the experiment. There are four main reasons why feature selection is essential. First, to simplify the model by reducing the number of param‑eters, next to decrease the training time, to reduce overfilling by enhancing generali‑zation, and to avoid the curse of dimensionality. Besides, we evaluate and compare each accuracy and performance of the classification model, such as Random Forest (RF), Support Vector Machines (SVM), K-Nearest Neighbors (KNN), and Linear Discrimi‑nant Analysis (LDA). The highest accuracy of the model is the best classifier. Practically, this paper adopts Random Forest to select the important feature in classification. Our experiments clearly show the comparative study of the RF algorithm from different perspectives. Furthermore, we compare the result of the dataset with and without essential features selection by RF methods varImp(), Boruta, and Recursive Feature Elimination (RFE) to get the best percentage accuracy and kappa. Experimental results demonstrate that Random Forest achieves a better performance in all experiment groups.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/U5EJPG8W/Chen et al. - 2020 - Selecting critical features for data classificatio.pdf}
}

@online{cheongAmNotLawyer2024,
  title = {({{A}}){{I Am Not}} a {{Lawyer}}, {{But}}...: {{Engaging Legal Experts}} towards {{Responsible LLM Policies}} for {{Legal Advice}}},
  shorttitle = {({{A}}){{I Am Not}} a {{Lawyer}}, {{But}}...},
  author = {Cheong, Inyoung and Xia, King and Feng, K. J. Kevin and Chen, Quan Ze and Zhang, Amy X.},
  date = {2024-02-02},
  eprint = {2402.01864},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2402.01864},
  urldate = {2024-04-22},
  abstract = {The rapid proliferation of large language models (LLMs) as general purpose chatbots available to the public raises hopes around expanding access to professional guidance in law, medicine, and finance, while triggering concerns about public reliance on LLMs for high-stakes circumstances. Prior research has speculated on high-level ethical considerations but lacks concrete criteria determining when and why LLM chatbots should or should not provide professional assistance. Through examining the legal domain, we contribute a structured expert analysis to uncover nuanced policy considerations around using LLMs for professional advice, using methods inspired by case-based reasoning. We convened workshops with 20 legal experts and elicited dimensions on appropriate AI assistance for sample user queries (``cases''). We categorized our expert dimensions into: (1) user attributes, (2) query characteristics, (3) AI capabilities, and (4) impacts. Beyond known issues like hallucinations, experts revealed novel legal problems, including that users' conversations with LLMs are not protected by attorney-client confidentiality or bound to professional ethics that guard against conflicted counsel or poor quality advice. This accountability deficit led participants to advocate for AI systems to help users polish their legal questions and relevant facts, rather than recommend specific actions. More generally, we highlight the potential of case-based expert deliberation as a method of responsibly translating professional integrity and domain knowledge into design requirements to inform appropriate AI behavior when generating advice in professional domains.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/93FQL8IU/Cheong et al. - 2024 - (A)I Am Not a Lawyer, But... Engaging Legal Exper.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/KGFKSX9Z/2402.html}
}

@online{chiuCreationEvaluationPretertiary2021,
  title = {Creation and {{Evaluation}} of a {{Pre-tertiary Artificial Intelligence}} ({{AI}}) {{Curriculum}}},
  author = {Chiu, Thomas K. F. and Meng, Helen and Chai, Ching-Sing and King, Irwin and Wong, Savio and Yam, Yeung},
  date = {2021-01-19},
  eprint = {2101.07570},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2101.07570},
  url = {http://arxiv.org/abs/2101.07570},
  urldate = {2023-05-30},
  abstract = {Contributions: The Chinese University of Hong Kong (CUHK)-Jockey Club AI for the Future Project (AI4Future) co-created an AI curriculum for pre-tertiary education and evaluated its efficacy. While AI is conventionally taught in tertiary level education, our co-creation process successfully developed the curriculum that has been used in secondary school teaching in Hong Kong and received positive feedback. Background: AI4Future is a cross-sector project that engages five major partners - CUHK Faculty of Engineering and Faculty of Education, Hong Kong secondary schools, the government and the AI industry. A team of 14 professors with expertise in engineering and education collaborated with 17 principals and teachers from 6 secondary schools to co-create the curriculum. This team formation bridges the gap between researchers in engineering and education, together with practitioners in education context. Research Questions: What are the main features of the curriculum content developed through the co-creation process? Would the curriculum significantly improve the students perceived competence in, as well as attitude and motivation towards AI? What are the teachers perceptions of the co-creation process that aims to accommodate and foster teacher autonomy? Methodology: This study adopted a mix of quantitative and qualitative methods and involved 335 student participants. Findings: 1) two main features of learning resources, 2) the students perceived greater competence, and developed more positive attitude to learn AI, and 3) the co-creation process generated a variety of resources which enhanced the teachers knowledge in AI, as well as fostered teachers autonomy in bringing the subject matter into their classrooms.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/7UTBXUD4/Chiu et al. - 2021 - Creation and Evaluation of a Pre-tertiary Artifici.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/MKPKQ9ZC/2101.html}
}

@online{choiConversationalFinancialInformation2023,
  title = {Conversational {{Financial Information Retrieval Model}} ({{ConFIRM}})},
  author = {Choi, Stephen and Gazeley, William and Wong, Siu Ho and Li, Tingting},
  date = {2023-11-10},
  eprint = {2310.13001},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2310.13001},
  url = {http://arxiv.org/abs/2310.13001},
  urldate = {2023-12-24},
  abstract = {With the exponential growth in large language models (LLMs), leveraging their emergent properties for specialized domains like finance merits exploration. However, regulated fields such as finance pose unique constraints, requiring domain-optimized frameworks. We present ConFIRM, an LLM-based conversational financial information retrieval model tailored for query intent classification and knowledge base labeling. ConFIRM comprises two modules: 1) a method to synthesize finance domain-specific question-answer pairs, and 2) evaluation of parameter efficient fine-tuning approaches for the query classification task. We generate a dataset of over 4000 samples, assessing accuracy on a separate test set. ConFIRM achieved over 90\% accuracy, essential for regulatory compliance. ConFIRM provides a data-efficient solution to extract precise query intent for financial dialog systems.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/BIZGIZJV/Choi et al. - 2023 - Conversational Financial Information Retrieval Mod.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/WPICRZ66/2310.html}
}

@online{chowdheryPaLMScalingLanguage2022,
  title = {{{PaLM}}: {{Scaling Language Modeling}} with {{Pathways}}},
  shorttitle = {{{PaLM}}},
  author = {Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and Schuh, Parker and Shi, Kensen and Tsvyashchenko, Sasha and Maynez, Joshua and Rao, Abhishek and Barnes, Parker and Tay, Yi and Shazeer, Noam and Prabhakaran, Vinodkumar and Reif, Emily and Du, Nan and Hutchinson, Ben and Pope, Reiner and Bradbury, James and Austin, Jacob and Isard, Michael and Gur-Ari, Guy and Yin, Pengcheng and Duke, Toju and Levskaya, Anselm and Ghemawat, Sanjay and Dev, Sunipa and Michalewski, Henryk and Garcia, Xavier and Misra, Vedant and Robinson, Kevin and Fedus, Liam and Zhou, Denny and Ippolito, Daphne and Luan, David and Lim, Hyeontaek and Zoph, Barret and Spiridonov, Alexander and Sepassi, Ryan and Dohan, David and Agrawal, Shivani and Omernick, Mark and Dai, Andrew M. and Pillai, Thanumalayan Sankaranarayana and Pellat, Marie and Lewkowycz, Aitor and Moreira, Erica and Child, Rewon and Polozov, Oleksandr and Lee, Katherine and Zhou, Zongwei and Wang, Xuezhi and Saeta, Brennan and Diaz, Mark and Firat, Orhan and Catasta, Michele and Wei, Jason and Meier-Hellstern, Kathy and Eck, Douglas and Dean, Jeff and Petrov, Slav and Fiedel, Noah},
  date = {2022-10-05},
  eprint = {2204.02311},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2204.02311},
  urldate = {2023-02-18},
  abstract = {Large language models have been shown to achieve remarkable performance across a variety of natural language tasks using few-shot learning, which drastically reduces the number of task-specific training examples needed to adapt the model to a particular application. To further our understanding of the impact of scale on few-shot learning, we trained a 540-billion parameter, densely activated, Transformer language model, which we call Pathways Language Model PaLM. We trained PaLM on 6144 TPU v4 chips using Pathways, a new ML system which enables highly efficient training across multiple TPU Pods. We demonstrate continued benefits of scaling by achieving state-of-the-art few-shot learning results on hundreds of language understanding and generation benchmarks. On a number of these tasks, PaLM 540B achieves breakthrough performance, outperforming the finetuned state-of-the-art on a suite of multi-step reasoning tasks, and outperforming average human performance on the recently released BIG-bench benchmark. A significant number of BIG-bench tasks showed discontinuous improvements from model scale, meaning that performance steeply increased as we scaled to our largest model. PaLM also has strong capabilities in multilingual tasks and source code generation, which we demonstrate on a wide array of benchmarks. We additionally provide a comprehensive analysis on bias and toxicity, and study the extent of training data memorization with respect to model scale. Finally, we discuss the ethical considerations related to large language models and discuss potential mitigation strategies.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/YS2STYQR/Chowdhery et al. - 2022 - PaLM Scaling Language Modeling with Pathways.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/AQTKNW2N/2204.html}
}

@article{CLASESPALABRASCATEGORIAS,
  title = {CLASES DE PALABRAS CATEGORÍAS GRAMATICALES},
  pages = {12},
  langid = {spanish},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/WGW2NTDF/CLASES DE PALABRAS CATEGORÍAS GRAMATICALES.pdf}
}

@online{cleiGenerativeAdversarialNeuroevolution2023,
  title = {Generative {{Adversarial Neuroevolution}} for {{Control Behaviour Imitation}}},
  author = {Clei, Maximilien Le and Bellec, Pierre},
  date = {2023-04-03},
  eprint = {2304.12432},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2304.12432},
  urldate = {2023-06-27},
  abstract = {There is a recent surge in interest for imitation learning, with large human video-game and robotic manipulation datasets being used to train agents on very complex tasks. While deep neuroevolution has recently been shown to match the performance of gradient-based techniques on various reinforcement learning problems, the application of deep neuroevolution techniques to imitation learning remains relatively unexplored. In this work, we propose to explore whether deep neuroevolution can be used for behaviour imitation on popular simulation environments. We introduce a simple co-evolutionary adversarial generation framework, and evaluate its capabilities by evolving standard deep recurrent networks to imitate state-of-the-art pre-trained agents on 8 OpenAI Gym state-based control tasks. Across all tasks, we find the final elite actor agents capable of achieving scores as high as those obtained by the pre-trained agents, all the while closely following their score trajectories. Our results suggest that neuroevolution could be a valuable addition to deep learning techniques to produce accurate emulation of behavioural agents. We believe that the generality and simplicity of our approach opens avenues for imitating increasingly complex behaviours in increasingly complex settings, e.g. human behaviour in real-world settings. We provide our source code, model checkpoints and results at github.com/MaximilienLC/gane.},
  pubstate = {preprint}
}

@article{collobertNaturalLanguageProcessing,
  title = {Natural {{Language Processing}} ({{Almost}}) from {{Scratch}}},
  author = {Collobert, Ronan and Weston, Jason and Bottou, Leon and Karlen, Michael and Kavukcuoglu, Koray and Kuksa, Pavel},
  journaltitle = {NATURAL LANGUAGE PROCESSING},
  pages = {45},
  abstract = {We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/M77ETUZA/Collobert et al. - Natural Language Processing (Almost) from Scratch.pdf}
}

@online{collobertNaturalLanguageProcessing2011,
  title = {Natural {{Language Processing}} (Almost) from {{Scratch}}},
  author = {Collobert, Ronan and Weston, Jason and Bottou, Leon and Karlen, Michael and Kavukcuoglu, Koray and Kuksa, Pavel},
  date = {2011-03-02},
  eprint = {1103.0398},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1103.0398},
  url = {http://arxiv.org/abs/1103.0398},
  urldate = {2022-11-21},
  abstract = {We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/DZSI4XEU/Collobert et al. - 2011 - Natural Language Processing (almost) from Scratch.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/WG5YHQQH/1103.html}
}

@online{colomboSaulLM7BPioneeringLarge2024,
  title = {{{SaulLM-7B}}: {{A}} Pioneering {{Large Language Model}} for {{Law}}},
  shorttitle = {{{SaulLM-7B}}},
  author = {Colombo, Pierre and Pires, Telmo Pessoa and Boudiaf, Malik and Culver, Dominic and Melo, Rui and Corro, Caio and Martins, Andre F. T. and Esposito, Fabrizio and Raposo, Vera Lúcia and Morgado, Sofia and Desa, Michael},
  date = {2024-03-06},
  eprint = {2403.03883},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.03883},
  url = {http://arxiv.org/abs/2403.03883},
  urldate = {2024-03-27},
  abstract = {In this paper, we introduce SaulLM-7B, a large language model (LLM) tailored for the legal domain. With 7 billion parameters, SaulLM-7B is the first LLM designed explicitly for legal text comprehension and generation. Leveraging the Mistral 7B architecture as its foundation, SaulLM-7B is trained on an English legal corpus of over 30 billion tokens. SaulLM-7B exhibits state-of-the-art proficiency in understanding and processing legal documents. Additionally, we present a novel instructional fine-tuning method that leverages legal datasets to further enhance SaulLM-7B's performance in legal tasks. SaulLM-7B is released under the MIT License.},
  pubstate = {preprint},
  version = {1},
  keywords = {Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/P2CQSCZX/Colombo et al. - 2024 - SaulLM-7B A pioneering Large Language Model for L.pdf}
}

@online{cooperReport1stWorkshop2023,
  title = {Report of the 1st {{Workshop}} on {{Generative AI}} and {{Law}}},
  author = {Cooper, A. Feder and Lee, Katherine and Grimmelmann, James and Ippolito, Daphne and Callison-Burch, Christopher and Choquette-Choo, Christopher A. and Mireshghallah, Niloofar and Brundage, Miles and Mimno, David and Choksi, Madiha Zahrah and Balkin, Jack M. and Carlini, Nicholas and De Sa, Christopher and Frankle, Jonathan and Ganguli, Deep and Gipson, Bryant and Guadamuz, Andres and Harris, Swee Leng and Jacobs, Abigail Z. and Joh, Elizabeth and Kamath, Gautam and Lemley, Mark and Matthews, Cass and McLeavey, Christine and McSherry, Corynne and Nasr, Milad and Ohm, Paul and Roberts, Adam and Rubin, Tom and Samuelson, Pamela and Schubert, Ludwig and Vaccaro, Kristen and Villa, Luis and Wu, Felix and Zeide, Elana},
  date = {2023-12-02},
  eprint = {2311.06477},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2311.06477},
  url = {http://arxiv.org/abs/2311.06477},
  urldate = {2024-02-15},
  abstract = {This report presents the takeaways of the inaugural Workshop on Generative AI and Law (GenLaw), held in July 2023. A cross-disciplinary group of practitioners and scholars from computer science and law convened to discuss the technical, doctrinal, and policy challenges presented by law for Generative AI, and by Generative AI for law, with an emphasis on U.S. law in particular. We begin the report with a high-level statement about why Generative AI is both immensely significant and immensely challenging for law. To meet these challenges, we conclude that there is an essential need for 1) a shared knowledge base that provides a common conceptual language for experts across disciplines; 2) clarification of the distinctive technical capabilities of generative-AI systems, as compared and contrasted to other computer and AI systems; 3) a logical taxonomy of the legal issues these systems raise; and, 4) a concrete research agenda to promote collaboration and knowledge-sharing on emerging issues at the intersection of Generative AI and law. In this report, we synthesize the key takeaways from the GenLaw workshop that begin to address these needs. All of the listed authors contributed to the workshop upon which this report is based, but they and their organizations do not necessarily endorse all of the specific claims in this report.},
  pubstate = {preprint},
  keywords = {Computer Science - Computers and Society},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/CGWIU68G/Cooper et al. - 2023 - Report of the 1st Workshop on Generative AI and La.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/LK58DKYJ/2311.html}
}

@online{CopilotStudioSamplesPlaybookPVA,
  title = {{{CopilotStudioSamples}}/{{Playbook}}/{{PVA Bot Building Handbook}}.Pdf at Master · Microsoft/{{CopilotStudioSamples}}},
  url = {https://github.com/microsoft/CopilotStudioSamples/blob/master/Playbook/PVA%20Bot%20Building%20Handbook.pdf},
  urldate = {2024-01-18},
  abstract = {Contribute to microsoft/CopilotStudioSamples development by creating an account on GitHub.},
  langid = {english},
  organization = {GitHub},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ULW5YJMI/PVA Bot Building Handbook.html}
}

@online{cuconasuPowerNoiseRedefining2024,
  title = {The {{Power}} of {{Noise}}: {{Redefining Retrieval}} for {{RAG Systems}}},
  shorttitle = {The {{Power}} of {{Noise}}},
  author = {Cuconasu, Florin and Trappolini, Giovanni and Siciliano, Federico and Filice, Simone and Campagnano, Cesare and Maarek, Yoelle and Tonellotto, Nicola and Silvestri, Fabrizio},
  date = {2024-02-12},
  eprint = {2401.14887},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2401.14887},
  url = {http://arxiv.org/abs/2401.14887},
  urldate = {2024-02-15},
  abstract = {Retrieval-Augmented Generation (RAG) systems represent a significant advancement over traditional Large Language Models (LLMs). RAG systems enhance their generation ability by incorporating external data retrieved through an Information Retrieval (IR) phase, overcoming the limitations of standard LLMs, which are restricted to their pre-trained knowledge and limited context window. Most research in this area has predominantly concentrated on the generative aspect of LLMs within RAG systems. Our study fills this gap by thoroughly and critically analyzing the influence of IR components on RAG systems. This paper analyzes which characteristics a retriever should possess for an effective RAG's prompt formulation, focusing on the type of documents that should be retrieved. We evaluate various elements, such as the relevance of the documents to the prompt, their position, and the number included in the context. Our findings reveal, among other insights, that including irrelevant documents can unexpectedly enhance performance by more than 30\% in accuracy, contradicting our initial assumption of diminished quality. These results underscore the need for developing specialized strategies to integrate retrieval with language generation models, thereby laying the groundwork for future research in this field.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Information Retrieval},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/24TDWPUP/Cuconasu et al. - 2024 - The Power of Noise Redefining Retrieval for RAG S.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/WW6NV688/2401.html}
}

@online{cuiChatLawOpenSourceLegal2023,
  title = {{{ChatLaw}}: {{Open-Source Legal Large Language Model}} with {{Integrated External Knowledge Bases}}},
  shorttitle = {{{ChatLaw}}},
  author = {Cui, Jiaxi and Li, Zongjian and Yan, Yang and Chen, Bohua and Yuan, Li},
  date = {2023-06-28},
  eprint = {2306.16092},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2306.16092},
  urldate = {2024-04-22},
  abstract = {Large Language Models (LLMs) have shown the potential to revolutionize natural language processing tasks in various domains, sparking great interest in vertical-specific large models. However, unlike proprietary models such as BloombergGPT and FinGPT, which have leveraged their unique data accumulations to make strides in the finance domain, there hasn't not many similar large language models in the Chinese legal domain to facilitate its digital transformation. In this paper, we propose an open-source legal large language model named ChatLaw. Due to the importance of data quality, we carefully designed a legal domain fine-tuning dataset. Additionally, to overcome the problem of model hallucinations in legal data screening during reference data retrieval, we introduce a method that combines vector database retrieval with keyword retrieval to effectively reduce the inaccuracy of relying solely on vector database retrieval. Furthermore, we propose a self-attention method to enhance the ability of large models to overcome errors present in reference data, further optimizing the issue of model hallucinations at the model level and improving the problem-solving capabilities of large models. We also open-sourced our model and part of the data at https://github.com/PKU-YuanGroup/ChatLaw.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ZLKEQU3C/Cui et al. - 2023 - ChatLaw Open-Source Legal Large Language Model wi.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/498KW2JY/2306.html}
}

@online{daiPromptagatorFewshotDense2022,
  title = {Promptagator: {{Few-shot Dense Retrieval From}} 8 {{Examples}}},
  shorttitle = {Promptagator},
  author = {Dai, Zhuyun and Zhao, Vincent Y. and Ma, Ji and Luan, Yi and Ni, Jianmo and Lu, Jing and Bakalov, Anton and Guu, Kelvin and Hall, Keith B. and Chang, Ming-Wei},
  date = {2022-09-23},
  eprint = {2209.11755},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2209.11755},
  url = {http://arxiv.org/abs/2209.11755},
  urldate = {2024-01-10},
  abstract = {Much recent research on information retrieval has focused on how to transfer from one task (typically with abundant supervised data) to various other tasks where supervision is limited, with the implicit assumption that it is possible to generalize from one task to all the rest. However, this overlooks the fact that there are many diverse and unique retrieval tasks, each targeting different search intents, queries, and search domains. In this paper, we suggest to work on Few-shot Dense Retrieval, a setting where each task comes with a short description and a few examples. To amplify the power of a few examples, we propose Prompt-base Query Generation for Retriever (Promptagator), which leverages large language models (LLM) as a few-shot query generator, and creates task-specific retrievers based on the generated data. Powered by LLM's generalization ability, Promptagator makes it possible to create task-specific end-to-end retrievers solely based on a few examples \{without\} using Natural Questions or MS MARCO to train \%question generators or dual encoders. Surprisingly, LLM prompting with no more than 8 examples allows dual encoders to outperform heavily engineered models trained on MS MARCO like ColBERT v2 by more than 1.2 nDCG on average on 11 retrieval sets. Further training standard-size re-rankers using the same generated data yields another 5.0 point nDCG improvement. Our studies determine that query generation can be far more effective than previously observed, especially when a small amount of task-specific knowledge is given.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Information Retrieval},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ZA3CIBMP/Dai et al. - 2022 - Promptagator Few-shot Dense Retrieval From 8 Exam.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/XVBSZL4Y/2209.html}
}

@online{daiPromptagatorFewshotDense2022a,
  title = {Promptagator: {{Few-shot Dense Retrieval From}} 8 {{Examples}}},
  shorttitle = {Promptagator},
  author = {Dai, Zhuyun and Zhao, Vincent Y. and Ma, Ji and Luan, Yi and Ni, Jianmo and Lu, Jing and Bakalov, Anton and Guu, Kelvin and Hall, Keith B. and Chang, Ming-Wei},
  date = {2022-09-23},
  eprint = {2209.11755},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2209.11755},
  url = {http://arxiv.org/abs/2209.11755},
  urldate = {2024-02-01},
  abstract = {Much recent research on information retrieval has focused on how to transfer from one task (typically with abundant supervised data) to various other tasks where supervision is limited, with the implicit assumption that it is possible to generalize from one task to all the rest. However, this overlooks the fact that there are many diverse and unique retrieval tasks, each targeting different search intents, queries, and search domains. In this paper, we suggest to work on Few-shot Dense Retrieval, a setting where each task comes with a short description and a few examples. To amplify the power of a few examples, we propose Prompt-base Query Generation for Retriever (Promptagator), which leverages large language models (LLM) as a few-shot query generator, and creates task-specific retrievers based on the generated data. Powered by LLM's generalization ability, Promptagator makes it possible to create task-specific end-to-end retrievers solely based on a few examples \{without\} using Natural Questions or MS MARCO to train \%question generators or dual encoders. Surprisingly, LLM prompting with no more than 8 examples allows dual encoders to outperform heavily engineered models trained on MS MARCO like ColBERT v2 by more than 1.2 nDCG on average on 11 retrieval sets. Further training standard-size re-rankers using the same generated data yields another 5.0 point nDCG improvement. Our studies determine that query generation can be far more effective than previously observed, especially when a small amount of task-specific knowledge is given.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Information Retrieval},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/J37AH4ZI/Dai et al. - 2022 - Promptagator Few-shot Dense Retrieval From 8 Exam.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/UTZDZA5A/2209.html}
}

@incollection{dalyAIEthicsNeeds2021,
  title = {{{AI Ethics Needs Good Data}}},
  booktitle = {{{AI}} for {{Everyone}}? {{Critical Perspectives}}},
  author = {Daly, Angela and Devitt, S. Kate and Mann, Monique},
  editor = {Verdegem, Pieter},
  date = {2021-09-20},
  pages = {103--121},
  publisher = {University of Westminster Press},
  doi = {10.16997/book55.g},
  url = {https://www.uwestminsterpress.co.uk/site/chapters/e/10.16997/book55.g/},
  urldate = {2023-05-30},
  abstract = {In this chapter we argue that discourses on AI must transcend the language of ‘ethics’ and engage with power and political economy in order to constitute ‘Good Data’. In particular, we must move beyond the depoliticised language of ‘ethics’ currently deployed (Wagner 2018) in determining whether AI is ‘good’ given the limitations of ethics as a frame through which AI issues can be viewed. In order to circumvent these limits, we use instead the language and conceptualisation of ‘Good Data’ (Daly, Devitt and Mann 2019), as a more expansive term to elucidate the values, rights and interests at stake when it comes to AI’s development and deployment, as well as that of other digital technologies. Good Data considerations move beyond recurring themes of data protection/privacy and the FAT (fairness, transparency and accountability) movement to include explicit political economy critiques of power. Instead of yet more ethics principles (that tend to say the same or similar things anyway), we offer four ‘pillars’ on which Good Data AI can be built: community; rights; usability; and politics. Overall, we view AI’s “goodness” as an explicitly political (economy) question of power (Winner 1980) and one which is always related to the degree which AI is created and used to increase the wellbeing of society and especially to increase the power of the most marginalized and disenfranchised. We offer recommendations and remedies towards implementing ‘better’ approaches towards AI. Our strategies enable a different (but complementary) kind of evaluation of AI as part of the broader socio-technical systems in which AI is built and deployed.},
  isbn = {978-1-914386-16-9},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/LUU773ZJ/Daly et al. - 2021 - AI Ethics Needs Good Data.pdf}
}

@article{dashFeatureSelectionClassification1997,
  title = {Feature {{Selection}} for {{Classiﬁcation}}},
  author = {Dash, M and Liu, H},
  date = {1997},
  journaltitle = {Intelligent Data Analysis},
  abstract = {Feature selection has been the focus of interest for quite some time and much work has been done. With the creation of huge databases and the consequent requirements for good machine learning techniques, new problems arise and novel approaches to feature selection are in demand. This survey is a comprehensive overview of many existing methods from the 1970’s to the present. It identifies four steps of a typical feature selection method, and categorizes the different existing methods in terms of generation procedures and evaluation functions, and reveals hitherto unattempted combinations of generation procedures and evaluation functions. Representative methods are chosen from each category for detailed explanation and discussion via example. Benchmark datasets with different characteristics are used for comparative study. The strengths and weaknesses of different methods are explained. Guidelines for applying feature selection methods are given based on data types and domain characteristics. This survey identifies the future research areas in feature selection, introduces newcomers to this field, and paves the way for practitioners who search for suitable methods for solving domain-specific real-world applications. (Intelligent Data Analysis, Vol. 1, no. 3, http:llwww.elsevier.com/locate/ida) © 1997 Elsevier Science B.V. All rights reserved.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/T46JHDEV/Dash y Liu - 1997 - Feature Selection for Classiﬁcation.pdf}
}

@article{debTaxonomyMetamodelingFrameworks2019,
  title = {A {{Taxonomy}} for {{Metamodeling Frameworks}} for {{Evolutionary Multiobjective Optimization}}},
  author = {Deb, Kalyanmoy and Hussein, Rayan and Roy, Proteek Chandan and Toscano-Pulido, Gregorio},
  date = {2019-02},
  journaltitle = {IEEE Transactions on Evolutionary Computation},
  volume = {23},
  number = {1},
  pages = {104--116},
  issn = {1941-0026},
  doi = {10.1109/TEVC.2018.2828091},
  url = {https://ieeexplore.ieee.org/document/8340780},
  urldate = {2023-09-27},
  abstract = {One of the main difficulties in applying an optimization algorithm to a practical problem is that evaluation of objectives and constraints often involve computationally expensive procedures. To handle such problems, a metamodel is first formed from a few exact (high-fidelity) solution evaluations and then optimized by an algorithm in a progressive manner. However, in solving multiobjective or many-objective optimization problems involving multiple constraints, a simple extension of the idea to form one metamodel for each objective and constraint function may not constitute the most efficient approach. The cumulative effect of errors from each metamodel may turn out to be detrimental for the accuracy of the overall optimization procedure. In this paper, we propose a taxonomy of different plausible metamodeling frameworks for multiobjective and many-objective optimization and provide a comparative study by discussing advantages and disadvantages of each framework. The results presented in this paper are obtained using the well-known Kriging metamodeling approach. Based on our extensive simulation studies on proposed frameworks, we report intriguing observations about the behavior of each framework, which may provide salient guidelines for further studies in this emerging area within evolutionary multiobjective optimization.},
  eventtitle = {{{IEEE Transactions}} on {{Evolutionary Computation}}},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/X3NLLA3X/8340780.html}
}

@online{delatorreAutocodificadoresVariacionalesVAE2023,
  title = {Autocodificadores {{Variacionales}} ({{VAE}}) {{Fundamentos Te}}\textbackslash 'oricos y {{Aplicaciones}}},
  author = {family=Torre, given=Jordi, prefix=de la, useprefix=true},
  date = {2023-02-18},
  eprint = {2302.09363},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2302.09363},
  url = {http://arxiv.org/abs/2302.09363},
  urldate = {2024-06-02},
  abstract = {VAEs are probabilistic graphical models based on neural networks that allow the coding of input data in a latent space formed by simpler probability distributions and the reconstruction, based on such latent variables, of the source data. After training, the reconstruction network, called decoder, is capable of generating new elements belonging to a close distribution, ideally equal to the original one. This article has been written in Spanish to facilitate the arrival of this scientific knowledge to the Spanish-speaking community.},
  pubstate = {preprint},
  keywords = {68.T.01,Computer Science - Artificial Intelligence,I.2},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/XD8F8KKD/de la Torre - 2023 - Autocodificadores Variacionales (VAE) Fundamentos .pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/HIYHFN3T/2302.html}
}

@inproceedings{deshpandeAdvancedGeneticOperators2008,
  title = {Advanced Genetic Operators and Techniques: An Analysis of Dominance \& Diploidy, Reordering Operator in Genetic Search},
  shorttitle = {Advanced Genetic Operators and Techniques},
  booktitle = {Proceedings of the 9th {{WSEAS International Conference}} on {{Evolutionary Computing}}},
  author = {Deshpande, Anuradha Sanjiv and Kelkar, Ramesh Balabhau},
  date = {2008-05-02},
  series = {{{EC}}'08},
  pages = {27--33},
  publisher = {{World Scientific and Engineering Academy and Society (WSEAS)}},
  location = {Stevens Point, Wisconsin, USA},
  abstract = {The paper explains use of low level advanced Genetic Algorithm operator DOMINANCE \& DIPLOIDY for getting new binary string structure in terms of heterozygous or homozygous expression of dominated \& recessive alleles. It also highlights role of schema representation (physical schema and expressed schema) on population size, as an attempt to improve upon the robustness of simple GA's. The paper has demonstrated numerically pattern of selection of dominant and recessive alleles. It has suggested numerically the probability of gene movement and gene disruption for various REORDERING OPERATORS LIKE INVERSION, CYCLE CROSSOVER, and order crossover etc. Theory of reordering operator is tested and verified upon string / schema representation. Thus the paper aims to analyze the advanced genetic operators and techniques in GA search.},
  isbn = {978-960-6766-58-9},
  keywords = {advanced genetic operators and techniques,binary string,dominance & diploidy,expressed schema,physical schema,population,probability,schema}
}

@online{dingDataAugmentationUsing2024,
  title = {Data {{Augmentation}} Using {{LLMs}}: {{Data Perspectives}}, {{Learning Paradigms}} and {{Challenges}}},
  shorttitle = {Data {{Augmentation}} Using {{LLMs}}},
  author = {Ding, Bosheng and Qin, Chengwei and Zhao, Ruochen and Luo, Tianze and Li, Xinze and Chen, Guizhen and Xia, Wenhan and Hu, Junjie and Luu, Anh Tuan and Joty, Shafiq},
  date = {2024-03-05},
  eprint = {2403.02990},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2403.02990},
  urldate = {2024-04-24},
  abstract = {In the rapidly evolving field of large language models (LLMs), data augmentation (DA) has emerged as a pivotal technique for enhancing model performance by diversifying training examples without the need for additional data collection. This survey explores the transformative impact of LLMs on DA, particularly addressing the unique challenges and opportunities they present in the context of natural language processing (NLP) and beyond. From both data and learning perspectives, we examine various strategies that utilize LLMs for data augmentation, including a novel exploration of learning paradigms where LLM-generated data is used for diverse forms of further training. Additionally, this paper highlights the primary open challenges faced in this domain, ranging from controllable data augmentation to multimodal data augmentation. This survey highlights a paradigm shift introduced by LLMs in DA, and aims to serve as a comprehensive guide for researchers and practitioners.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/INQYZRHV/Ding et al. - 2024 - Data Augmentation using LLMs Data Perspectives, L.pdf}
}

@online{doerschTutorialVariationalAutoencoders2021,
  title = {Tutorial on {{Variational Autoencoders}}},
  author = {Doersch, Carl},
  date = {2021-01-03},
  eprint = {1606.05908},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1606.05908},
  urldate = {2023-08-27},
  abstract = {In just three years, Variational Autoencoders (VAEs) have emerged as one of the most popular approaches to unsupervised learning of complicated distributions. VAEs are appealing because they are built on top of standard function approximators (neural networks), and can be trained with stochastic gradient descent. VAEs have already shown promise in generating many kinds of complicated data, including handwritten digits [1, 2], faces [1, 3, 4], house numbers [5, 6], CIFAR images [6], physical models of scenes [4], segmentation [7], and predicting the future from static images [8]. This tutorial introduces the intuitions behind VAEs, explains the mathematics behind them, and describes some empirical behavior. No prior knowledge of variational Bayesian methods is assumed.},
  langid = {english},
  pubstate = {preprint},
  keywords = {va_theory},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ZMU2KUFY/Doersch - 2021 - Tutorial on Variational Autoencoders.pdf}
}

@incollection{drefsDirectEvolutionaryOptimization2023,
  title = {Direct {{Evolutionary Optimization}} of {{Variational Autoencoders}} with {{Binary Latents}}},
  booktitle = {Machine {{Learning}} and {{Knowledge Discovery}} in {{Databases}}},
  author = {Drefs, Jakob and Guiraud, Enrico and Panagiotou, Filippos and Lücke, Jörg},
  editor = {Amini, Massih-Reza and Canu, Stéphane and Fischer, Asja and Guns, Tias and Kralj Novak, Petra and Tsoumakas, Grigorios},
  date = {2023},
  volume = {13715},
  pages = {357--372},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-26409-2_22},
  url = {https://link.springer.com/10.1007/978-3-031-26409-2_22},
  urldate = {2023-08-28},
  abstract = {Many types of data are generated at least partly by discrete causes that are sparsely active. To model such data, we here investigate a deep generative model in the form of a variational autoencoder (VAE) which can learn a sparse, binary code for its latents. Because of the latents’ discrete nature, standard VAE training is not possible. The goal of previous approaches has therefore been to amend (i.e., typically anneal) discrete priors in order to train discrete VAEs analogously to conventional ones. Here, we divert much more strongly from conventional VAE training: We ask if it is also possible to keep the discrete nature of the latents fully intact by applying a direct, discrete optimization for the encoding model. In doing so, we (1) sidestep standard VAE mechanisms such as sampling approximation, reparameterization trick and amortization, and (2) observe a much sparser encoding compared to autoencoders that use annealed discrete latents. Direct optimization of VAEs is enabled by an evolutionary algorithm in conjunction with truncated posteriors as variational distributions, i.e. by a combination of methods which is here for the first time applied to a deep model. We first show how the discrete variational method (A) ties into gradient ascent for network weights, and how it (B) uses the decoder network to select binary latent states for training. Sparse codes have prominently been applied to image patches, where latents encode edge-like structure. For our VAEs, we maintain this prototypical application domain and observe the emergence of much sparser codes compared to more conventional VAEs. To allow for a broad comparison to other approaches, the emerging encoding was evaluated on denoising and inpainting tasks, which are canonical benchmarks for image patch models. For datasets with many, large images of single objects (ImageNet, CIFAR etc) deep generative models with dense codes seem preferable. For image patches, however, we observed advantages of sparse codes that give rise to state-of-the-art performance in ‘zero-shot’ denoising and inpainting benchmarks. Sparse codes can consequently make VAEs competitive on tasks where they have previously been outperformed by non-generative approaches.},
  isbn = {978-3-031-26408-5 978-3-031-26409-2},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/PWEM543E/Drefs et al. - 2023 - Direct Evolutionary Optimization of Variational Au.pdf}
}

@article{drefsEvolutionaryVariationalOptimization,
  title = {Evolutionary {{Variational Optimization}} of {{Generative Models}}},
  author = {Drefs, Jakob and Guiraud, Enrico and Lücke, Jörg},
  abstract = {We combine two popular optimization approaches to derive learning algorithms for generative models: variational optimization and evolutionary algorithms. The combination is realized for generative models with discrete latents by using truncated posteriors as the family of variational distributions. The variational parameters of truncated posteriors are sets of latent states. By interpreting these states as genomes of individuals and by using the variational lower bound to define a fitness, we can apply evolutionary algorithms to realize the variational loop. The used variational distributions are very flexible and we show that evolutionary algorithms can effectively and efficiently optimize the variational bound. Furthermore, the variational loop is generally applicable (“black box”) with no analytical derivations required. To show general applicability, we apply the approach to three generative models (we use Noisy-OR Bayes Nets, Binary Sparse Coding, and Spike-and-Slab Sparse Coding). To demonstrate effectiveness and efficiency of the novel variational approach, we use the standard competitive benchmarks of image denoising and inpainting. The benchmarks allow quantitative comparisons to a wide range of methods including probabilistic approaches, deep deterministic and generative networks, and non-local image processing methods. In the category of “zero-shot” learning (when only the corrupted image is used for training), we observed the evolutionary variational algorithm to significantly improve the state-of-the-art in many benchmark settings. For one well-known inpainting benchmark, we also observed state-of-the-art performance across all categories of algorithms although we only train on the corrupted image. In general, our investigations highlight the importance of research on optimization methods for generative models to achieve performance improvements.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/Q3U55WR5/Drefs et al. - Evolutionary Variational Optimization of Generativ.pdf}
}

@article{dullerudFAIRNESSONLYMETRIC2022,
  title = {{{IS FAIRNESS ONLY METRIC DEEP}}? {{EVALUATING AND ADDRESSING SUBGROUP GAPS IN DML}}},
  author = {Dullerud, Natalie and Roth, Karsten and Hamidieh, Kimia and Papernot, Nicolas and Ghassemi, Marzyeh},
  date = {2022},
  abstract = {Deep metric learning (DML) enables learning with less supervision through its emphasis on the similarity structure of representations. There has been much work on improving generalization of DML in settings like zero-shot retrieval, but little is known about its implications for fairness. In this paper, we are the first to evaluate state-of-the-art DML methods trained on imbalanced data, and to show the negative impact these representations have on minority subgroup performance when used for downstream tasks. In this work, we first define fairness in DML through an analysis of three properties of the representation space – interclass alignment, intra-class alignment, and uniformity – and propose finDML, the f airness in non-balanced DML benchmark to characterize representation fairness. Utilizing finDML, we find bias in DML representations to propagate to common downstream classification tasks. Surprisingly, this bias is propagated even when training data in the downstream task is re-balanced. To address this problem, we present Partial Attribute De-correlation (PARADE) to de-correlate feature representations from sensitive attributes and reduce performance gaps between subgroups in both embedding space and downstream metrics.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/V5CKQ79A/Dullerud et al. - 2022 - IS FAIRNESS ONLY METRIC DEEP EVALUATING AND ADDRE.pdf}
}

@online{dullerudFairnessOnlyMetric2022,
  title = {Is {{Fairness Only Metric Deep}}? {{Evaluating}} and {{Addressing Subgroup Gaps}} in {{Deep Metric Learning}}},
  shorttitle = {Is {{Fairness Only Metric Deep}}?},
  author = {Dullerud, Natalie and Roth, Karsten and Hamidieh, Kimia and Papernot, Nicolas and Ghassemi, Marzyeh},
  date = {2022-03-23},
  eprint = {2203.12748},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.2203.12748},
  url = {http://arxiv.org/abs/2203.12748},
  urldate = {2023-05-30},
  abstract = {Deep metric learning (DML) enables learning with less supervision through its emphasis on the similarity structure of representations. There has been much work on improving generalization of DML in settings like zero-shot retrieval, but little is known about its implications for fairness. In this paper, we are the first to evaluate state-of-the-art DML methods trained on imbalanced data, and to show the negative impact these representations have on minority subgroup performance when used for downstream tasks. In this work, we first define fairness in DML through an analysis of three properties of the representation space -- inter-class alignment, intra-class alignment, and uniformity -- and propose finDML, the fairness in non-balanced DML benchmark to characterize representation fairness. Utilizing finDML, we find bias in DML representations to propagate to common downstream classification tasks. Surprisingly, this bias is propagated even when training data in the downstream task is re-balanced. To address this problem, we present Partial Attribute De-correlation (PARADE) to de-correlate feature representations from sensitive attributes and reduce performance gaps between subgroups in both embedding space and downstream metrics.},
  pubstate = {preprint},
  keywords = {Computer Science - Computers and Society},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/JH9B5M2Y/Dullerud et al. - 2022 - Is Fairness Only Metric Deep Evaluating and Addre.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/NRVCW8G5/2203.html}
}

@online{dworkFairnessAwareness2011,
  title = {Fairness {{Through Awareness}}},
  author = {Dwork, Cynthia and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Zemel, Rich},
  date = {2011-11-28},
  eprint = {1104.3913},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1104.3913},
  url = {http://arxiv.org/abs/1104.3913},
  urldate = {2023-05-30},
  abstract = {We study fairness in classification, where individuals are classified, e.g., admitted to a university, and the goal is to prevent discrimination against individuals based on their membership in some group, while maintaining utility for the classifier (the university). The main conceptual contribution of this paper is a framework for fair classification comprising (1) a (hypothetical) task-specific metric for determining the degree to which individuals are similar with respect to the classification task at hand; (2) an algorithm for maximizing utility subject to the fairness constraint, that similar individuals are treated similarly. We also present an adaptation of our approach to achieve the complementary goal of "fair affirmative action," which guarantees statistical parity (i.e., the demographics of the set of individuals receiving any classification are the same as the demographics of the underlying population), while treating similar individuals as similarly as possible. Finally, we discuss the relationship of fairness to privacy: when fairness implies privacy, and how tools developed in the context of differential privacy may be applied to fairness.},
  pubstate = {preprint},
  keywords = {Computer Science - Computational Complexity,Computer Science - Computers and Society},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/82NDATYI/Dwork et al. - 2011 - Fairness Through Awareness.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/MM9AWPTR/1104.html}
}

@inproceedings{dworkFairnessAwareness2012,
  title = {Fairness through Awareness},
  booktitle = {Proceedings of the 3rd {{Innovations}} in {{Theoretical Computer Science Conference}}},
  author = {Dwork, Cynthia and Hardt, Moritz and Pitassi, Toniann and Reingold, Omer and Zemel, Richard},
  date = {2012-01-08},
  series = {{{ITCS}} '12},
  pages = {214--226},
  publisher = {Association for Computing Machinery},
  location = {New York, NY, USA},
  doi = {10.1145/2090236.2090255},
  url = {https://doi.org/10.1145/2090236.2090255},
  urldate = {2023-05-30},
  abstract = {We study fairness in classification, where individuals are classified, e.g., admitted to a university, and the goal is to prevent discrimination against individuals based on their membership in some group, while maintaining utility for the classifier (the university). The main conceptual contribution of this paper is a framework for fair classification comprising (1) a (hypothetical) task-specific metric for determining the degree to which individuals are similar with respect to the classification task at hand; (2) an algorithm for maximizing utility subject to the fairness constraint, that similar individuals are treated similarly. We also present an adaptation of our approach to achieve the complementary goal of "fair affirmative action," which guarantees statistical parity (i.e., the demographics of the set of individuals receiving any classification are the same as the demographics of the underlying population), while treating similar individuals as similarly as possible. Finally, we discuss the relationship of fairness to privacy: when fairness implies privacy, and how tools developed in the context of differential privacy may be applied to fairness.},
  isbn = {978-1-4503-1115-1},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/5RYJBU2H/Dwork et al. - 2012 - Fairness through awareness.pdf}
}

@online{EfficientMethodsNatural,
  title = {Efficient {{Methods}} for {{Natural Language Processing}}: {{A Survey}}},
  shorttitle = {Efficient {{Methods}} for {{Natural Language Processing}}},
  url = {https://ar5iv.labs.arxiv.org/html/2209.00099},
  urldate = {2022-11-16},
  abstract = {Getting the most out of limited resources allows advances in natural language processing (NLP) research and practice while being conservative with resources. Those resources may be data, time, storage, or energy. Recen…},
  langid = {english},
  organization = {ar5iv},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/DTGUTTRG/2209.html}
}

@article{el-hasnonyImprovedFeatureSelection2020,
  title = {Improved {{Feature Selection Model}} for {{Big Data Analytics}}},
  author = {El-Hasnony, Ibrahim M. and Barakat, Sherif I. and Elhoseny, Mohamed and Mostafa, Reham R.},
  date = {2020},
  journaltitle = {IEEE Access},
  shortjournal = {IEEE Access},
  volume = {8},
  pages = {66989--67004},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.2986232},
  url = {https://ieeexplore.ieee.org/document/9058715/},
  urldate = {2023-08-26},
  abstract = {Although there are many attempts to build an optimal model for feature selection in Big Data applications, the complex nature of processing such kind of data makes it still a big challenge. Accordingly, the data mining process may be obstructed due to the high dimensionality and complexity of huge data sets. For the most informative features and classification accuracy optimization, the feature selection process constitutes a mandatory pre-processing phase to reduce dataset dimensionality. The exhaustive search for the relevant features is time-consuming. In this paper, a new binary variant of the wrapper feature selection grey wolf optimization and particle swarm optimization is proposed. The K-nearest neighbor classifier with Euclidean separation matrices is used to find the optimal solutions. A tent chaotic map helps in avoiding the algorithm from locked to the local optima problem. The sigmoid function employed for converting the search space from a continuous vector to a binary one to be suitable to the problem of feature selection. Crossvalidation K-fold is used to overcome the overfitting issue. A variety of comparisons have been made with well-known and common algorithms, such as the particle swarm optimization algorithm, and the grey wolf optimization algorithm. Twenty datasets are used for the experiments, and statistical analyses are conducted to approve the performance and the effectiveness and of the proposed model with measures like selected features ratio, classification accuracy, and computation time. The cumulative features picked through the twenty datasets were 196 out of 773, as opposed to 393 and 336 in the GWO and the PSO, respectively. The overall accuracy is 90\% relative to other algorithms ’ 81.6 and 86.8. The total processing time for all datasets equals 184.3 seconds, wherein GWO and PSO equal 272 and 245.6, respectively.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/F7VFW2XI/El-Hasnony et al. - 2020 - Improved Feature Selection Model for Big Data Anal.pdf}
}

@online{ELBOWhatWhy2021,
  title = {{{ELBO}} — {{What}} \& {{Why}}},
  date = {2021-01-11T00:00:00+00:00},
  url = {https://yunfanj.com/blog/2021/01/11/ELBO.html},
  urldate = {2023-09-24},
  abstract = {ELBO (evidence lower bound) is a key concept in Variational Bayesian Methods. It transforms inference problems, which are always intractable, into optimization problems that can be solved with, for example, gradient-based methods.},
  langid = {english},
  organization = {Yunfan’s Blog},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/9XFWU3P3/ELBO.html}
}

@online{ELBOWhatWhy2021a,
  title = {{{ELBO}} — {{What}} \& {{Why}}},
  date = {2021-01-11T00:00:00+00:00},
  url = {https://yunfanj.com/blog/2021/01/11/ELBO.html},
  urldate = {2023-09-25},
  abstract = {ELBO (evidence lower bound) is a key concept in Variational Bayesian Methods. It transforms inference problems, which are always intractable, into optimization problems that can be solved with, for example, gradient-based methods.},
  langid = {english},
  organization = {Yunfan’s Blog},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/VUYWPMAN/ELBO.html}
}

@article{eltonApplyingDeutschConcept2021,
  title = {Applying {{Deutsch}}'s Concept of Good Explanations to Artificial Intelligence and Neuroscience -- an Initial Exploration},
  author = {Elton, Daniel C.},
  date = {2021-06},
  journaltitle = {Cognitive Systems Research},
  shortjournal = {Cognitive Systems Research},
  volume = {67},
  eprint = {2012.09318},
  eprinttype = {arxiv},
  eprintclass = {cs},
  pages = {9--17},
  issn = {13890417},
  doi = {10.1016/j.cogsys.2020.12.002},
  url = {http://arxiv.org/abs/2012.09318},
  urldate = {2023-05-29},
  abstract = {Artificial intelligence has made great strides since the deep learning revolution, but AI systems still struggle to extrapolate outside of their training data and adapt to new situations. For inspiration we look to the domain of science, where scientists have been able to develop theories which show remarkable ability to extrapolate and sometimes predict the existence of phenomena which have never been observed before. According to David Deutsch, this type of extrapolation, which he calls "reach", is due to scientific theories being hard to vary. In this work we investigate Deutsch's hard-to-vary principle and how it relates to more formalized principles in deep learning such as the bias-variance trade-off and Occam's razor. We distinguish internal variability, how much a model/theory can be varied internally while still yielding the same predictions, with external variability, which is how much a model must be varied to accurately predict new, out-of-distribution data. We discuss how to measure internal variability using the size of the Rashomon set and how to measure external variability using Kolmogorov complexity. We explore what role hard-to-vary explanations play in intelligence by looking at the human brain and distinguish two learning systems in the brain. The first system operates similar to deep learning and likely underlies most of perception and motor control while the second is a more creative system capable of generating hard-to-vary explanations of the world. We argue that figuring out how replicate this second system, which is capable of generating hard-to-vary explanations, is a key challenge which needs to be solved in order to realize artificial general intelligence. We make contact with the framework of Popperian epistemology which rejects induction and asserts that knowledge generation is an evolutionary process which proceeds through conjecture and refutation.},
  keywords = {I.2.0},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/D3UJIWXN/Elton - 2021 - Applying Deutsch's concept of good explanations to.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ZE27JUY2/2012.html}
}

@online{Fairlearn,
  title = {Fairlearn},
  url = {https://fairlearn.org},
  urldate = {2023-06-07},
  abstract = {An open source toolkit for assessing and improving fairness in AI},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/4M9NY3EJ/fairlearn.org.html}
}

@article{fajardoOversamplingImbalancedData2021,
  title = {On Oversampling Imbalanced Data with Deep Conditional Generative Models},
  author = {Fajardo, Val Andrei and Findlay, David and Jaiswal, Charu and Yin, Xinshang and Houmanfar, Roshanak and Xie, Honglei and Liang, Jiaxi and She, Xichen and Emerson, D.B.},
  date = {2021-05},
  journaltitle = {Expert Systems with Applications},
  shortjournal = {Expert Systems with Applications},
  volume = {169},
  pages = {114463},
  issn = {09574174},
  doi = {10.1016/j.eswa.2020.114463},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417420311155},
  urldate = {2023-08-27},
  abstract = {Class imbalanced datasets are common in real-world applications ranging from credit card fraud detection to rare disease diagnosis. Recently, deep generative models have proved successful for an array of machine learning problems such as semi-supervised learning, transfer learning, and recommender systems. However their application to class imbalance situations is limited. In this paper, we consider class conditional variants of generative adversarial networks and variational autoencoders and apply them to the imbalance problem. The main question we seek to answer is whether or not deep conditional generative models can effectively learn the distributions of minority classes so as to produce synthetic observations that ultimately lead to improvements in the performance of a downstream classifier. The numerical results show that this is indeed true and that deep generative models outperform traditional oversampling methods in many circumstances, especially in cases of severe imbalance.},
  langid = {english},
  keywords = {estado_arte},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/3826XQJ8/Fajardo et al. - 2021 - On oversampling imbalanced data with deep conditio.pdf}
}

@online{Feature_ImportancesBewareDefault,
  title = {Feature\_{{Importances}}:{{Beware Default Random Forest FI}}},
  url = {http://explained.ai/decision-tree-viz/index.html},
  urldate = {2023-11-23},
  abstract = {Training a model that accurately predicts outcomes is great, but most of the time you don't just need predictions, you want to be able to interpret your model. The problem is that the scikit-learn Random Forest feature importance and R's default Random Forest feature importance strategies are biased. To get reliable results in Python, use permutation importance, provided here and in our rfpimp package (via pip). For R, use importance=T in the Random Forest constructor then type=1 in R's importance() function.},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/NK5EBGSL/rf-importance.html}
}

@online{felixDeepLearningNamed2020,
  title = {Deep {{Learning}} for {{Named Entity Recognition}} in {{Legal Domain}}},
  author = {Félix, Nadia and Soares, Anderson and Castro, Pedro},
  date = {2020-06-01},
  url = {https://www.researchgate.net/publication/340315335_Deep_Learning_for_Named_Entity_Recognition_in_Legal_Domain},
  urldate = {2022-11-09},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/YZULYHIL/340315335_Deep_Learning_for_Named_Entity_Recognition_in_Legal_Domain.html}
}

@online{fernandoPromptbreederSelfReferentialSelfImprovement2023,
  title = {Promptbreeder: {{Self-Referential Self-Improvement Via Prompt Evolution}}},
  shorttitle = {Promptbreeder},
  author = {Fernando, Chrisantha and Banarse, Dylan and Michalewski, Henryk and Osindero, Simon and Rocktäschel, Tim},
  date = {2023-09-28},
  eprint = {2309.16797},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2309.16797},
  url = {http://arxiv.org/abs/2309.16797},
  urldate = {2024-02-09},
  abstract = {Popular prompt strategies like Chain-of-Thought Prompting can dramatically improve the reasoning abilities of Large Language Models (LLMs) in various domains. However, such hand-crafted prompt-strategies are often sub-optimal. In this paper, we present Promptbreeder, a general-purpose self-referential self-improvement mechanism that evolves and adapts prompts for a given domain. Driven by an LLM, Promptbreeder mutates a population of task-prompts, and subsequently evaluates them for fitness on a training set. Crucially, the mutation of these task-prompts is governed by mutation-prompts that the LLM generates and improves throughout evolution in a self-referential way. That is, Promptbreeder is not just improving task-prompts, but it is also improving the mutationprompts that improve these task-prompts. Promptbreeder outperforms state-of-the-art prompt strategies such as Chain-of-Thought and Plan-and-Solve Prompting on commonly used arithmetic and commonsense reasoning benchmarks. Furthermore, Promptbreeder is able to evolve intricate task-prompts for the challenging problem of hate speech classification.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/TU8BT5MK/Fernando et al. - 2023 - Promptbreeder Self-Referential Self-Improvement V.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/CCLYR3CR/2309.html}
}

@online{ferraraShouldChatGPTBe2023,
  title = {Should {{ChatGPT}} Be {{Biased}}? {{Challenges}} and {{Risks}} of {{Bias}} in {{Large Language Models}}},
  shorttitle = {Should {{ChatGPT}} Be {{Biased}}?},
  author = {Ferrara, Emilio},
  date = {2023-04-18},
  eprint = {2304.03738},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2304.03738},
  url = {http://arxiv.org/abs/2304.03738},
  urldate = {2023-05-30},
  abstract = {As the capabilities of generative language models continue to advance, the implications of biases ingrained within these models have garnered increasing attention from researchers, practitioners, and the broader public. This article investigates the challenges and risks associated with biases in large-scale language models like ChatGPT. We discuss the origins of biases, stemming from, among others, the nature of training data, model specifications, algorithmic constraints, product design, and policy decisions. We explore the ethical concerns arising from the unintended consequences of biased model outputs. We further analyze the potential opportunities to mitigate biases, the inevitability of some biases, and the implications of deploying these models in various applications, such as virtual assistants, content generation, and chatbots. Finally, we review the current approaches to identify, quantify, and mitigate biases in language models, emphasizing the need for a multi-disciplinary, collaborative effort to develop more equitable, transparent, and responsible AI systems. This article aims to stimulate a thoughtful dialogue within the artificial intelligence community, encouraging researchers and developers to reflect on the role of biases in generative language models and the ongoing pursuit of ethical AI.},
  pubstate = {preprint},
  keywords = {Computer Science - Computers and Society},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/LWVJWIMT/Ferrara - 2023 - Should ChatGPT be Biased Challenges and Risks of .pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/7L38XISH/2304.html}
}

@incollection{ferreroInteroperabilidadSistemas2021,
  title = {Interoperabilidad En Sistemas},
  booktitle = {Justicia y Tecnología},
  author = {Ferrero, Genoveva María},
  date = {2021-01-01},
  series = {Sistemas {{Judiciales N}}° 24},
  pages = {6--15},
  publisher = {Centro de Estudios de Justicia de las Américas - CEJA},
  location = {Ciudad Autónoma de Buenos Aires, Argentina}
}

@online{finardiChroniclesRAGRetriever2024,
  title = {The {{Chronicles}} of {{RAG}}: {{The Retriever}}, the {{Chunk}} and the {{Generator}}},
  shorttitle = {The {{Chronicles}} of {{RAG}}},
  author = {Finardi, Paulo and Avila, Leonardo and Castaldoni, Rodrigo and Gengo, Pedro and Larcher, Celio and Piau, Marcos and Costa, Pablo and Caridá, Vinicius},
  date = {2024-01-15},
  eprint = {2401.07883},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2401.07883},
  urldate = {2024-02-15},
  abstract = {Retrieval Augmented Generation (RAG) has become one of the most popular paradigms for enabling LLMs to access external data, and also as a mechanism for grounding to mitigate against hallucinations. When implementing RAG you can face several challenges like effective integration of retrieval models, efficient representation learning, data diversity, computational efficiency optimization, evaluation, and quality of text generation. Given all these challenges, every day a new technique to improve RAG appears, making it unfeasible to experiment with all combinations for your problem. In this context, this paper presents good practices to implement, optimize, and evaluate RAG for the Brazilian Portuguese language, focusing on the establishment of a simple pipeline for inference and experiments. We explored a diverse set of methods to answer questions about the first Harry Potter book. To generate the answers we used the OpenAI's gpt-4, gpt-4-1106-preview, gpt-3.5-turbo-1106, and Google's Gemini Pro. Focusing on the quality of the retriever, our approach achieved an improvement of MRR@10 by 35.4\% compared to the baseline. When optimizing the input size in the application, we observed that it is possible to further enhance it by 2.4\%. Finally, we present the complete architecture of the RAG with our recommendations. As result, we moved from a baseline of 57.88\% to a maximum relative score of 98.61\%.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Information Retrieval,Computer Science - Machine Learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/Z4RSYLBM/Finardi et al. - 2024 - The Chronicles of RAG The Retriever, the Chunk an.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ARWXR84A/2401.html}
}

@online{findlayEcosystemApproachEthical2020,
  title = {An {{Ecosystem Approach}} to {{Ethical AI}} and {{Data Use}}: {{Experimental Reflections}}},
  shorttitle = {An {{Ecosystem Approach}} to {{Ethical AI}} and {{Data Use}}},
  author = {Findlay, Mark and Seah, Josephine},
  date = {2020-12-27},
  eprint = {2101.02008},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2101.02008},
  urldate = {2023-05-30},
  abstract = {While we have witnessed a rapid growth of ethics documents meant to guide AI development, the promotion of AI ethics has nonetheless proceeded with little input from AI practitioners themselves. Given the proliferation of AI for Social Good initiatives, this is an emerging gap that needs to be addressed in order to develop more meaningful ethical approaches to AI use and development. This paper offers a methodology, a shared fairness approach, aimed at identifying the needs of AI practitioners when it comes to confronting and resolving ethical challenges and to find a third space where their operational language can be married with that of the more abstract principles that presently remain at the periphery of their work experiences. We offer a grassroots approach to operational ethics based on dialog and mutualised responsibility. This methodology is centred around conversations intended to elicit practitioners perceived ethical attribution and distribution over key value laden operational decisions, to identify when these decisions arise and what ethical challenges they confront, and to engage in a language of ethics and responsibility which enables practitioners to internalise ethical responsibility. The methodology bridges responsibility imbalances that rest in structural decision making power and elite technical knowledge, by commencing with personal, facilitated conversations, returning the ethical discourse to those meant to give it meaning at the sharp end of the ecosystem. Our primary contribution is to add to the recent literature seeking to bring AI practitioners' experiences to the fore by offering a methodology for understanding how ethics manifests as a relational and interdependent sociotechnical practice in their work.},
  pubstate = {preprint},
  keywords = {Computer Science - Computers and Society},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/DBXFMPPW/Findlay y Seah - 2020 - An Ecosystem Approach to Ethical AI and Data Use .pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/C7L9JADA/2101.html}
}

@video{FinGPTa,
  entrysubtype = {video},
  title = {{{FinGPT}}},
  url = {https://medium.com/@ashkangolgoon/financial-llms-fingpt-bloomberggpt-82dda11a6c05#:~:text=Although%20BloombergGPT%20is%20not%20an,fine%2Dtuning%20of%20base%20LLMs.}
}

@online{FLANFlanV2,
  title = {{{FLAN}}/Flan/v2 at Main · Google-Research/{{FLAN}}},
  url = {https://github.com/google-research/FLAN},
  urldate = {2023-02-28},
  abstract = {Contribute to google-research/FLAN development by creating an account on GitHub.},
  langid = {english},
  organization = {GitHub},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/9M3ASHQU/v2.html}
}

@video{FLANT5,
  entrysubtype = {video},
  title = {{{FLAN-T5}}},
  url = {https://huggingface.co/docs/transformers/model_doc/t5}
}

@software{FLANT5_checkpoints,
  title = {{{FLAN-T5}}\_checkpoints},
  url = {https://github.com/google-research/t5x/blob/main/docs/models.md#flan-t5-checkpoints}
}

@article{floridiAI4PeopleEthicalFramework2018,
  title = {{{AI4People}}—{{An Ethical Framework}} for a {{Good AI Society}}: {{Opportunities}}, {{Risks}}, {{Principles}}, and {{Recommendations}}},
  shorttitle = {{{AI4People}}—{{An Ethical Framework}} for a {{Good AI Society}}},
  author = {Floridi, Luciano and Cowls, Josh and Beltrametti, Monica and Chatila, Raja and Chazerand, Patrice and Dignum, Virginia and Luetge, Christoph and Madelin, Robert and Pagallo, Ugo and Rossi, Francesca and Schafer, Burkhard and Valcke, Peggy and Vayena, Effy},
  date = {2018-12-01},
  journaltitle = {Minds and Machines},
  shortjournal = {Minds \& Machines},
  volume = {28},
  number = {4},
  pages = {689--707},
  issn = {1572-8641},
  doi = {10.1007/s11023-018-9482-5},
  url = {https://doi.org/10.1007/s11023-018-9482-5},
  urldate = {2023-06-03},
  abstract = {This article reports the findings of AI4People, an Atomium—EISMD initiative~designed to lay the foundations for a “Good AI Society”. We introduce the core opportunities and risks of AI for society; present a synthesis of five ethical principles that should undergird its development and adoption; and offer 20 concrete recommendations—to assess, to develop, to incentivise, and to support good AI—which in some cases may be undertaken directly by national or supranational policy makers, while in others may be led by other stakeholders. If adopted, these recommendations would serve as a firm foundation for the establishment of a Good AI Society.},
  langid = {english},
  keywords = {AI4People,Artificial intelligence,Data governance,Digital ethics,Ethics of AI,Governance},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/U7ID29UW/Floridi et al. - 2018 - AI4People—An Ethical Framework for a Good AI Socie.pdf}
}

@inproceedings{galimzhanovaRewritingConversationalUtterances2023,
  title = {Rewriting {{Conversational Utterances}} with {{Instructed Large Language Models}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Web Intelligence}} and {{Intelligent Agent Technology}} ({{WI-IAT}})},
  author = {Galimzhanova, Elnara and Muntean, Cristina Ioana and Nardini, Franco Maria and Perego, Raffaele and Rocchietti, Guido},
  date = {2023-10-26},
  pages = {56--63},
  publisher = {IEEE},
  location = {Venice, Italy},
  doi = {10.1109/WI-IAT59888.2023.00014},
  url = {https://ieeexplore.ieee.org/document/10350178/},
  urldate = {2024-01-25},
  abstract = {Many recent studies have shown the ability of large language models (LLMs) to achieve state-of-the-art performance on many NLP tasks, such as question answering, text summarization, coding, and translation. In some cases, the results provided by LLMs are on par with those of human experts. These models’ most disruptive innovation is their ability to perform tasks via zero-shot or few-shot prompting. This capability has been successfully exploited to train instructed LLMs, where reinforcement learning with human feedback is used to guide the model to follow the user’s requests directly. In this paper, we investigate the ability of instructed LLMs to improve conversational search effectiveness by rewriting user questions in a conversational setting. We study which prompts provide the most informative rewritten utterances that lead to the best retrieval performance. Reproducible experiments are conducted on publicly-available TREC CAST datasets. The results show that rewriting conversational utterances with instructed LLMs achieves significant improvements of up to 25.2\% in MRR, 31.7\% in Precision@1, 27\% in NDCG@3, and 11.5\% in Recall@500 over state-of-the-art techniques.},
  eventtitle = {2023 {{IEEE International Conference}} on {{Web Intelligence}} and {{Intelligent Agent Technology}} ({{WI-IAT}})},
  isbn = {9798350309188},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/I2F28K7H/Galimzhanova et al. - 2023 - Rewriting Conversational Utterances with Instructe.pdf}
}

@inproceedings{galimzhanovaRewritingConversationalUtterances2023a,
  title = {Rewriting {{Conversational Utterances}} with {{Instructed Large Language Models}}},
  booktitle = {2023 {{IEEE}}/{{WIC International Conference}} on {{Web Intelligence}} and {{Intelligent Agent Technology}} ({{WI-IAT}})},
  author = {Galimzhanova, Elnara and Muntean, Cristina Ioana and Nardini, Franco Maria and Perego, Raffaele and Rocchietti, Guido},
  date = {2023-10},
  pages = {56--63},
  doi = {10.1109/WI-IAT59888.2023.00014},
  url = {https://ieeexplore.ieee.org/document/10350178},
  urldate = {2024-01-26},
  abstract = {Many recent studies have shown the ability of large language models (LLMs) to achieve state-of-the-art performance on many NLP tasks, such as question answering, text summarization, coding, and translation. In some cases, the results provided by LLMs are on par with those of human experts. These models' most disruptive innovation is their ability to perform tasks via zero-shot or few-shot prompting. This capability has been successfully exploited to train instructed LLMs, where reinforcement learning with human feedback is used to guide the model to follow the user's requests directly. In this paper, we investigate the ability of instructed LLMs to improve conversational search effectiveness by rewriting user questions in a conversational setting. We study which prompts provide the most informative rewritten utterances that lead to the best retrieval performance. Reproducible experiments are conducted on publicly-available TREC CAST datasets. The results show that rewriting conversational utterances with instructed LLMs achieves significant improvements of up to 25.2\% in MRR, 31.7\% in Precision@1, 27\% in NDCG@3, and 11.5\% in Recall@500 over state-of-the-art techniques.},
  eventtitle = {2023 {{IEEE}}/{{WIC International Conference}} on {{Web Intelligence}} and {{Intelligent Agent Technology}} ({{WI-IAT}})},
  keywords = {ChatGPT,conversational systems,Disruptive innovation,Encoding,information retrieval,Intelligent agents,LLMs,query rewriting,Question answering (information retrieval),Reinforcement learning,Task analysis},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/WTZMPNS6/10350178.html}
}

@inproceedings{galimzhanovaRewritingConversationalUtterances2023b,
  title = {Rewriting {{Conversational Utterances}} with {{Instructed Large Language Models}}},
  booktitle = {2023 {{IEEE}}/{{WIC International Conference}} on {{Web Intelligence}} and {{Intelligent Agent Technology}} ({{WI-IAT}})},
  author = {Galimzhanova, Elnara and Muntean, Cristina Ioana and Nardini, Franco Maria and Perego, Raffaele and Rocchietti, Guido},
  date = {2023-10},
  pages = {56--63},
  doi = {10.1109/WI-IAT59888.2023.00014},
  url = {https://ieeexplore.ieee.org/document/10350178},
  urldate = {2024-01-26},
  abstract = {Many recent studies have shown the ability of large language models (LLMs) to achieve state-of-the-art performance on many NLP tasks, such as question answering, text summarization, coding, and translation. In some cases, the results provided by LLMs are on par with those of human experts. These models' most disruptive innovation is their ability to perform tasks via zero-shot or few-shot prompting. This capability has been successfully exploited to train instructed LLMs, where reinforcement learning with human feedback is used to guide the model to follow the user's requests directly. In this paper, we investigate the ability of instructed LLMs to improve conversational search effectiveness by rewriting user questions in a conversational setting. We study which prompts provide the most informative rewritten utterances that lead to the best retrieval performance. Reproducible experiments are conducted on publicly-available TREC CAST datasets. The results show that rewriting conversational utterances with instructed LLMs achieves significant improvements of up to 25.2\% in MRR, 31.7\% in Precision@1, 27\% in NDCG@3, and 11.5\% in Recall@500 over state-of-the-art techniques.},
  eventtitle = {2023 {{IEEE}}/{{WIC International Conference}} on {{Web Intelligence}} and {{Intelligent Agent Technology}} ({{WI-IAT}})},
  keywords = {ChatGPT,conversational systems,Disruptive innovation,Encoding,information retrieval,Intelligent agents,LLMs,query rewriting,Question answering (information retrieval),Reinforcement learning,Task analysis},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/5ZE2WYEH/10350178.html}
}

@inproceedings{galimzhanovaRewritingConversationalUtterances2023c,
  title = {Rewriting {{Conversational Utterances}} with {{Instructed Large Language Models}}},
  author = {Galimzhanova, Elnara and Muntean, Cristina and Nardini, Franco Maria and Perego, Raffaele and Rocchietti, Guido},
  date = {2023-10-26},
  pages = {56--63},
  doi = {10.1109/WI-IAT59888.2023.00014},
  url = {/home/sebacastillo/Documentos/Globant/EY/QueryRewriting.pdf},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/B5PCC3H4/Galimzhanova et al. - 2023 - Rewriting Conversational Utterances with Instructe.pdf}
}

@online{gaoEfficientToolUse2024,
  title = {Efficient {{Tool Use}} with {{Chain-of-Abstraction Reasoning}}},
  author = {Gao, Silin and Dwivedi-Yu, Jane and Yu, Ping and Tan, Xiaoqing Ellen and Pasunuru, Ramakanth and Golovneva, Olga and Sinha, Koustuv and Celikyilmaz, Asli and Bosselut, Antoine and Wang, Tianlu},
  date = {2024-02-26},
  eprint = {2401.17464},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2401.17464},
  url = {http://arxiv.org/abs/2401.17464},
  urldate = {2024-03-12},
  abstract = {To achieve faithful reasoning that aligns with human expectations, large language models (LLMs) need to ground their reasoning to real-world knowledge (e.g., web facts, math and physical rules). Tools help LLMs access this external knowledge, but there remains challenges for fine-tuning LLM agents (e.g., Toolformer) to invoke tools in multi-step reasoning problems, where inter-connected tool calls require holistic and efficient tool usage planning. In this work, we propose a new method for LLMs to better leverage tools in multi-step reasoning. Our method, Chain-of-Abstraction (CoA), trains LLMs to first decode reasoning chains with abstract placeholders, and then call domain tools to reify each reasoning chain by filling in specific knowledge. This planning with abstract chains enables LLMs to learn more general reasoning strategies, which are robust to shifts of domain knowledge (e.g., math results) relevant to different reasoning questions. It also allows LLMs to perform decoding and calling of external tools in parallel, which avoids the inference delay caused by waiting for tool responses. In mathematical reasoning and Wiki QA domains, we show that our method consistently outperforms previous chain-of-thought and tool-augmented baselines on both in-distribution and out-of-distribution test sets, with an average \textasciitilde 6\% absolute QA accuracy improvement. LLM agents trained with our method also show more efficient tool use, with inference speed being on average \textasciitilde 1.4x faster than baseline tool-augmented LLMs.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/7HLUBYZG/Gao et al. - 2024 - Efficient Tool Use with Chain-of-Abstraction Reaso.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/KUKSH278/2401.html}
}

@online{gaoPreciseZeroShotDense2022,
  title = {Precise {{Zero-Shot Dense Retrieval}} without {{Relevance Labels}}},
  author = {Gao, Luyu and Ma, Xueguang and Lin, Jimmy and Callan, Jamie},
  date = {2022-12-20},
  eprint = {2212.10496},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2212.10496},
  url = {http://arxiv.org/abs/2212.10496},
  urldate = {2024-01-26},
  abstract = {While dense retrieval has been shown effective and efficient across tasks and languages, it remains difficult to create effective fully zero-shot dense retrieval systems when no relevance label is available. In this paper, we recognize the difficulty of zero-shot learning and encoding relevance. Instead, we propose to pivot through Hypothetical Document Embeddings\textasciitilde (HyDE). Given a query, HyDE first zero-shot instructs an instruction-following language model (e.g. InstructGPT) to generate a hypothetical document. The document captures relevance patterns but is unreal and may contain false details. Then, an unsupervised contrastively learned encoder\textasciitilde (e.g. Contriever) encodes the document into an embedding vector. This vector identifies a neighborhood in the corpus embedding space, where similar real documents are retrieved based on vector similarity. This second step ground the generated document to the actual corpus, with the encoder's dense bottleneck filtering out the incorrect details. Our experiments show that HyDE significantly outperforms the state-of-the-art unsupervised dense retriever Contriever and shows strong performance comparable to fine-tuned retrievers, across various tasks (e.g. web search, QA, fact verification) and languages\textasciitilde (e.g. sw, ko, ja).},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Information Retrieval},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/SYDH3V5P/Gao et al. - 2022 - Precise Zero-Shot Dense Retrieval without Relevanc.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/IXJM38KW/2212.html}
}

@online{gaoRetrievalAugmentedGenerationLarge2023,
  title = {Retrieval-{{Augmented Generation}} for {{Large Language Models}}: {{A Survey}}},
  shorttitle = {Retrieval-{{Augmented Generation}} for {{Large Language Models}}},
  author = {Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Haofen},
  date = {2023-12-18},
  eprint = {2312.10997},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2312.10997},
  url = {http://arxiv.org/abs/2312.10997},
  urldate = {2023-12-26},
  abstract = {Large language models (LLMs) demonstrate powerful capabilities, but they still face challenges in practical applications, such as hallucinations, slow knowledge updates, and lack of transparency in answers. Retrieval-Augmented Generation (RAG) refers to the retrieval of relevant information from external knowledge bases before answering questions with LLMs. RAG has been demonstrated to significantly enhance answer accuracy, reduce model hallucination, particularly for knowledge-intensive tasks. By citing sources, users can verify the accuracy of answers and increase trust in model outputs. It also facilitates knowledge updates and the introduction of domain-specific knowledge. RAG effectively combines the parameterized knowledge of LLMs with non-parameterized external knowledge bases, making it one of the most important methods for implementing large language models. This paper outlines the development paradigms of RAG in the era of LLMs, summarizing three paradigms: Naive RAG, Advanced RAG, and Modular RAG. It then provides a summary and organization of the three main components of RAG: retriever, generator, and augmentation methods, along with key technologies in each component. Furthermore, it discusses how to evaluate the effectiveness of RAG models, introducing two evaluation methods for RAG, emphasizing key metrics and abilities for evaluation, and presenting the latest automatic evaluation framework. Finally, potential future research directions are introduced from three aspects: vertical optimization, horizontal scalability, and the technical stack and ecosystem of RAG.},
  pubstate = {preprint},
  version = {1},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/IGTTZHM9/Gao et al. - 2023 - Retrieval-Augmented Generation for Large Language .pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/JMB5YP8B/2312.html}
}

@article{gardosMaintenanceAntipsychoticTherapy1976,
  title = {Maintenance Antipsychotic Therapy: Is the Cure Worse than the Disease?},
  shorttitle = {Maintenance Antipsychotic Therapy},
  author = {Gardos, G. and Cole, J. O.},
  date = {1976-01},
  journaltitle = {The American Journal of Psychiatry},
  shortjournal = {Am J Psychiatry},
  volume = {133},
  number = {1},
  eprint = {2021},
  eprinttype = {pmid},
  pages = {32--36},
  issn = {0002-953X},
  doi = {10.1176/ajp.133.1.32},
  abstract = {The serious long-term complications of maintenance antipsychotic therapy led the authors to undertake a critical review of outpatient withdrawal studies. Key findings included the following: 1) for a least 40\% of outpatient schizophrenics, drugs seem to be essential for survival in the community; 2) the majority of patients who relapse after drug withdrawal recompensate fairly rapidly upon reinstitution of antipsychotic drug therapy; 3) placebo survivors seem to function as well as drug survivors--thus the benefit of maintenance drug therapy appears to be prevention of relapse; and 4) some cases of early relapse after drug withdrawal may be due to dyskinesia rather than psychotic decompensation. The authors urge clinicians to evaluate each patient on maintenance antipsychotic therapy in terms of feasibility of drug withdrawal and offer practical guidelines for withdrawal and subsequent management.},
  langid = {english},
  keywords = {Antipsychotic Agents,Basal Ganglia Diseases,Chlorpromazine,Chronic Disease,Clinical Trials as Topic,Female,Humans,Movement Disorders,Promazine,Recurrence,Schizophrenia,Trifluoperazine},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/8RX54UPV/11.pdf}
}

@online{gartnerTransformerBasedLearnedOptimization2022,
  title = {Transformer-{{Based Learned Optimization}}},
  author = {Gärtner, Erik and Metz, Luke and Andriluka, Mykhaylo and Freeman, C. Daniel and Sminchisescu, Cristian},
  date = {2022-12-02},
  eprint = {2212.01055},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2212.01055},
  urldate = {2022-12-05},
  abstract = {In this paper, we propose a new approach to learned optimization. As common in the literature, we represent the computation of the update step of the optimizer with a neural network. The parameters of the optimizer are then learned on a set of training optimization tasks, in order to perform minimisation efficiently. Our main innovation is to propose a new neural network architecture for the learned optimizer inspired by the classic BFGS algorithm. As in BFGS, we estimate a preconditioning matrix as a sum of rank-one updates but use a transformer-based neural network to predict these updates jointly with the step length and direction. In contrast to several recent learned optimization approaches, our formulation allows for conditioning across different dimensions of the parameter space of the target problem while remaining applicable to optimization tasks of variable dimensionality without retraining. We demonstrate the advantages of our approach on a benchmark composed of objective functions traditionally used for evaluation of optimization algorithms, as well as on the real world-task of physics-based reconstruction of articulated 3D human motion.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/8YFXCK2X/Gärtner et al. - 2022 - Transformer-Based Learned Optimization.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/MHNMVHFK/2212.html}
}

@online{geMARTImprovingLLM2023,
  title = {{{MART}}: {{Improving LLM Safety}} with {{Multi-round Automatic Red-Teaming}}},
  shorttitle = {{{MART}}},
  author = {Ge, Suyu and Zhou, Chunting and Hou, Rui and Khabsa, Madian and Wang, Yi-Chia and Wang, Qifan and Han, Jiawei and Mao, Yuning},
  date = {2023-11-13},
  eprint = {2311.07689},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2311.07689},
  url = {http://arxiv.org/abs/2311.07689},
  urldate = {2023-11-19},
  abstract = {Red-teaming is a common practice for mitigating unsafe behaviors in Large Language Models (LLMs), which involves thoroughly assessing LLMs to identify potential flaws and addressing them with responsible and accurate responses. While effective, manual red-teaming is costly, and existing automatic red-teaming typically discovers safety risks without addressing them. In this paper, we propose a Multi-round Automatic Red-Teaming (MART) method, which incorporates both automatic adversarial prompt writing and safe response generation, significantly increasing red-teaming scalability and the safety of the target LLM. Specifically, an adversarial LLM and a target LLM interplay with each other in an iterative manner, where the adversarial LLM aims to generate challenging prompts that elicit unsafe responses from the target LLM, while the target LLM is fine-tuned with safety aligned data on these adversarial prompts. In each round, the adversarial LLM crafts better attacks on the updated target LLM, while the target LLM also improves itself through safety fine-tuning. On adversarial prompt benchmarks, the violation rate of an LLM with limited safety alignment reduces up to 84.7\% after 4 rounds of MART, achieving comparable performance to LLMs with extensive adversarial prompt writing. Notably, model helpfulness on non-adversarial prompts remains stable throughout iterations, indicating the target LLM maintains strong performance on instruction following.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/BWSSEU93/Ge et al. - 2023 - MART Improving LLM Safety with Multi-round Automa.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/NWJ9JSQI/2311.html}
}

@online{gemmateamGemmaOpenModels2024,
  title = {Gemma: {{Open Models Based}} on {{Gemini Research}} and {{Technology}}},
  shorttitle = {Gemma},
  author = {Gemma Team and Mesnard, Thomas and Hardin, Cassidy and Dadashi, Robert and Bhupatiraju, Surya and Pathak, Shreya and Sifre, Laurent and Rivière, Morgane and Kale, Mihir Sanjay and Love, Juliette and Tafti, Pouya and Hussenot, Léonard and Chowdhery, Aakanksha and Roberts, Adam and Barua, Aditya and Botev, Alex and Castro-Ros, Alex and Slone, Ambrose and Héliou, Amélie and Tacchetti, Andrea and Bulanova, Anna and Paterson, Antonia and Tsai, Beth and Shahriari, Bobak and Lan, Charline Le and Choquette-Choo, Christopher A. and Crepy, Clément and Cer, Daniel and Ippolito, Daphne and Reid, David and Buchatskaya, Elena and Ni, Eric and Noland, Eric and Yan, Geng and Tucker, George and Muraru, George-Christian and Rozhdestvenskiy, Grigory and Michalewski, Henryk and Tenney, Ian and Grishchenko, Ivan and Austin, Jacob and Keeling, James and Labanowski, Jane and Lespiau, Jean-Baptiste and Stanway, Jeff and Brennan, Jenny and Chen, Jeremy and Ferret, Johan and Chiu, Justin and Mao-Jones, Justin and Lee, Katherine and Yu, Kathy and Millican, Katie and Sjoesund, Lars Lowe and Lee, Lisa and Dixon, Lucas and Reid, Machel and Mikuła, Maciej and Wirth, Mateo and Sharman, Michael and Chinaev, Nikolai and Thain, Nithum and Bachem, Olivier and Chang, Oscar and Wahltinez, Oscar and Bailey, Paige and Michel, Paul and Yotov, Petko and Sessa, Pier Giuseppe and Chaabouni, Rahma and Comanescu, Ramona and Jana, Reena and Anil, Rohan and McIlroy, Ross and Liu, Ruibo and Mullins, Ryan and Smith, Samuel L. and Borgeaud, Sebastian and Girgin, Sertan and Douglas, Sholto and Pandya, Shree and Shakeri, Siamak and De, Soham and Klimenko, Ted and Hennigan, Tom and Feinberg, Vlad and Stokowiec, Wojciech and Chen, Yu-hui and Ahmed, Zafarali and Gong, Zhitao and Warkentin, Tris and Peran, Ludovic and Giang, Minh and Farabet, Clément and Vinyals, Oriol and Dean, Jeff and Kavukcuoglu, Koray and Hassabis, Demis and Ghahramani, Zoubin and Eck, Douglas and Barral, Joelle and Pereira, Fernando and Collins, Eli and Joulin, Armand and Fiedel, Noah and Senter, Evan and Andreev, Alek and Kenealy, Kathleen},
  date = {2024-03-13},
  eprint = {2403.08295},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2403.08295},
  urldate = {2024-04-08},
  abstract = {This work introduces Gemma, a family of lightweight, state-of-the art open models built from the research and technology used to create Gemini models. Gemma models demonstrate strong performance across academic benchmarks for language understanding, reasoning, and safety. We release two sizes of models (2 billion and 7 billion parameters), and provide both pretrained and fine-tuned checkpoints. Gemma outperforms similarly sized open models on 11 out of 18 text-based tasks, and we present comprehensive evaluations of safety and responsibility aspects of the models, alongside a detailed description of model development. We believe the responsible release of LLMs is critical for improving the safety of frontier models, and for enabling the next wave of LLM innovations.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/TQC5PLD8/Gemma Team et al. - 2024 - Gemma Open Models Based on Gemini Research and Te.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/FW2TCZWN/2403.html}
}

@online{GeneticAlgorithmsFitness2023,
  title = {Genetic {{Algorithms}}: {{Fitness Function}} for {{Feature Selection Algorithm}} | {{Saturn Cloud Blog}}},
  shorttitle = {Genetic {{Algorithms}}},
  date = {2023-07-18T00:00:00+00:00},
  url = {https://saturncloud.io/blog/genetic-algorithms-fitness-function-for-feature-selection-algorithm/},
  urldate = {2023-09-27},
  abstract = {As data scientists and software engineers, we are constantly faced with the challenge of feature selection in machine learning models. Feature selection plays a crucial role in improving model performance and reducing computational complexity. One powerful approach to feature selection is using genetic algorithms, which mimic the process of natural selection to iteratively search for the best set of features.},
  langid = {english},
  keywords = {ea_fitness_function},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/WMNIV6KD/genetic-algorithms-fitness-function-for-feature-selection-algorithm.html}
}

@article{girinDynamicalVariationalAutoencoders2021,
  title = {Dynamical {{Variational Autoencoders}}: {{A Comprehensive Review}}},
  shorttitle = {Dynamical {{Variational Autoencoders}}},
  author = {Girin, Laurent and Leglaive, Simon and Bie, Xiaoyu and Diard, Julien and Hueber, Thomas and Alameda-Pineda, Xavier},
  date = {2021},
  journaltitle = {Foundations and Trends® in Machine Learning},
  shortjournal = {FNT in Machine Learning},
  volume = {15},
  number = {1-2},
  eprint = {2008.12595},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  pages = {1--175},
  issn = {1935-8237, 1935-8245},
  doi = {10.1561/2200000089},
  url = {http://arxiv.org/abs/2008.12595},
  urldate = {2023-08-27},
  abstract = {Variational autoencoders (VAEs) are powerful deep generative models widely used to represent high-dimensional complex data through a low-dimensional latent space learned in an unsupervised manner. In the original VAE model, the input data vectors are processed independently. Recently, a series of papers have presented different extensions of the VAE to process sequential data, which model not only the latent space but also the temporal dependencies within a sequence of data vectors and corresponding latent vectors, relying on recurrent neural networks or state-space models. In this paper, we perform a literature review of these models. We introduce and discuss a general class of models, called dynamical variational autoencoders (DVAEs), which encompasses a large subset of these temporal VAE extensions. Then, we present in detail seven recently proposed DVAE models, with an aim to homogenize the notations and presentation lines, as well as to relate these models with existing classical temporal models. We have reimplemented those seven DVAE models and present the results of an experimental benchmark conducted on the speech analysis-resynthesis task (the PyTorch code is made publicly available). The paper concludes with a discussion on important issues concerning the DVAE class of models and future research guidelines.},
  langid = {english},
  keywords = {va_theory},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/KHNB52KZ/Girin et al. - 2021 - Dynamical Variational Autoencoders A Comprehensiv.pdf}
}

@article{gmComprehensiveSurveyAnalysis2020,
  title = {A Comprehensive Survey and Analysis of Generative Models in Machine Learning},
  author = {Gm, Harshvardhan and Gourisaria, Mahendra Kumar and Pandey, Manjusha and Rautaray, Siddharth Swarup},
  date = {2020-11},
  journaltitle = {Computer Science Review},
  shortjournal = {Computer Science Review},
  volume = {38},
  pages = {100285},
  issn = {15740137},
  doi = {10.1016/j.cosrev.2020.100285},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1574013720303853},
  urldate = {2023-08-27},
  abstract = {Generative models have been in existence for many decades. In the field of machine learning, we come across many scenarios when directly learning a target is intractable through discriminative models, and in such cases the joint distribution of the target and the training data is approximated and generated. These generative models help us better represent or model a set of data by generating data in the form of Markov chains or simply employing a generative iterative process to do the same. With the recent innovation of Generative Adversarial Networks (GANs), it is now possible to make use of AI to generate pieces of art, music, etc. with a high extent of realism. In this paper, we review and analyse critically all the generative models, namely Gaussian Mixture Models (GMM), Hidden Markov Models (HMM), Latent Dirichlet Allocation (LDA), Restricted Boltzmann Machines (RBM), Deep Belief Networks (DBN), Deep Boltzmann Machines (DBM), and GANs. We study their algorithms and implement each of the models to provide the reader some insights on which generative model to pick from while dealing with a problem. We also provide some noteworthy contributions done in the past to these models from the literature.},
  langid = {english},
  keywords = {va_aplications,va_implementacion},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/F2TIT7VX/Gm et al. - 2020 - A comprehensive survey and analysis of generative .pdf}
}

@online{gobiernoespanaPlanTecnologiasLenguaje,
  title = {Plan de {{Tecnologías}} Del {{Lenguaje}} - {{Página}} Principal Del {{Plan}} de {{Impulso}} de Las Tecnologías Del {{Lenguaje}}},
  author = {Gobierno España},
  url = {https://plantl.mineco.gob.es/Paginas/index.aspx},
  urldate = {2022-11-04},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ZTNQKE5M/index.html}
}

@book{goldbergdavide.GeneticAlgorithmsSearch1989,
  title = {Genetic {{Algorithms}} in {{Search}}, {{Optimization}}, and {{Machine Learning}}},
  author = {{Goldberg, David E.}},
  date = {1989},
  publisher = {Addison-Wesley},
  location = {New York, NY, USA},
  keywords = {ga_libros},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/9PN6V4RY/Goldberg_Genetic_Algorithms_in_Search.pdf}
}

@article{golubMolecularClassificationCancer1999,
  title = {Molecular {{Classification}} of {{Cancer}}: {{Class Discovery}} and {{Class Prediction}} by {{Gene Expression Monitoring}}},
  shorttitle = {Molecular {{Classification}} of {{Cancer}}},
  author = {Golub, T. R. and Slonim, D. K. and Tamayo, P. and Huard, C. and Gaasenbeek, M. and Mesirov, J. P. and Coller, H. and Loh, M. L. and Downing, J. R. and Caligiuri, M. A. and Bloomfield, C. D. and Lander, E. S.},
  date = {1999-10-15},
  journaltitle = {Science},
  shortjournal = {Science},
  volume = {286},
  number = {5439},
  pages = {531--537},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.286.5439.531},
  url = {https://www.science.org/doi/10.1126/science.286.5439.531},
  urldate = {2023-09-18},
  abstract = {Although cancer classification has improved over the past 30 years, there has been no general approach for identifying new cancer classes (class discovery) or for assigning tumors to known classes (class prediction). Here, a generic approach to cancer classification based on gene expression monitoring by DNA microarrays is described and applied to human acute leukemias as a test case. A class discovery procedure automatically discovered the distinction between acute myeloid leukemia (AML) and acute lymphoblastic leukemia (ALL) without previous knowledge of these classes. An automatically derived class predictor was able to determine the class of new leukemia cases. The results demonstrate the feasibility of cancer classification based solely on gene expression monitoring and suggest a general strategy for discovering and predicting cancer classes for other types of cancer, independent of previous biological knowledge.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/HGGKZEI9/Golub et al. - 1999 - Molecular Classification of Cancer Class Discover.pdf}
}

@article{golubtrMolecularClassificationCancer1999,
  title = {Molecular Classification of Cancer: Class Discovery and Class Prediction by Gene Expression Monitoring},
  author = {{Golub, TR} and {Slonim, DK} and {Tamayo, P} and {Huard C} and {Gaasenbeek M} and {Mesirov JP} and {Coller H} and {Loh ML} and {Downing JR} and {Caligiuri MA} and {Bloomfield CD} and {Lander ES}},
  date = {1999},
  journaltitle = {Science},
  volume = {286},
  number = {5439}
}

@article{gonzalezSistemasJudiciales24,
  title = {Sistemas Judiciales 24},
  author = {González, Leonel and Rua, Gonzalo and Quintana, Jaime Arellano and Binder, Alberto and Blanco, Rafael and Fuchs, Marie-Christine and Hammergren, Linn and Ramírez, Silvina},
  pages = {208},
  langid = {spanish},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/IJE9PU68/González et al. - Sistemas Judiciales 24.pdf}
}

@article{gonzalezSistemasJudiciales24a,
  title = {Sistemas Judiciales 24},
  author = {González, Leonel and Rua, Gonzalo and Quintana, Jaime Arellano and Binder, Alberto and Blanco, Rafael and Fuchs, Marie-Christine and Hammergren, Linn and Ramírez, Silvina},
  pages = {208},
  langid = {spanish},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/B5ZJ5RPS/González et al. - Sistemas Judiciales 24.pdf}
}

@book{goodfelloiwDeepLearning2016,
  title = {Deep {{Learning}}},
  author = {{Goodfello Iw} and {Bengio Y} and {Courville A}},
  date = {2016},
  publisher = {MIT Press},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/HXWYYAEL/Ian Goodfellow, Yoshua Bengio, Aaron Courville - Deep Learning (2017, MIT).pdf}
}

@article{grefenstetteOptimizationControlParameters1986,
  title = {Optimization of {{Control Parameters}} for {{Genetic Algorithms}}},
  author = {Grefenstette, John J.},
  date = {1986-01},
  journaltitle = {IEEE Transactions on Systems, Man, and Cybernetics},
  volume = {16},
  number = {1},
  pages = {122--128},
  issn = {2168-2909},
  doi = {10.1109/TSMC.1986.289288},
  abstract = {The task of optimizing a complex system presents at least two levels of problems for the system designer. First, a class of optimization algorithms must be chosen that is suitable for application to the system. Second, various parameters of the optimization algorithm need to be tuned for efficiency. A class of adaptive search procedures called genetic algorithms (GA) has been used to optimize a wide variety of complex systems. GA's are applied to the second level task of identifying efficient GA's for a set of numerical optimization problems. The results are validated on an image registration problem. GA's are shown to be effective for both levels of the systems optimization problem.},
  eventtitle = {{{IEEE Transactions}} on {{Systems}}, {{Man}}, and {{Cybernetics}}},
  keywords = {Adaptive control,Adaptive systems,Algorithm design and analysis,Control theory,Design optimization,Genetic algorithms,Image registration,Process control,Programmable control,Response surface methodology},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ALC5FW9E/4075583.html}
}

@incollection{grimComputationalPhilosophy2022,
  title = {Computational {{Philosophy}}},
  booktitle = {The {{Stanford Encyclopedia}} of {{Philosophy}}},
  author = {Grim, Patrick and Singer, Daniel},
  editor = {Zalta, Edward N. and Nodelman, Uri},
  date = {2022},
  edition = {Fall 2022},
  publisher = {Metaphysics Research Lab, Stanford University},
  url = {https://plato.stanford.edu/archives/fall2022/entries/computational-philosophy/},
  urldate = {2023-05-29},
  abstract = {Computational philosophy is the use of mechanized computationaltechniques to instantiate, extend, and amplify philosophical research.Computational philosophy is not philosophy of computers orcomputational techniques; it is rather philosophy usingcomputers and computational techniques. The idea is simply to applyadvances in computer technology and techniques to advance discovery,exploration and argument within any philosophical area.},
  keywords = {artificial intelligence,epistemology: social,logic: ancient,logic: epistemic,prisoner’s dilemma,reasoning: automated,scientific knowledge: social dimensions of,social norms},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/YLFU3KGP/computational-philosophy.html}
}

@online{guanLeveragingPretrainedLarge2023,
  title = {Leveraging {{Pre-trained Large Language Models}} to {{Construct}} and {{Utilize World Models}} for {{Model-based Task Planning}}},
  author = {Guan, Lin and Valmeekam, Karthik and Sreedharan, Sarath and Kambhampati, Subbarao},
  date = {2023-11-01},
  eprint = {2305.14909},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2305.14909},
  urldate = {2024-04-26},
  abstract = {There is a growing interest in applying pre-trained large language models (LLMs) to planning problems. However, methods that use LLMs directly as planners are currently impractical due to several factors, including limited correctness of plans, strong reliance on feedback from interactions with simulators or even the actual environment, and the inefficiency in utilizing human feedback. In this work, we introduce a novel alternative paradigm that constructs an explicit world (domain) model in planning domain definition language (PDDL) and then uses it to plan with sound domain-independent planners. To address the fact that LLMs may not generate a fully functional PDDL model initially, we employ LLMs as an interface between PDDL and sources of corrective feedback, such as PDDL validators and humans. For users who lack a background in PDDL, we show that LLMs can translate PDDL into natural language and effectively encode corrective feedback back to the underlying domain model. Our framework not only enjoys the correctness guarantee offered by the external planners but also reduces human involvement by allowing users to correct domain models at the beginning, rather than inspecting and correcting (through interactive prompting) every generated plan as in previous work. On two IPC domains and a Household domain that is more complicated than commonly used benchmarks such as ALFWorld, we demonstrate that GPT-4 can be leveraged to produce high-quality PDDL models for over 40 actions, and the corrected PDDL models are then used to successfully solve 48 challenging planning tasks. Resources, including the source code, are released at: https://guansuns.github.io/pages/llm-dm.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/72TJ98MG/Guan et al. - 2023 - Leveraging Pre-trained Large Language Models to Co.pdf}
}

@online{guanLeveragingPretrainedLarge2023a,
  title = {Leveraging {{Pre-trained Large Language Models}} to {{Construct}} and {{Utilize World Models}} for {{Model-based Task Planning}}},
  author = {Guan, Lin and Valmeekam, Karthik and Sreedharan, Sarath and Kambhampati, Subbarao},
  date = {2023-11-01},
  eprint = {2305.14909},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2305.14909},
  url = {http://arxiv.org/abs/2305.14909},
  urldate = {2024-04-30},
  abstract = {There is a growing interest in applying pre-trained large language models (LLMs) to planning problems. However, methods that use LLMs directly as planners are currently impractical due to several factors, including limited correctness of plans, strong reliance on feedback from interactions with simulators or even the actual environment, and the inefficiency in utilizing human feedback. In this work, we introduce a novel alternative paradigm that constructs an explicit world (domain) model in planning domain definition language (PDDL) and then uses it to plan with sound domain-independent planners. To address the fact that LLMs may not generate a fully functional PDDL model initially, we employ LLMs as an interface between PDDL and sources of corrective feedback, such as PDDL validators and humans. For users who lack a background in PDDL, we show that LLMs can translate PDDL into natural language and effectively encode corrective feedback back to the underlying domain model. Our framework not only enjoys the correctness guarantee offered by the external planners but also reduces human involvement by allowing users to correct domain models at the beginning, rather than inspecting and correcting (through interactive prompting) every generated plan as in previous work. On two IPC domains and a Household domain that is more complicated than commonly used benchmarks such as ALFWorld, we demonstrate that GPT-4 can be leveraged to produce high-quality PDDL models for over 40 actions, and the corrected PDDL models are then used to successfully solve 48 challenging planning tasks. Resources, including the source code, are released at: https://guansuns.github.io/pages/llm-dm.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/7GU556FI/Guan et al. - 2023 - Leveraging Pre-trained Large Language Models to Co.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/S2LPE942/2305.html}
}

@online{guptaAutomatedNewsSummarization2021,
  title = {Automated {{News Summarization Using Transformers}}},
  author = {Gupta, Anushka and Chugh, Diksha and Anjum and Katarya, Rahul},
  date = {2021-04-23},
  eprint = {2108.01064},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2108.01064},
  url = {http://arxiv.org/abs/2108.01064},
  urldate = {2023-08-05},
  abstract = {The amount of text data available online is increasing at a very fast pace hence text summarization has become essential. Most of the modern recommender and text classification systems require going through a huge amount of data. Manually generating precise and fluent summaries of lengthy articles is a very tiresome and time-consuming task. Hence generating automated summaries for the data and using it to train machine learning models will make these models space and time-efficient. Extractive summarization and abstractive summarization are two separate methods of generating summaries. The extractive technique identifies the relevant sentences from the original document and extracts only those from the text. Whereas in abstractive summarization techniques, the summary is generated after interpreting the original text, hence making it more complicated. In this paper, we will be presenting a comprehensive comparison of a few transformer architecture based pre-trained models for text summarization. For analysis and comparison, we have used the BBC news dataset that contains text data that can be used for summarization and human generated summaries for evaluating and comparing the summaries generated by machine learning models.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/8BYAHCER/Gupta et al. - 2021 - Automated News Summarization Using Transformers.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/FTQY39JY/2108.html}
}

@article{gutierrez-fandinoMarIASpanishLanguage,
  title = {{{MarIA}}: {{Spanish Language Models}}},
  author = {Gutiérrez-Fandiño, Asier and Armengol-Estapé, Jordi and Pàmies, Marc and Llop-Palao, Joan and Silveira-Ocampo, Joaquín and Carrino, Casimiro Pio and Armentano-Oller, Carme and Rodriguez-Penagos, Carlos and Gonzalez-Agirre, Aitor and Villegas, Marta},
  pages = {22},
  abstract = {This work presents MarIA, a family of Spanish language models and associated resources made available to the industry and the research community. Currently, MarIA includes RoBERTa-base, RoBERTa-large, GPT2 and GPT2-large Spanish language models, which can arguably be presented as the largest and most proficient language models in Spanish. The models were pretrained using a massive corpus of 570GB of clean and deduplicated texts with 135 billion words extracted from the Spanish Web Archive crawled by the National Library of Spain between 2009 and 2019. We assessed the performance of the models with nine existing evaluation datasets and with a novel extractive Question Answering dataset created ex novo. Overall, MarIA models outperform the existing Spanish models across a variety of NLU tasks and training settings.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/HJU3RLAJ/Gutiérrez-Fandiño et al. - MarIA Spanish Language Models.pdf}
}

@online{gutierrez-fandinoSpanishLegaleseLanguage2021,
  title = {Spanish {{Legalese Language Model}} and {{Corpora}}},
  author = {Gutiérrez-Fandiño, Asier and Armengol-Estapé, Jordi and Gonzalez-Agirre, Aitor and Villegas, Marta},
  date = {2021-10-23},
  eprint = {2110.12201},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2110.12201},
  urldate = {2022-11-04},
  abstract = {There are many Language Models for the English language according to its worldwide relevance. However, for the Spanish language, even if it is a widely spoken language, there are very few Spanish Language Models which result to be small and too general. Legal slang could be think of a Spanish variant on its own as it is very complicated in vocabulary, semantics and phrase understanding. For this work we gathered legal-domain corpora from different sources, generated a model and evaluated against Spanish general domain tasks. The model provides reasonable results in those tasks.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/6D2GQ87K/Gutiérrez-Fandiño et al. - 2021 - Spanish Legalese Language Model and Corpora.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/77LUEA5K/2110.html}
}

@online{gutierrez-fandinoSpanishLegaleseLanguage2021a,
  title = {Spanish {{Legalese Language Model}} and {{Corpora}}},
  author = {Gutiérrez-Fandiño, Asier and Armengol-Estapé, Jordi and Gonzalez-Agirre, Aitor and Villegas, Marta},
  date = {2021-10-23},
  eprint = {2110.12201},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2110.12201},
  urldate = {2024-03-31},
  abstract = {There are many Language Models for the English language according to its worldwide relevance. However, for the Spanish language, even if it is a widely spoken language, there are very few Spanish Language Models which result to be small and too general. Legal slang could be think of a Spanish variant on its own as it is very complicated in vocabulary, semantics and phrase understanding. For this work we gathered legal-domain corpora from different sources, generated a model and evaluated against Spanish general domain tasks. The model provides reasonable results in those tasks.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/K6YFV73Y/Gutiérrez-Fandiño et al. - 2021 - Spanish Legalese Language Model and Corpora.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/9P7BV99N/2110.html}
}

@article{guyonIntroductionVariableFeature,
  title = {An {{Introduction}} to {{Variable}} and {{Feature Selection}}},
  author = {Guyon, Isabelle and Elisseeff, Andre},
  abstract = {Variable and feature selection have become the focus of much research in areas of application for which datasets with tens or hundreds of thousands of variables are available. These areas include text processing of internet documents, gene expression array analysis, and combinatorial chemistry. The objective of variable selection is three-fold: improving the prediction performance of the predictors, providing faster and more cost-effective predictors, and providing a better understanding of the underlying process that generated the data. The contributions of this special issue cover a wide range of aspects of such problems: providing a better definition of the objective function, feature construction, feature ranking, multivariate feature selection, efficient search methods, and feature validity assessment methods.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/QMSI5YS4/Guyon y Elisseeﬀ - An Introduction to Variable and Feature Selection.pdf}
}

@online{haganHumanCenteredStandardsLegal2023,
  type = {SSRN Scholarly Paper},
  title = {Towards {{Human-Centered Standards}} for {{Legal Help AI}}},
  author = {Hagan, Margaret},
  date = {2023-09-25},
  number = {4582745},
  location = {Rochester, NY},
  url = {https://papers.ssrn.com/abstract=4582745},
  urldate = {2024-02-15},
  abstract = {As more groups consider how AI may be used in the legal sector, this paper envisions how companies and policymakers can prioritize the perspective of community members as they design AI and policies around it. It presents findings of structured interviews and design sessions with community members, in which they were asked about whether, how, and why they would use AI tools powered by large language models to respond to legal problems like receiving an eviction notice. The respondents reviewed options for simple versus complex interfaces for AI tools, and expressed how they would want to engage with an AI tool to resolve a legal problem. These empirical findings provide directions that can counterbalance legal domain experts’ proposals about the public interest around AI, as expressed by attorneys, court officials, advocates, and regulators. By hearing directly from community members about how they want to use AI for civil justice tasks, what risks concern them, and the value they would find in different kinds of AI tools, this research can ensure that people’s points of view are understood and prioritized, rather than only domain experts’ assertions about people’s needs and preferences around legal help AI.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Access to Justice,Artificial Intelligence,Legal Services,Legal Technology,Participatory Policy-making},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/QAX5QXVN/Hagan - 2023 - Towards Human-Centered Standards for Legal Help AI.pdf}
}

@online{haganOpportunitiesRisksAI2023,
  title = {Opportunities \& {{Risks}} for {{AI}}, {{Legal Help}}, and {{Access}} to {{Justice}}},
  author = {Hagan, Margaret},
  date = {2023-06-29T01:36:30},
  url = {https://medium.com/legal-design-and-innovation/opportunities-risks-for-ai-legal-help-and-access-to-justice-9c2faf8be393},
  urldate = {2024-02-15},
  abstract = {How might AI help more people find \& use their legal rights? And what risks of harm should we plan for? Here are maps we can plan around.},
  langid = {english},
  organization = {Legal Design and Innovation},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/RM55DHV4/opportunities-risks-for-ai-legal-help-and-access-to-justice-9c2faf8be393.html}
}

@inproceedings{hamadaDataDrivenAnalysisPareto2018,
  title = {Data-{{Driven Analysis}} of {{Pareto Set Topology}}},
  booktitle = {Proceedings of the {{Genetic}} and {{Evolutionary Computation Conference}}},
  author = {Hamada, Naoki and Goto, Keisuke},
  date = {2018-07-02},
  eprint = {1804.07179},
  eprinttype = {arxiv},
  eprintclass = {cs, math},
  pages = {657--664},
  doi = {10.1145/3205455.3205613},
  url = {http://arxiv.org/abs/1804.07179},
  urldate = {2023-09-13},
  abstract = {When and why can evolutionary multi-objective optimization (EMO) algorithms cover the entire Pareto set? That is a major concern for EMO researchers and practitioners. A recent theoretical study revealed that (roughly speaking) if the Pareto set forms a topological simplex (a curved line, a curved triangle, a curved tetrahedron, etc.), then decomposition-based EMO algorithms can cover the entire Pareto set. Usually, we cannot know the true Pareto set and have to estimate its topology by using the population of EMO algorithms during or after the runtime. This paper presents a data-driven approach to analyze the topology of the Pareto set. We give a theory of how to recognize the topology of the Pareto set from data and implement an algorithm to judge whether the true Pareto set may form a topological simplex or not. Numerical experiments show that the proposed method correctly recognizes the topology of high-dimensional Pareto sets within reasonable population size.},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/JSX9WKV3/Hamada y Goto - 2018 - Data-Driven Analysis of Pareto Set Topology.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/XRRRA2V8/1804.html}
}

@online{hanComprehensiveSurveyVector2023,
  title = {A {{Comprehensive Survey}} on {{Vector Database}}: {{Storage}} and {{Retrieval Technique}}, {{Challenge}}},
  shorttitle = {A {{Comprehensive Survey}} on {{Vector Database}}},
  author = {Han, Yikun and Liu, Chunjiang and Wang, Pengfei},
  date = {2023-10-18},
  eprint = {2310.11703},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2310.11703},
  urldate = {2023-12-20},
  abstract = {A vector database is used to store high-dimensional data that cannot be characterized by traditional DBMS. Although there are not many articles describing existing or introducing new vector database architectures, the approximate nearest neighbor search problem behind vector databases has been studied for a long time, and considerable related algorithmic articles can be found in the literature. This article attempts to comprehensively review relevant algorithms to provide a general understanding of this booming research area. The basis of our framework categorises these studies by the approach of solving ANNS problem, respectively hash-based, tree-based, graph-based and quantization-based approaches. Then we present an overview of existing challenges for vector databases. Lastly, we sketch how vector databases can be combined with large language models and provide new possibilities.},
  pubstate = {preprint},
  keywords = {Computer Science - Databases},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/MYJNEJTQ/Han et al. - 2023 - A Comprehensive Survey on Vector Database Storage.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/NGRPHRP6/2310.html}
}

@online{hanLMInfiniteZeroShotExtreme2024,
  title = {{{LM-Infinite}}: {{Zero-Shot Extreme Length Generalization}} for {{Large Language Models}}},
  shorttitle = {{{LM-Infinite}}},
  author = {Han, Chi and Wang, Qifan and Peng, Hao and Xiong, Wenhan and Chen, Yu and Ji, Heng and Wang, Sinong},
  date = {2024-03-09},
  eprint = {2308.16137},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2308.16137},
  url = {http://arxiv.org/abs/2308.16137},
  urldate = {2024-03-19},
  abstract = {Today's large language models (LLMs) typically train on short text segments (e.g., {$<$}4K tokens) due to the quadratic complexity of their Transformer architectures. As a result, their performance suffers drastically on inputs longer than those encountered during training, substantially limiting their applications in real-world tasks involving long contexts such as encoding scientific articles, code repositories, or long dialogues. Through theoretical analysis and empirical investigation, this work identifies three major factors contributing to this length generalization failure. Our theoretical analysis further reveals that commonly used techniques like truncating the attention window or relative positional encodings are inadequate to address them. Answering these challenges, we propose LM-Infinite, a simple and effective method for enhancing LLMs' capabilities of handling long contexts. LM-Infinite is highly flexible and can be used with most modern LLMs off-the-shelf. Without any parameter updates, it allows LLMs pre-trained with 2K or 4K-long segments to generalize to up to 200M length inputs while retaining perplexity. It also improves performance on downstream tasks such as Passkey Retrieval and Qasper in the zero-shot setting. LM-Infinite brings substantial efficiency improvements: it achieves 2.7x decoding speed up and 7.5x memory saving over the original model. Our code will be publicly available upon publication.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/3TLEMKXW/Han et al. - 2024 - LM-Infinite Zero-Shot Extreme Length Generalizati.pdf}
}

@online{haoLargeLanguageModels2024,
  title = {Large {{Language Models Can Plan Your Travels Rigorously}} with {{Formal Verification Tools}}},
  author = {Hao, Yilun and Chen, Yongchao and Zhang, Yang and Fan, Chuchu},
  date = {2024-04-18},
  eprint = {2404.11891},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2404.11891},
  url = {http://arxiv.org/abs/2404.11891},
  urldate = {2024-05-08},
  abstract = {The recent advancements of Large Language Models (LLMs), with their abundant world knowledge and capabilities of tool-using and reasoning, fostered many LLM planning algorithms. However, LLMs have not shown to be able to accurately solve complex combinatorial optimization problems. In Xie et al. (2024), the authors proposed TravelPlanner, a U.S. domestic travel planning benchmark, and showed that LLMs themselves cannot make travel plans that satisfy user requirements with a best success rate of 0.6\%. In this work, we propose a framework that enables LLMs to formally formulate and solve the travel planning problem as a satisfiability modulo theory (SMT) problem and use SMT solvers interactively and automatically solve the combinatorial search problem. The SMT solvers guarantee the satisfiable of input constraints and the LLMs can enable a language-based interaction with our framework. When the input constraints cannot be satisfiable, our LLM-based framework will interactively offer suggestions to users to modify their travel requirements via automatic reasoning using the SMT solvers. We evaluate our framework with TravelPlanner and achieve a success rate of 97\%. We also create a separate dataset that contain international travel benchmarks and use both dataset to evaluate the effectiveness of our interactive planning framework when the initial user queries cannot be satisfied. Our framework could generate valid plans with an average success rate of 78.6\% for our dataset and 85.0\% for TravelPlanner according to diverse humans preferences.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Human-Computer Interaction},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/JWZI5AT9/Hao et al. - 2024 - Large Language Models Can Plan Your Travels Rigoro.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/Q2ZAIV3F/2404.html}
}

@book{hastieElementStatisticalLearning2009,
  title = {The {{Element}} of {{Statistical Learning}}: {{Data Mining}}, {{Inference}}, and {{Prediction}}},
  author = {Hastie, T and Tibshirani, R and Friedman, J},
  date = {2009},
  edition = {Second Edition},
  publisher = {Springer},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/XM3UKJJQ/Tibshirani y Friedman - Valerie and Patrick Hastie.pdf}
}

@article{hawkins-hookerGeneratingFunctionalProtein2021,
  title = {Generating Functional Protein Variants with Variational Autoencoders},
  author = {Hawkins-Hooker, Alex and Depardieu, Florence and Baur, Sebastien and Couairon, Guillaume and Chen, Arthur and Bikard, David},
  date = {2021-02-26},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {17},
  number = {2},
  pages = {e1008736},
  publisher = {Public Library of Science},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1008736},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008736},
  urldate = {2023-10-03},
  abstract = {The vast expansion of protein sequence databases provides an opportunity for new protein design approaches which seek to learn the sequence-function relationship directly from natural sequence variation. Deep generative models trained on protein sequence data have been shown to learn biologically meaningful representations helpful for a variety of downstream tasks, but their potential for direct use in the design of novel proteins remains largely unexplored. Here we show that variational autoencoders trained on a dataset of almost 70000 luciferase-like oxidoreductases can be used to generate novel, functional variants of the luxA bacterial luciferase. We propose separate VAE models to work with aligned sequence input (MSA VAE) and raw sequence input (AR-VAE), and offer evidence that while both are able to reproduce patterns of amino acid usage characteristic of the family, the MSA VAE is better able to capture long-distance dependencies reflecting the influence of 3D structure. To confirm the practical utility of the models, we used them to generate variants of luxA whose luminescence activity was validated experimentally. We further showed that conditional variants of both models could be used to increase the solubility of luxA without disrupting function. Altogether 6/12 of the variants generated using the unconditional AR-VAE and 9/11 generated using the unconditional MSA VAE retained measurable luminescence, together with all 23 of the less distant variants generated by conditional versions of the models; the most distant functional variant contained 35 differences relative to the nearest training set sequence. These results demonstrate the feasibility of using deep generative models to explore the space of possible protein sequences and generate useful variants, providing a method complementary to rational design and directed evolution approaches.},
  langid = {english},
  keywords = {estado_arte},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ZEHGL5T6/Hawkins-Hooker et al. - 2021 - Generating functional protein variants with variat.pdf}
}

@online{highamDeepLearningIntroduction2018,
  title = {Deep {{Learning}}: {{An Introduction}} for {{Applied Mathematicians}}},
  shorttitle = {Deep {{Learning}}},
  author = {Higham, Catherine F. and Higham, Desmond J.},
  date = {2018-01-17},
  eprint = {1801.05894},
  eprinttype = {arxiv},
  eprintclass = {cs, math, stat},
  url = {http://arxiv.org/abs/1801.05894},
  urldate = {2022-11-13},
  abstract = {Multilayered artificial neural networks are becoming a pervasive tool in a host of application fields. At the heart of this deep learning revolution are familiar concepts from applied and computational mathematics; notably, in calculus, approximation theory, optimization and linear algebra. This article provides a very brief introduction to the basic ideas that underlie deep learning from an applied mathematics perspective. Our target audience includes postgraduate and final year undergraduate students in mathematics who are keen to learn about the area. The article may also be useful for instructors in mathematics who wish to enliven their classes with references to the application of deep learning techniques. We focus on three fundamental questions: what is a deep neural network? how is a network trained? what is the stochastic gradient method? We illustrate the ideas with a short MATLAB code that sets up and trains a network. We also show the use of state-of-the art software on a large scale image classification problem. We finish with references to the current literature.},
  pubstate = {preprint},
  keywords = {97R40 68T01 65K10 62M45,G.1.6,I.2.0,I.2.10,I.2.6,Mathematics - History and Overview,Mathematics - Numerical Analysis},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/CLQ74LQ6/Higham y Higham - 2018 - Deep Learning An Introduction for Applied Mathema.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/SXYPPAW5/1801.html}
}

@online{hoffmannTrainingComputeOptimalLarge2022,
  title = {Training {{Compute-Optimal Large Language Models}}},
  author = {Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and Hennigan, Tom and Noland, Eric and Millican, Katie and family=Driessche, given=George, prefix=van den, useprefix=false and Damoc, Bogdan and Guy, Aurelia and Osindero, Simon and Simonyan, Karen and Elsen, Erich and Rae, Jack W. and Vinyals, Oriol and Sifre, Laurent},
  date = {2022-03-29},
  eprint = {2203.15556},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2203.15556},
  url = {http://arxiv.org/abs/2203.15556},
  urldate = {2022-11-09},
  abstract = {We investigate the optimal model size and number of tokens for training a transformer language model under a given compute budget. We find that current large language models are significantly undertrained, a consequence of the recent focus on scaling language models whilst keeping the amount of training data constant. By training over \textbackslash nummodels language models ranging from 70 million to over 16 billion parameters on 5 to 500 billion tokens, we find that for compute-optimal training, the model size and the number of training tokens should be scaled equally: for every doubling of model size the number of training tokens should also be doubled. We test this hypothesis by training a predicted compute-optimal model, \textbackslash chinchilla, that uses the same compute budget as \textbackslash gopher but with 70B parameters and 4\$\textbackslash times\$ more more data. \textbackslash chinchilla uniformly and significantly outperforms \textbackslash Gopher (280B), GPT-3 (175B), Jurassic-1 (178B), and Megatron-Turing NLG (530B) on a large range of downstream evaluation tasks. This also means that \textbackslash chinchilla uses substantially less compute for fine-tuning and inference, greatly facilitating downstream usage. As a highlight, \textbackslash chinchilla reaches a state-of-the-art average accuracy of 67.5\textbackslash\% on the MMLU benchmark, greater than a 7\textbackslash\% improvement over \textbackslash gopher.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/5MRXH433/Hoffmann et al. - 2022 - Training Compute-Optimal Large Language Models.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/JGVNISHL/2203.html}
}

@article{horneDiscoveryPotentInhibitors2024,
  title = {Discovery of Potent Inhibitors of α-Synuclein Aggregation Using Structure-Based Iterative Learning},
  author = {Horne, Robert I. and Andrzejewska, Ewa A. and Alam, Parvez and Brotzakis, Z. Faidon and Srivastava, Ankit and Aubert, Alice and Nowinska, Magdalena and Gregory, Rebecca C. and Staats, Roxine and Possenti, Andrea and Chia, Sean and Sormanni, Pietro and Ghetti, Bernardino and Caughey, Byron and Knowles, Tuomas P. J. and Vendruscolo, Michele},
  date = {2024-04-17},
  journaltitle = {Nature Chemical Biology},
  shortjournal = {Nat Chem Biol},
  pages = {1--12},
  publisher = {Nature Publishing Group},
  issn = {1552-4469},
  doi = {10.1038/s41589-024-01580-x},
  url = {https://www.nature.com/articles/s41589-024-01580-x},
  urldate = {2024-04-18},
  abstract = {Machine learning methods hold the promise to reduce the costs and the failure rates of conventional drug discovery pipelines. This issue is especially pressing for neurodegenerative diseases, where the development of disease-modifying drugs has been particularly challenging. To address this problem, we describe here a machine learning approach to identify small molecule inhibitors of α-synuclein aggregation, a process implicated in Parkinson’s disease and other synucleinopathies. Because the proliferation of α-synuclein aggregates takes place through autocatalytic secondary nucleation, we aim to identify compounds that bind the catalytic sites on the surface of the aggregates. To achieve this goal, we use structure-based machine learning in an iterative manner to first identify and then progressively optimize secondary nucleation inhibitors. Our results demonstrate that this approach leads to the facile identification of compounds two orders of magnitude more potent than previously reported ones.},
  langid = {english},
  keywords = {Cheminformatics,Computational biology and bioinformatics,Drug discovery,Neurodegenerative diseases,Single-molecule biophysics},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/E3GUD5F2/Horne et al. - 2024 - Discovery of potent inhibitors of α-synuclein aggr.pdf}
}

@online{HowAddressArtificial2021,
  title = {How to Address Artificial Intelligence Fairness},
  date = {2021-01-22},
  url = {https://www.weforum.org/agenda/2021/01/how-to-address-artificial-intelligence-fairness/},
  urldate = {2023-05-30},
  abstract = {As AI provides an increasing number of recommendations to human decision-makers, it becomes imperative that we uncover all stones to make sure we can trust it.},
  langid = {english},
  organization = {World Economic Forum},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/QMATMQ4Z/how-to-address-artificial-intelligence-fairness.html}
}

@online{hrefHowDoesIncontext,
  title = {How Does In-Context Learning Work? {{A}} Framework for Understanding the Differences from Traditional Supervised Learning},
  shorttitle = {How Does In-Context Learning Work?},
  author = {{href=},},
  url = {http://ai.stanford.edu/blog/understanding-incontext/},
  urldate = {2022-11-03},
  abstract = {The official Stanford AI Lab blog},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/VY8R7JNJ/understanding-incontext.html}
}

@online{huangLargeLanguageModels2023,
  title = {Large {{Language Models Cannot Self-Correct Reasoning Yet}}},
  author = {Huang, Jie and Chen, Xinyun and Mishra, Swaroop and Zheng, Huaixiu Steven and Yu, Adams Wei and Song, Xinying and Zhou, Denny},
  date = {2023-10-03},
  eprint = {2310.01798},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2310.01798},
  urldate = {2023-12-24},
  abstract = {Large Language Models (LLMs) have emerged as a groundbreaking technology with their unparalleled text generation capabilities across various applications. Nevertheless, concerns persist regarding the accuracy and appropriateness of their generated content. A contemporary methodology, self-correction, has been proposed as a remedy to these issues. Building upon this premise, this paper critically examines the role and efficacy of self-correction within LLMs, shedding light on its true potential and limitations. Central to our investigation is the notion of intrinsic self-correction, whereby an LLM attempts to correct its initial responses based solely on its inherent capabilities, without the crutch of external feedback. In the context of reasoning, our research indicates that LLMs struggle to self-correct their responses without external feedback, and at times, their performance might even degrade post self-correction. Drawing from these insights, we offer suggestions for future research and practical applications in this field.},
  pubstate = {preprint},
  keywords = {strategies_self-correct},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/T8T4IGLM/Huang et al. - 2023 - Large Language Models Cannot Self-Correct Reasonin.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/Z8HN5Z87/2310.html}
}

@online{huangSurveyHallucinationLarge2023,
  title = {A {{Survey}} on {{Hallucination}} in {{Large Language Models}}: {{Principles}}, {{Taxonomy}}, {{Challenges}}, and {{Open Questions}}},
  shorttitle = {A {{Survey}} on {{Hallucination}} in {{Large Language Models}}},
  author = {Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and Liu, Ting},
  date = {2023-11-09},
  eprint = {2311.05232},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2311.05232},
  url = {http://arxiv.org/abs/2311.05232},
  urldate = {2023-11-11},
  abstract = {The emergence of large language models (LLMs) has marked a significant breakthrough in natural language processing (NLP), leading to remarkable advancements in text understanding and generation. Nevertheless, alongside these strides, LLMs exhibit a critical tendency to produce hallucinations, resulting in content that is inconsistent with real-world facts or user inputs. This phenomenon poses substantial challenges to their practical deployment and raises concerns over the reliability of LLMs in real-world scenarios, which attracts increasing attention to detect and mitigate these hallucinations. In this survey, we aim to provide a thorough and in-depth overview of recent advances in the field of LLM hallucinations. We begin with an innovative taxonomy of LLM hallucinations, then delve into the factors contributing to hallucinations. Subsequently, we present a comprehensive overview of hallucination detection methods and benchmarks. Additionally, representative approaches designed to mitigate hallucinations are introduced accordingly. Finally, we analyze the challenges that highlight the current limitations and formulate open questions, aiming to delineate pathways for future research on hallucinations in LLMs.},
  pubstate = {preprint},
  keywords = {LLMs_hallucinations},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/3BL2TKZ6/Huang et al. - 2023 - A Survey on Hallucination in Large Language Models.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/23EVS466/2311.html}
}

@online{huangSurveyHallucinationLarge2023a,
  title = {A {{Survey}} on {{Hallucination}} in {{Large Language Models}}: {{Principles}}, {{Taxonomy}}, {{Challenges}}, and {{Open Questions}}},
  shorttitle = {A {{Survey}} on {{Hallucination}} in {{Large Language Models}}},
  author = {Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and Liu, Ting},
  date = {2023-11-09},
  eprint = {2311.05232},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2311.05232},
  url = {http://arxiv.org/abs/2311.05232},
  urldate = {2024-01-08},
  abstract = {The emergence of large language models (LLMs) has marked a significant breakthrough in natural language processing (NLP), leading to remarkable advancements in text understanding and generation. Nevertheless, alongside these strides, LLMs exhibit a critical tendency to produce hallucinations, resulting in content that is inconsistent with real-world facts or user inputs. This phenomenon poses substantial challenges to their practical deployment and raises concerns over the reliability of LLMs in real-world scenarios, which attracts increasing attention to detect and mitigate these hallucinations. In this survey, we aim to provide a thorough and in-depth overview of recent advances in the field of LLM hallucinations. We begin with an innovative taxonomy of LLM hallucinations, then delve into the factors contributing to hallucinations. Subsequently, we present a comprehensive overview of hallucination detection methods and benchmarks. Additionally, representative approaches designed to mitigate hallucinations are introduced accordingly. Finally, we analyze the challenges that highlight the current limitations and formulate open questions, aiming to delineate pathways for future research on hallucinations in LLMs.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/RF3E46AM/Huang et al. - 2023 - A Survey on Hallucination in Large Language Models.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/7Y9985JQ/2311.html}
}

@online{huangSurveyRetrievalAugmentedText2024,
  title = {A {{Survey}} on {{Retrieval-Augmented Text Generation}} for {{Large Language Models}}},
  author = {Huang, Yizheng and Huang, Jimmy},
  date = {2024-04-16},
  eprint = {2404.10981},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2404.10981},
  url = {http://arxiv.org/abs/2404.10981},
  urldate = {2024-04-21},
  abstract = {Retrieval-Augmented Generation (RAG) merges retrieval methods with deep learning advancements to address the static limitations of large language models (LLMs) by enabling the dynamic integration of up-to-date external information. This methodology, focusing primarily on the text domain, provides a cost-effective solution to the generation of plausible but incorrect responses by LLMs, thereby enhancing the accuracy and reliability of their outputs through the use of real-world data. As RAG grows in complexity and incorporates multiple concepts that can influence its performance, this paper organizes the RAG paradigm into four categories: pre-retrieval, retrieval, post-retrieval, and generation, offering a detailed perspective from the retrieval viewpoint. It outlines RAG's evolution and discusses the field's progression through the analysis of significant studies. Additionally, the paper introduces evaluation methods for RAG, addressing the challenges faced and proposing future research directions. By offering an organized framework and categorization, the study aims to consolidate existing research on RAG, clarify its technological underpinnings, and highlight its potential to broaden the adaptability and applications of LLMs.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Information Retrieval},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/MU7G59NE/Huang y Huang - 2024 - A Survey on Retrieval-Augmented Text Generation fo.pdf}
}

@online{ibrahimSimpleScalableStrategies2024,
  title = {Simple and {{Scalable Strategies}} to {{Continually Pre-train Large Language Models}}},
  author = {Ibrahim, Adam and Thérien, Benjamin and Gupta, Kshitij and Richter, Mats L. and Anthony, Quentin and Lesort, Timothée and Belilovsky, Eugene and Rish, Irina},
  date = {2024-03-26},
  eprint = {2403.08763},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.08763},
  url = {http://arxiv.org/abs/2403.08763},
  urldate = {2024-04-08},
  abstract = {Large language models (LLMs) are routinely pre-trained on billions of tokens, only to start the process over again once new data becomes available. A much more efficient solution is to continually pre-train these models, saving significant compute compared to re-training. However, the distribution shift induced by new data typically results in degraded performance on previous data or poor adaptation to the new data. In this work, we show that a simple and scalable combination of learning rate (LR) re-warming, LR re-decaying, and replay of previous data is sufficient to match the performance of fully re-training from scratch on all available data, as measured by the final loss and the average score on several language model (LM) evaluation benchmarks. Specifically, we show this for a weak but realistic distribution shift between two commonly used LLM pre-training datasets (English\$\textbackslash rightarrow\$English) and a stronger distribution shift (English\$\textbackslash rightarrow\$German) at the \$405\$M parameter model scale with large dataset sizes (hundreds of billions of tokens). Selecting the weak but realistic shift for larger-scale experiments, we also find that our continual learning strategies match the re-training baseline for a 10B parameter LLM. Our results demonstrate that LLMs can be successfully updated via simple and scalable continual learning strategies, matching the re-training baseline using only a fraction of the compute. Finally, inspired by previous work, we propose alternatives to the cosine learning rate schedule that help circumvent forgetting induced by LR re-warming and that are not bound to a fixed token budget.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/3XRBBZXU/Ibrahim et al. - 2024 - Simple and Scalable Strategies to Continually Pre-.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/8ZPJ4XPE/2403.html}
}

@article{inanLlamaGuardLLMbased,
  title = {Llama {{Guard}}: {{LLM-based Input-Output Safeguard}} for {{Human-AI Conversations}}},
  author = {Inan, Hakan and Upasani, Kartikeya and Chi, Jianfeng and Rungta, Rashi and Iyer, Krithika and Mao, Yuning and Hu, Qing and Fuller, Brian and Testuggine, Davide and Khabsa, Madian},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/AA2UJ99S/Inan et al. - Llama Guard LLM-based Input-Output Safeguard for .pdf}
}

@dataset{isabelleguyonGisette2004,
  title = {Gisette},
  author = {Isabelle Guyon, Steve Gunn},
  date = {2004},
  publisher = {UCI Machine Learning Repository},
  doi = {10.24432/C5HP5B},
  url = {https://archive.ics.uci.edu/dataset/170},
  urldate = {2023-09-19}
}

@article{islamFINANCEBENCHNewBenchmark,
  title = {{{FINANCEBENCH}}: {{A New Benchmark}} for {{Financial Question Answering}}},
  author = {Islam, Pranab and Kannappan, Anand and Kiela, Douwe and Qian, Rebecca and Scherrer, Nino and Vidgen, Bertie},
  abstract = {FINANCEBENCH is a first-of-its-kind test suite for evaluating the performance of LLMs on open book financial question answering (QA). It comprises 10,231 questions about publicly traded companies, with corresponding answers and evidence strings. The questions in FINANCEBENCH are ecologically valid and cover a diverse set of scenarios. They are intended to be clear-cut and straightforward to answer to serve as a minimum performance standard. We test 16 state of the art model configurations (including GPT-4-Turbo, Llama2 and Claude2, with vector stores and long context prompts) on a sample of 150 cases from FINANCEBENCH, and manually review their answers (n=2,400). The cases are available open-source. We show that existing LLMs have clear limitations for financial QA. Notably, GPT-4-Turbo used with a retrieval system incorrectly answered or refused to answer 81\% of questions. While augmentation techniques such as using longer context window to feed in relevant evidence improve performance, they are unrealistic for enterprise settings due to increased latency and cannot support larger financial documents. We find that all models examined exhibit weaknesses, such as hallucinations, that limit their suitability for use by enterprises.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/CRKQ2P89/Islam et al. - FINANCEBENCH A New Benchmark for Financial Questi.pdf}
}

@online{islamFinanceBenchNewBenchmark2023,
  title = {{{FinanceBench}}: {{A New Benchmark}} for {{Financial Question Answering}}},
  shorttitle = {{{FinanceBench}}},
  author = {Islam, Pranab and Kannappan, Anand and Kiela, Douwe and Qian, Rebecca and Scherrer, Nino and Vidgen, Bertie},
  date = {2023-11-20},
  eprint = {2311.11944},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.2311.11944},
  url = {http://arxiv.org/abs/2311.11944},
  urldate = {2023-12-23},
  abstract = {FinanceBench is a first-of-its-kind test suite for evaluating the performance of LLMs on open book financial question answering (QA). It comprises 10,231 questions about publicly traded companies, with corresponding answers and evidence strings. The questions in FinanceBench are ecologically valid and cover a diverse set of scenarios. They are intended to be clear-cut and straightforward to answer to serve as a minimum performance standard. We test 16 state of the art model configurations (including GPT-4-Turbo, Llama2 and Claude2, with vector stores and long context prompts) on a sample of 150 cases from FinanceBench, and manually review their answers (n=2,400). The cases are available open-source. We show that existing LLMs have clear limitations for financial QA. Notably, GPT-4-Turbo used with a retrieval system incorrectly answered or refused to answer 81\% of questions. While augmentation techniques such as using longer context window to feed in relevant evidence improve performance, they are unrealistic for enterprise settings due to increased latency and cannot support larger financial documents. We find that all models examined exhibit weaknesses, such as hallucinations, that limit their suitability for use by enterprises.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/H8TYMTEQ/Islam et al. - 2023 - FinanceBench A New Benchmark for Financial Questi.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/XIVEWBB7/2311.html}
}

@online{izacardLeveragingPassageRetrieval2021,
  title = {Leveraging {{Passage Retrieval}} with {{Generative Models}} for {{Open Domain Question Answering}}},
  author = {Izacard, Gautier and Grave, Edouard},
  date = {2021-02-03},
  eprint = {2007.01282},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2007.01282},
  urldate = {2023-07-23},
  abstract = {Generative models for open domain question answering have proven to be competitive, without resorting to external knowledge. While promising, this approach requires to use models with billions of parameters, which are expensive to train and query. In this paper, we investigate how much these models can benefit from retrieving text passages, potentially containing evidence. We obtain state-of-the-art results on the Natural Questions and TriviaQA open benchmarks. Interestingly, we observe that the performance of this method significantly improves when increasing the number of retrieved passages. This is evidence that generative models are good at aggregating and combining evidence from multiple passages.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/FDY847GQ/Izacard y Grave - 2021 - Leveraging Passage Retrieval with Generative Model.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ACRN37GA/2007.html}
}

@online{jangModelStockAll2024,
  title = {Model {{Stock}}: {{All}} We Need Is Just a Few Fine-Tuned Models},
  shorttitle = {Model {{Stock}}},
  author = {Jang, Dong-Hwan and Yun, Sangdoo and Han, Dongyoon},
  date = {2024-03-28},
  eprint = {2403.19522},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.19522},
  url = {http://arxiv.org/abs/2403.19522},
  urldate = {2024-03-31},
  abstract = {This paper introduces an efficient fine-tuning method for large pre-trained models, offering strong in-distribution (ID) and out-of-distribution (OOD) performance. Breaking away from traditional practices that need a multitude of fine-tuned models for averaging, our approach employs significantly fewer models to achieve final weights yet yield superior accuracy. Drawing from key insights in the weight space of fine-tuned weights, we uncover a strong link between the performance and proximity to the center of weight space. Based on this, we introduce a method that approximates a center-close weight using only two fine-tuned models, applicable during or after training. Our innovative layer-wise weight averaging technique surpasses state-of-the-art model methods such as Model Soup, utilizing only two fine-tuned models. This strategy can be aptly coined Model Stock, highlighting its reliance on selecting a minimal number of models to draw a more optimized-averaged model. We demonstrate the efficacy of Model Stock with fine-tuned models based upon pre-trained CLIP architectures, achieving remarkable performance on both ID and OOD tasks on the standard benchmarks, all while barely bringing extra computational demands. Our code and pre-trained models are available at https://github.com/naver-ai/model-stock.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/69XW33FF/Jang et al. - 2024 - Model Stock All we need is just a few fine-tuned .pdf}
}

@article{jiaoSurveyEvolutionaryMultiobjective2023,
  title = {A {{Survey}} on {{Evolutionary Multiobjective Feature Selection}} in {{Classification}}: {{Approaches}}, {{Applications}}, and {{Challenges}}},
  shorttitle = {A {{Survey}} on {{Evolutionary Multiobjective Feature Selection}} in {{Classification}}},
  author = {Jiao, Ruwang and Nguyen, Bach Hoai and Xue, Bing and Zhang, Mengjie},
  date = {2023},
  journaltitle = {IEEE Transactions on Evolutionary Computation},
  shortjournal = {IEEE Trans. Evol. Computat.},
  pages = {1--1},
  issn = {1089-778X, 1089-778X, 1941-0026},
  doi = {10.1109/TEVC.2023.3292527},
  url = {https://ieeexplore.ieee.org/document/10173647/},
  urldate = {2023-08-26},
  abstract = {Maximizing the classification accuracy and minimizing the number of selected features are two primary objectives in feature selection, which is inherently a multiobjective task. Multiobjective feature selection enables us to gain various insights from complex data in addition to dimensionality reduction and improved accuracy, which has attracted increasing attention from researchers and practitioners. Over the past two decades, significant advancements in multiobjective feature selection in classification have been achieved in both the methodologies and applications, but have not been well summarized and discussed. To fill this gap, this paper presents a broad survey on existing research on multiobjective feature selection in classification, focusing on up-to-date approaches, applications, current challenges, and future directions. To be specific, we categorize multiobjective feature selection in classification on the basis of different criteria, and provide detailed descriptions of representative methods in each category. Additionally, we summarize a list of successful real-world applications of multiobjective feature selection from different domains, to exemplify their significant practical value and demonstrate their abilities in providing a set of tradeoff feature subsets to meet different requirements of decision makers. We also discuss key challenges and shed lights on emerging directions for future developments of multiobjective feature selection.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/NAL8KXV8/Jiao et al. - 2023 - A Survey on Evolutionary Multiobjective Feature Se.pdf}
}

@article{jiaoSurveyEvolutionaryMultiobjective2023a,
  title = {A {{Survey}} on {{Evolutionary Multiobjective Feature Selection}} in {{Classification}}: {{Approaches}}, {{Applications}}, and {{Challenges}}},
  shorttitle = {A {{Survey}} on {{Evolutionary Multiobjective Feature Selection}} in {{Classification}}},
  author = {Jiao, Ruwang and Nguyen, Bach Hoai and Xue, Bing and Zhang, Mengjie},
  date = {2023},
  journaltitle = {IEEE Transactions on Evolutionary Computation},
  shortjournal = {IEEE Trans. Evol. Computat.},
  pages = {1--1},
  issn = {1089-778X, 1089-778X, 1941-0026},
  doi = {10.1109/TEVC.2023.3292527},
  url = {https://ieeexplore.ieee.org/document/10173647/},
  urldate = {2023-08-26},
  abstract = {Maximizing the classification accuracy and minimizing the number of selected features are two primary objectives in feature selection, which is inherently a multiobjective task. Multiobjective feature selection enables us to gain various insights from complex data in addition to dimensionality reduction and improved accuracy, which has attracted increasing attention from researchers and practitioners. Over the past two decades, significant advancements in multiobjective feature selection in classification have been achieved in both the methodologies and applications, but have not been well summarized and discussed. To fill this gap, this paper presents a broad survey on existing research on multiobjective feature selection in classification, focusing on up-to-date approaches, applications, current challenges, and future directions. To be specific, we categorize multiobjective feature selection in classification on the basis of different criteria, and provide detailed descriptions of representative methods in each category. Additionally, we summarize a list of successful real-world applications of multiobjective feature selection from different domains, to exemplify their significant practical value and demonstrate their abilities in providing a set of tradeoff feature subsets to meet different requirements of decision makers. We also discuss key challenges and shed lights on emerging directions for future developments of multiobjective feature selection.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/LJ5EEV9A/Jiao et al. - 2023 - A Survey on Evolutionary Multiobjective Feature Se.pdf}
}

@inproceedings{jinPubMedQADatasetBiomedical2019,
  title = {{{PubMedQA}}: {{A Dataset}} for {{Biomedical Research Question Answering}}},
  shorttitle = {{{PubMedQA}}},
  booktitle = {Proceedings of the 2019 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} and the 9th {{International Joint Conference}} on {{Natural Language Processing}} ({{EMNLP-IJCNLP}})},
  author = {Jin, Qiao and Dhingra, Bhuwan and Liu, Zhengping and Cohen, William and Lu, Xinghua},
  editor = {Inui, Kentaro and Jiang, Jing and Ng, Vincent and Wan, Xiaojun},
  date = {2019-11},
  pages = {2567--2577},
  publisher = {Association for Computational Linguistics},
  location = {Hong Kong, China},
  doi = {10.18653/v1/D19-1259},
  url = {https://aclanthology.org/D19-1259},
  urldate = {2024-03-28},
  abstract = {We introduce PubMedQA, a novel biomedical question answering (QA) dataset collected from PubMed abstracts. The task of PubMedQA is to answer research questions with yes/no/maybe (e.g.: Do preoperative statins reduce atrial fibrillation after coronary artery bypass grafting?) using the corresponding abstracts. PubMedQA has 1k expert-annotated, 61.2k unlabeled and 211.3k artificially generated QA instances. Each PubMedQA instance is composed of (1) a question which is either an existing research article title or derived from one, (2) a context which is the corresponding abstract without its conclusion, (3) a long answer, which is the conclusion of the abstract and, presumably, answers the research question, and (4) a yes/no/maybe answer which summarizes the conclusion. PubMedQA is the first QA dataset where reasoning over biomedical research texts, especially their quantitative contents, is required to answer the questions. Our best performing model, multi-phase fine-tuning of BioBERT with long answer bag-of-word statistics as additional supervision, achieves 68.1\% accuracy, compared to single human performance of 78.0\% accuracy and majority-baseline of 55.2\% accuracy, leaving much room for improvement. PubMedQA is publicly available at https://pubmedqa.github.io.},
  eventtitle = {{{EMNLP-IJCNLP}} 2019},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/44HIIU83/Jin et al. - 2019 - PubMedQA A Dataset for Biomedical Research Questi.pdf}
}

@article{JournalScientificTechnical,
  title = {Journal of {{Scientific}} and {{Technical Advancements}}},
  volume = {1},
  number = {3},
  abstract = {Genetic algorithm is an optimization technique which is based on the process of natural selection that drives biological evolution. It repeatedly modifies a population of individual solution and chooses individuals randomly on the basis of fitness value from the current population to be parent and uses them to produce the offspring for the next population. The main components of genetic algorithm consists of fitness function, cross over, mutation etc. The design of fitness function is very essential in genetic algorithm as the desired output depends heavily on the design of fitness function. The fitness value of each individual is computed by applying the fitness function to it. A fitness function is an application specific objective function used to evaluate relative effectiveness of the potential solutions. For standard optimization algorithm, it is known as objective function. In this paper, some of the fitness functions, applied in different domains, have been selected and analyzed. It has been observed that formulation of specific fitness function is very significant and different classes of applications depend on different parameters for designing such functions. The study may further be enhanced to design specific and optimized fitness function for future research.},
  langid = {english},
  keywords = {ea_fitness_function},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/IY6ZH49R/Journal of Scientific and Technical Advancements.pdf}
}

@inproceedings{jovicReviewFeatureSelection2015,
  title = {A Review of Feature Selection Methods with Applications},
  booktitle = {2015 38th {{International Convention}} on {{Information}} and {{Communication Technology}}, {{Electronics}} and {{Microelectronics}} ({{MIPRO}})},
  author = {Jovic, A. and Brkic, K. and Bogunovic, N.},
  date = {2015-05},
  pages = {1200--1205},
  publisher = {IEEE},
  location = {Opatija, Croatia},
  doi = {10.1109/MIPRO.2015.7160458},
  url = {http://ieeexplore.ieee.org/document/7160458/},
  urldate = {2023-09-05},
  abstract = {Feature selection (FS) methods can be used in data pre-processing to achieve efficient data reduction. This is useful for finding accurate data models. Since exhaustive search for optimal feature subset is infeasible in most cases, many search strategies have been proposed in literature. The usual applications of FS are in classification, clustering, and regression tasks. This review considers most of the commonly used FS techniques. Particular emphasis is on the application aspects. In addition to standard filter, wrapper, and embedded methods, we also provide insight into FS for recent hybrid approaches and other advanced topics.},
  eventtitle = {2015 38th {{International Convention}} on {{Information}} and {{Communication Technology}}, {{Electronics}} and {{Microelectronics}} ({{MIPRO}})},
  isbn = {978-953-233-082-3},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/7J9AFLJL/Jovic et al. - 2015 - A review of feature selection methods with applica.pdf}
}

@book{jurafskySpeechLanguageProcessing,
  title = {Speech and {{Language Processing}}: {{An}} Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition.},
  author = {Jurafsky, Daniel and Martin, James H.},
  edition = {3, Draft},
  url = {https://web.stanford.edu/~jurafsky/slp3/ed3book_jan122022.pdf}
}

@book{jurafskySpeechLanguageProcessing2021,
  title = {Speech and {{Language Processing}}: {{An Introduction}} to {{Natural Language Processing}}, {{Computational Linguistics}}, and {{Speech Recognition}}},
  author = {Jurafsky, Daniel and Martin, James H.},
  date = {2021-12-29},
  edition = {2021},
  url = {https://web.stanford.edu/~jurafsky/slp3/}
}

@online{kaddourChallengesApplicationsLarge2023,
  title = {Challenges and {{Applications}} of {{Large Language Models}}},
  author = {Kaddour, Jean and Harris, Joshua and Mozes, Maximilian and Bradley, Herbie and Raileanu, Roberta and McHardy, Robert},
  date = {2023-07-19},
  eprint = {2307.10169},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2307.10169},
  urldate = {2023-07-23},
  abstract = {Large Language Models (LLMs) went from non-existent to ubiquitous in the machine learning discourse within a few years. Due to the fast pace of the field, it is difficult to identify the remaining challenges and already fruitful application areas. In this paper, we aim to establish a systematic set of open problems and application successes so that ML researchers can comprehend the field's current state more quickly and become productive.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/7ZGZUD8T/Kaddour et al. - 2023 - Challenges and Applications of Large Language Mode.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/PHK8NT6Q/2307.html}
}

@article{kambhampatiCanLargeLanguage2024,
  title = {Can Large Language Models Reason and Plan?},
  author = {Kambhampati, Subbarao},
  date = {2024-04},
  journaltitle = {Annals of the New York Academy of Sciences},
  shortjournal = {Annals of the New York Academy of Sciences},
  volume = {1534},
  number = {1},
  pages = {15--18},
  issn = {0077-8923, 1749-6632},
  doi = {10.1111/nyas.15125},
  url = {https://nyaspubs.onlinelibrary.wiley.com/doi/10.1111/nyas.15125},
  urldate = {2024-04-26},
  abstract = {Abstract             While humans sometimes do show the capability of correcting their own erroneous guesses with self‐critiquing, there seems to be no basis for that assumption in the case of LLMs.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/WH7MJC8M/Kambhampati - 2024 - Can large language models reason and plan.pdf}
}

@online{kambhampatiLLMsCanPlan2024,
  title = {{{LLMs Can}}'t {{Plan}}, {{But Can Help Planning}} in {{LLM-Modulo Frameworks}}},
  author = {Kambhampati, Subbarao and Valmeekam, Karthik and Guan, Lin and Stechly, Kaya and Verma, Mudit and Bhambri, Siddhant and Saldyt, Lucas and Murthy, Anil},
  date = {2024-02-05},
  eprint = {2402.01817},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2402.01817},
  url = {http://arxiv.org/abs/2402.01817},
  urldate = {2024-04-26},
  abstract = {There is considerable confusion about the role of Large Language Models (LLMs) in planning and reasoning tasks. On one side are over-optimistic claims that LLMs can indeed do these tasks with just the right prompting or self-verification strategies. On the other side are perhaps over-pessimistic claims that all that LLMs are good for in planning/reasoning tasks are as mere translators of the problem specification from one syntactic format to another, and ship the problem off to external symbolic solvers. In this position paper, we take the view that both these extremes are misguided. We argue that auto-regressive LLMs cannot, by themselves, do planning or self-verification (which is after all a form of reasoning), and shed some light on the reasons for misunderstandings in the literature. We will also argue that LLMs should be viewed as universal approximate knowledge sources that have much more meaningful roles to play in planning/reasoning tasks beyond simple front-end/back-end format translators. We present a vision of \{\textbackslash bf LLM-Modulo Frameworks\} that combine the strengths of LLMs with external model-based verifiers in a tighter bi-directional interaction regime. We will show how the models driving the external verifiers themselves can be acquired with the help of LLMs. We will also argue that rather than simply pipelining LLMs and symbolic components, this LLM-Modulo Framework provides a better neuro-symbolic approach that offers tighter integration between LLMs and symbolic components, and allows extending the scope of model-based planning/reasoning regimes towards more flexible knowledge, problem and preference specifications.},
  pubstate = {preprint},
  version = {2},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/J8F2ENBW/Kambhampati et al. - 2024 - LLMs Can't Plan, But Can Help Planning in LLM-Modu.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/YFNLH87E/2402.html}
}

@article{katochReviewGeneticAlgorithm2021,
  title = {A Review on Genetic Algorithm: Past, Present, and Future},
  shorttitle = {A Review on Genetic Algorithm},
  author = {Katoch, Sourabh and Chauhan, Sumit Singh and Kumar, Vijay},
  date = {2021-02-01},
  journaltitle = {Multimedia Tools and Applications},
  shortjournal = {Multimed Tools Appl},
  volume = {80},
  number = {5},
  pages = {8091--8126},
  issn = {1573-7721},
  doi = {10.1007/s11042-020-10139-6},
  url = {https://doi.org/10.1007/s11042-020-10139-6},
  urldate = {2023-06-29},
  abstract = {In this paper, the analysis of recent advances in genetic algorithms is discussed. The genetic algorithms of great interest in research community are selected for analysis. This review will help the new and demanding researchers to provide the wider vision of genetic algorithms. The well-known algorithms and their implementation are presented with their pros and cons. The genetic operators and their usages are discussed with the aim of facilitating new researchers. The different research domains involved in genetic algorithms are covered. The future research directions in the area of genetic operators, fitness function and hybrid algorithms are discussed. This structured review will be helpful for research and graduate teaching.},
  langid = {english},
  keywords = {Crossover,Evolution,Genetic algorithm,Metaheuristic,Mutation,Optimization,Selection}
}

@article{kebailiDeepLearningApproaches2023,
  title = {Deep {{Learning Approaches}} for {{Data Augmentation}} in {{Medical Imaging}}: {{A Review}}},
  shorttitle = {Deep {{Learning Approaches}} for {{Data Augmentation}} in {{Medical Imaging}}},
  author = {Kebaili, Aghiles and Lapuyade-Lahorgue, Jérôme and Ruan, Su},
  date = {2023-04-13},
  journaltitle = {Journal of Imaging},
  shortjournal = {J. Imaging},
  volume = {9},
  number = {4},
  eprint = {2307.13125},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  pages = {81},
  issn = {2313-433X},
  doi = {10.3390/jimaging9040081},
  url = {http://arxiv.org/abs/2307.13125},
  urldate = {2023-11-29},
  abstract = {Deep learning has become a popular tool for medical image analysis, but the limited availability of training data remains a major challenge, particularly in the medical field where data acquisition can be costly and subject to privacy regulations. Data augmentation techniques offer a solution by artificially increasing the number of training samples, but these techniques often produce limited and unconvincing results. To address this issue, a growing number of studies have proposed the use of deep generative models to generate more realistic and diverse data that conform to the true distribution of the data. In this review, we focus on three types of deep generative models for medical image augmentation: variational autoencoders, generative adversarial networks, and diffusion models. We provide an overview of the current state of the art in each of these models and discuss their potential for use in different downstream tasks in medical imaging, including classification, segmentation, and cross-modal translation. We also evaluate the strengths and limitations of each model and suggest directions for future research in this field. Our goal is to provide a comprehensive review about the use of deep generative models for medical image augmentation and to highlight the potential of these models for improving the performance of deep learning algorithms in medical image analysis.},
  keywords = {Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/GDFNHCTI/Kebaili et al. - 2023 - Deep Learning Approaches for Data Augmentation in .pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/KK3W74ZV/2307.html}
}

@article{khaireStabilityFeatureSelection2022,
  title = {Stability of Feature Selection Algorithm: {{A}} Review},
  shorttitle = {Stability of Feature Selection Algorithm},
  author = {Khaire, Utkarsh Mahadeo and Dhanalakshmi, R.},
  date = {2022-04},
  journaltitle = {Journal of King Saud University - Computer and Information Sciences},
  shortjournal = {Journal of King Saud University - Computer and Information Sciences},
  volume = {34},
  number = {4},
  pages = {1060--1073},
  issn = {13191578},
  doi = {10.1016/j.jksuci.2019.06.012},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1319157819304379},
  urldate = {2023-08-26},
  abstract = {Feature selection technique is a knowledge discovery tool which provides an understanding of the problem through the analysis of the most relevant features. Feature selection aims at building better classifier by listing significant features which also helps in reducing computational overload. Due to existing high throughput technologies and their recent advancements are resulting in high dimensional data due to which feature selection is being treated as handy and mandatory in such datasets. This actually questions the interpretability and stability of traditional feature selection algorithms. The high correlation in features frequently produces multiple equally optimal signatures, which makes traditional feature selection method unstable and thus leading to instability which reduces the confidence of selected features. Stability is the robustness of the feature preferences it produces to perturbation of training samples. Stability indicates the reproducibility power of the feature selection method. High stability of the feature selection algorithm is equally important as the high classification accuracy when evaluating feature selection performance. In this paper, we provide an overview of feature selection techniques and instability of the feature selection algorithm. We also present some of the solutions which can handle the different source of instability.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/MUS8J3RK/Khaire y Dhanalakshmi - 2022 - Stability of feature selection algorithm A review.pdf}
}

@online{khattabDemonstrateSearchPredictComposingRetrieval2022,
  title = {Demonstrate-{{Search-Predict}}: {{Composing}} Retrieval and Language Models for Knowledge-Intensive {{NLP}}},
  shorttitle = {Demonstrate-{{Search-Predict}}},
  author = {Khattab, Omar and Santhanam, Keshav and Li, Xiang Lisa and Hall, David and Liang, Percy and Potts, Christopher and Zaharia, Matei},
  date = {2022-12-28},
  url = {https://arxiv.org/abs/2212.14024v2},
  urldate = {2024-01-10},
  abstract = {Retrieval-augmented in-context learning has emerged as a powerful approach for addressing knowledge-intensive tasks using frozen language models (LM) and retrieval models (RM). Existing work has combined these in simple "retrieve-then-read" pipelines in which the RM retrieves passages that are inserted into the LM prompt. To begin to fully realize the potential of frozen LMs and RMs, we propose Demonstrate-Search-Predict (DSP), a framework that relies on passing natural language texts in sophisticated pipelines between an LM and an RM. DSP can express high-level programs that bootstrap pipeline-aware demonstrations, search for relevant passages, and generate grounded predictions, systematically breaking down problems into small transformations that the LM and RM can handle more reliably. We have written novel DSP programs for answering questions in open-domain, multi-hop, and conversational settings, establishing in early evaluations new state-of-the-art in-context learning results and delivering 37-120\%, 8-39\%, and 80-290\% relative gains against the vanilla LM (GPT-3.5), a standard retrieve-then-read pipeline, and a contemporaneous self-ask pipeline, respectively. We release DSP at https://github.com/stanfordnlp/dsp},
  langid = {english},
  organization = {arXiv.org},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ZNSCTKPH/Khattab et al. - 2022 - Demonstrate-Search-Predict Composing retrieval an.pdf}
}

@online{khmaissiaConfidenceGuidedDataAugmentation2023,
  title = {Confidence-{{Guided Data Augmentation}} for {{Improved Semi-Supervised Training}}},
  author = {Khmaissia, Fadoua and Frigui, Hichem},
  date = {2023-02-21},
  eprint = {2209.08174},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2209.08174},
  urldate = {2023-09-15},
  abstract = {We propose a new strategy to improve the accuracy and robustness of image classification. First, we train a baseline CNN model. Then, we identify challenging regions in the feature space by identifying all misclassified samples, and correctly classified samples with low confidence values. These samples are then used to train a Variational AutoEncoder (VAE). Next, the VAE is used to generate synthetic images. Finally, the generated synthetic images are used in conjunction with the original labeled images to train a new model in a semi-supervised fashion. Empirical results on benchmark datasets such as STL10 and CIFAR-100 show that the synthetically generated samples can further diversify the training data, leading to improvement in image classification in comparison with the fully supervised baseline approaches using only the available data.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/264MLE57/Khmaissia y Frigui - 2023 - Confidence-Guided Data Augmentation for Improved S.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/W67GEXUM/2209.html}
}

@inproceedings{kielaDynabenchRethinkingBenchmarking2021,
  title = {Dynabench: {{Rethinking Benchmarking}} in {{NLP}}},
  shorttitle = {Dynabench},
  booktitle = {Proceedings of the 2021 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}},
  author = {Kiela, Douwe and Bartolo, Max and Nie, Yixin and Kaushik, Divyansh and Geiger, Atticus and Wu, Zhengxuan and Vidgen, Bertie and Prasad, Grusha and Singh, Amanpreet and Ringshia, Pratik and Ma, Zhiyi and Thrush, Tristan and Riedel, Sebastian and Waseem, Zeerak and Stenetorp, Pontus and Jia, Robin and Bansal, Mohit and Potts, Christopher and Williams, Adina},
  date = {2021-06},
  pages = {4110--4124},
  publisher = {Association for Computational Linguistics},
  location = {Online},
  doi = {10.18653/v1/2021.naacl-main.324},
  url = {https://aclanthology.org/2021.naacl-main.324},
  urldate = {2022-11-15},
  abstract = {We introduce Dynabench, an open-source platform for dynamic dataset creation and model benchmarking. Dynabench runs in a web browser and supports human-and-model-in-the-loop dataset creation: annotators seek to create examples that a target model will misclassify, but that another person will not. In this paper, we argue that Dynabench addresses a critical need in our community: contemporary models quickly achieve outstanding performance on benchmark tasks but nonetheless fail on simple challenge examples and falter in real-world scenarios. With Dynabench, dataset creation, model development, and model assessment can directly inform each other, leading to more robust and informative benchmarks. We report on four initial NLP tasks, illustrating these concepts and highlighting the promise of the platform, and address potential objections to dynamic benchmarking as a new standard for the field.},
  eventtitle = {{{NAACL-HLT}} 2021},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ZH2WYVE3/Kiela et al. - 2021 - Dynabench Rethinking Benchmarking in NLP.pdf}
}

@online{kimLLMCompilerParallel2023,
  title = {An {{LLM Compiler}} for {{Parallel Function Calling}}},
  author = {Kim, Sehoon and Moon, Suhong and Tabrizi, Ryan and Lee, Nicholas and Mahoney, Michael W. and Keutzer, Kurt and Gholami, Amir},
  date = {2023-12-07},
  eprint = {2312.04511},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2312.04511},
  url = {http://arxiv.org/abs/2312.04511},
  urldate = {2023-12-11},
  abstract = {Large Language Models (LLMs) have shown remarkable results on various complex reasoning benchmarks. The reasoning capabilities of LLMs enable them to execute function calls, using user-provided functions to overcome their inherent limitations, such as knowledge cutoffs, poor arithmetic skills, or lack of access to private data. This development has expanded LLMs' scope to include multi-function calling, where LLMs are equipped with a variety of functions and select the proper functions based on the context. Multi-function calling abilities of LLMs have catalyzed LLM-based software development, allowing them to tackle more complex problems. However, current methods for multi-function calling often require sequential reasoning and acting for each function which can result in high latency, cost, and sometimes inaccurate behavior. To address this, we introduce LLMCompiler, which executes functions in parallel to efficiently orchestrate multi-function calling. Drawing from the principles of classical compilers, LLMCompiler streamlines parallel function calling with three components: (i) an LLM Planner, formulating execution strategies and dependencies; (ii) a Task Fetching Unit, dispatching function calling tasks; and (iii) an Executor, executing these tasks in parallel. LLMCompiler automatically computes an optimized orchestration for the function calls and can be used with open-source models such as LLaMA-2. We have benchmarked LLMCompiler on a range of tasks including cases with non-trivial inter-dependency between function calls, as well as cases that require dynamic replanning based on intermediate results. We observe consistent latency speedup of up to 3.7x, cost savings of up to 6.7x, and accuracy improvement of up to \textasciitilde 9\% as compared to ReAct. Additionally, LLMCompiler achieves up to 1.35x latency gain over OpenAI's recent parallel function calling, while achieving similar accuracy.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/3CNWD485/Kim et al. - 2023 - An LLM Compiler for Parallel Function Calling.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/8HCN6CM7/2312.html}
}

@online{kimLLMCompilerParallel2023a,
  title = {An {{LLM Compiler}} for {{Parallel Function Calling}}},
  author = {Kim, Sehoon and Moon, Suhong and Tabrizi, Ryan and Lee, Nicholas and Mahoney, Michael W. and Keutzer, Kurt and Gholami, Amir},
  date = {2023-12-07},
  eprint = {2312.04511},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2312.04511},
  urldate = {2023-12-30},
  abstract = {Large Language Models (LLMs) have shown remarkable results on various complex reasoning benchmarks. The reasoning capabilities of LLMs enable them to execute function calls, using user-provided functions to overcome their inherent limitations, such as knowledge cutoffs, poor arithmetic skills, or lack of access to private data. This development has expanded LLMs' scope to include multi-function calling, where LLMs are equipped with a variety of functions and select the proper functions based on the context. Multi-function calling abilities of LLMs have catalyzed LLM-based software development, allowing them to tackle more complex problems. However, current methods for multi-function calling often require sequential reasoning and acting for each function which can result in high latency, cost, and sometimes inaccurate behavior. To address this, we introduce LLMCompiler, which executes functions in parallel to efficiently orchestrate multi-function calling. Drawing from the principles of classical compilers, LLMCompiler streamlines parallel function calling with three components: (i) an LLM Planner, formulating execution strategies and dependencies; (ii) a Task Fetching Unit, dispatching function calling tasks; and (iii) an Executor, executing these tasks in parallel. LLMCompiler automatically computes an optimized orchestration for the function calls and can be used with open-source models such as LLaMA-2. We have benchmarked LLMCompiler on a range of tasks including cases with non-trivial inter-dependency between function calls, as well as cases that require dynamic replanning based on intermediate results. We observe consistent latency speedup of up to 3.7x, cost savings of up to 6.7x, and accuracy improvement of up to \textasciitilde 9\% as compared to ReAct. Additionally, LLMCompiler achieves up to 1.35x latency gain over OpenAI's recent parallel function calling, while achieving similar accuracy.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ESA3N2CF/Kim et al. - 2023 - An LLM Compiler for Parallel Function Calling.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/PJHMRRDA/2312.html}
}

@article{kingmaIntroductionVariationalAutoencoders2019,
  title = {An {{Introduction}} to {{Variational Autoencoders}}},
  author = {Kingma, Diederik P. and Welling, Max},
  date = {2019},
  journaltitle = {Foundations and Trends® in Machine Learning},
  shortjournal = {FNT in Machine Learning},
  volume = {12},
  number = {4},
  eprint = {1906.02691},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  pages = {307--392},
  issn = {1935-8237, 1935-8245},
  doi = {10.1561/2200000056},
  url = {http://arxiv.org/abs/1906.02691},
  urldate = {2023-08-28},
  abstract = {Variational autoencoders provide a principled framework for learning deep latent-variable models and corresponding inference models. In this work, we provide an introduction to variational autoencoders and some important extensions.},
  keywords = {va_theory},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/9YRAISJQ/Kingma y Welling - 2019 - An Introduction to Variational Autoencoders.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/L4G7KYP7/1906.html}
}

@inproceedings{kingmaSemisupervisedLearningDeep2014,
  title = {Semi-Supervised {{Learning}} with {{Deep Generative Models}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Kingma, Durk P and Mohamed, Shakir and Jimenez Rezende, Danilo and Welling, Max},
  date = {2014},
  volume = {27},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper_files/paper/2014/hash/d523773c6b194f37b938d340d5d02232-Abstract.html},
  urldate = {2024-01-15},
  abstract = {The ever-increasing size of modern data sets combined with the difficulty of obtaining label information has made semi-supervised learning one of the problems of significant practical importance in modern data analysis. We revisit the approach to semi-supervised learning with generative models and develop new models that allow for effective generalisation from small labelled data sets to large unlabelled ones. Generative approaches have thus far been either inflexible, inefficient or non-scalable. We show that deep generative models and approximate Bayesian inference exploiting recent advances in variational methods can be used to provide significant improvements, making generative approaches highly competitive for semi-supervised learning.},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/YIRXK6XA/Kingma et al. - 2014 - Semi-supervised Learning with Deep Generative Mode.pdf}
}

@article{kirkpatrickOvercomingCatastrophicForgetting2017,
  title = {Overcoming Catastrophic Forgetting in Neural Networks},
  author = {Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A. and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and Hassabis, Demis and Clopath, Claudia and Kumaran, Dharshan and Hadsell, Raia},
  date = {2017-03-28},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proc. Natl. Acad. Sci. U.S.A.},
  volume = {114},
  number = {13},
  eprint = {1612.00796},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  pages = {3521--3526},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1611835114},
  url = {http://arxiv.org/abs/1612.00796},
  urldate = {2023-10-03},
  abstract = {The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence. Neural networks are not, in general, capable of this and it has been widely thought that catastrophic forgetting is an inevitable feature of connectionist models. We show that it is possible to overcome this limitation and train networks that can maintain expertise on tasks which they have not experienced for a long time. Our approach remembers old tasks by selectively slowing down learning on the weights important for those tasks. We demonstrate our approach is scalable and effective by solving a set of classification tasks based on the MNIST hand written digit dataset and by learning several Atari 2600 games sequentially.},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/YIN5CF7B/Kirkpatrick et al. - 2017 - Overcoming catastrophic forgetting in neural netwo.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/NYXDU99H/1612.html}
}

@article{kohaviWrappersFeatureSubset1997,
  title = {Wrappers for Feature Subset Selection},
  author = {Kohavi, Ron and John, George H.},
  date = {1997-12},
  journaltitle = {Artificial Intelligence},
  shortjournal = {Artificial Intelligence},
  volume = {97},
  number = {1-2},
  pages = {273--324},
  issn = {00043702},
  doi = {10.1016/S0004-3702(97)00043-X},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S000437029700043X},
  urldate = {2023-09-05},
  abstract = {In the feature subset selection problem, a learning algorithm is faced with the problem of selecting a relevant subset of features upon which to focus its attention, while ignoring the rest. To achieve the best possible performance with a particular learning algorithm on a particular training set, a feature subset selection method should consider how the algorithm and the training set interact. We explore the relation between optimal feature subset selection and relevance. Our wrapper method searches for an optimal feature subset tailored to a particular algorithm and a domain. We study the strengths and weaknesses of the wrapper approach and show a series of improved designs. We compare the wrapper approach to induction without feature subset selection and to Relief, a filter approach to feature subset selection. Significant improvement in accuracy is achieved for some datasets for the two families of induction algorithms used: decision trees and Naive-Bayes. @ 1997 Elsevier Science B.V.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ABIXGLXW/Kohavi y John - 1997 - Wrappers for feature subset selection.pdf}
}

@article{kohaviWrappersFeatureSubset1997a,
  title = {Wrappers for Feature Subset Selection},
  author = {Kohavi, Ron and John, George H.},
  date = {1997-12},
  journaltitle = {Artificial Intelligence},
  shortjournal = {Artificial Intelligence},
  volume = {97},
  number = {1-2},
  pages = {273--324},
  issn = {00043702},
  doi = {10.1016/S0004-3702(97)00043-X},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S000437029700043X},
  urldate = {2023-09-05},
  abstract = {In the feature subset selection problem, a learning algorithm is faced with the problem of selecting a relevant subset of features upon which to focus its attention, while ignoring the rest. To achieve the best possible performance with a particular learning algorithm on a particular domain, a feature subset selection method should consider how the algorithm and the training data interact. We explore the relation between optimal feature subset selection and relevance. Our wrapper method searches for an optimal feature subset tailored to a particular algorithm and a domain. We study the strengths and weaknesses of the wrapper approach and show improvements over the original design. We compare the wrapper approach to induction without feature subset selection and to Relief, a lter-based approach to feature subset selection. Signi cant improvement in accuracy on real problems is achieved for the two families of induction algorithms used: decision trees and Naive-Bayes.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/TI5HUHZ9/Kohavi y John - 1997 - Wrappers for feature subset selection.pdf}
}

@incollection{kononenkoEstimatingAttributesAnalysis1994,
  title = {Estimating Attributes: {{Analysis}} and Extensions of {{RELIEF}}},
  shorttitle = {Estimating Attributes},
  booktitle = {Machine {{Learning}}: {{ECML-94}}},
  author = {Kononenko, Igor},
  editor = {Bergadano, Francesco and Raedt, Luc},
  editora = {Carbonell, J. G. and Siekmann, J. and Goos, G. and Hartmanis, J.},
  editoratype = {redactor},
  date = {1994},
  volume = {784},
  pages = {171--182},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/3-540-57868-4_57},
  url = {http://link.springer.com/10.1007/3-540-57868-4_57},
  urldate = {2023-09-05},
  abstract = {In the context of machine learning from examples this paper deals with the problem of estimating the quality of attributes with and without dependencies among them. Kira and Rendell (1992a,b) developed an algorithm called RELIEF, which was shown to be very efficient in estimating attributes. Original RELIEF can deal with discrete and continuous attributes and is limited to only two-class problems. In this paper RELIEF is analysed and extended to deal with noisy, incomplete, and multi-class data sets. The extensions are verified on various artificial and one well known real-world problem.},
  isbn = {978-3-540-57868-0 978-3-540-48365-6},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/IW4LVLU7/Kononenko - 1994 - Estimating attributes Analysis and extensions of .pdf}
}

@book{kramerGeneticAlgorithmEssentials2017,
  title = {Genetic {{Algorithm Essentials}}},
  author = {Kramer, Oliver},
  date = {2017},
  series = {Studies in {{Computational Intelligence}}},
  volume = {679},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-52156-5},
  url = {http://link.springer.com/10.1007/978-3-319-52156-5},
  urldate = {2023-09-05},
  isbn = {978-3-319-52155-8 978-3-319-52156-5},
  langid = {english},
  keywords = {ga_libros},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/KEWZBNND/Kramer - 2017 - Genetic Algorithm Essentials.pdf}
}

@online{kreuzbergerMachineLearningOperations2022,
  title = {Machine {{Learning Operations}} ({{MLOps}}): {{Overview}}, {{Definition}}, and {{Architecture}}},
  shorttitle = {Machine {{Learning Operations}} ({{MLOps}})},
  author = {Kreuzberger, Dominik and Kühl, Niklas and Hirschl, Sebastian},
  date = {2022-05-14},
  eprint = {2205.02302},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2205.02302},
  urldate = {2023-07-11},
  abstract = {The final goal of all industrial machine learning (ML) projects is to develop ML products and rapidly bring them into production. However, it is highly challenging to automate and operationalize ML products and thus many ML endeavors fail to deliver on their expectations. The paradigm of Machine Learning Operations (MLOps) addresses this issue. MLOps includes several aspects, such as best practices, sets of concepts, and development culture. However, MLOps is still a vague term and its consequences for researchers and professionals are ambiguous. To address this gap, we conduct mixed-method research, including a literature review, a tool review, and expert interviews. As a result of these investigations, we provide an aggregated overview of the necessary principles, components, and roles, as well as the associated architecture and workflows. Furthermore, we furnish a definition of MLOps and highlight open challenges in the field. Finally, this work provides guidance for ML researchers and practitioners who want to automate and operate their ML products with a designated set of technologies.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/5U9W7CLX/Kreuzberger et al. - 2022 - Machine Learning Operations (MLOps) Overview, Def.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/WEGQL26T/2205.html}
}

@online{kwarciakDeepGenerativeNetworks2023,
  title = {Deep {{Generative Networks}} for {{Heterogeneous Augmentation}} of {{Cranial Defects}}},
  author = {Kwarciak, Kamil and Wodzinski, Marek},
  date = {2023-08-09},
  eprint = {2308.04883},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  url = {http://arxiv.org/abs/2308.04883},
  urldate = {2023-09-15},
  abstract = {The design of personalized cranial implants is a challenging and tremendous task that has become a hot topic in terms of process automation with the use of deep learning techniques. The main challenge is associated with the high diversity of possible cranial defects. The lack of appropriate data sources negatively influences the data-driven nature of deep learning algorithms. Hence, one of the possible solutions to overcome this problem is to rely on synthetic data. In this work, we propose three volumetric variations of deep generative models to augment the dataset by generating synthetic skulls, i.e. Wasserstein Generative Adversarial Network with Gradient Penalty (WGAN-GP), WGAN-GP hybrid with Variational Autoencoder pretraining (VAE/WGAN-GP) and Introspective Variational Autoencoder (IntroVAE). We show that it is possible to generate dozens of thousands of defective skulls with compatible defects that achieve a trade-off between defect heterogeneity and the realistic shape of the skull. We evaluate obtained synthetic data quantitatively by defect segmentation with the use of V-Net and qualitatively by their latent space exploration. We show that the synthetically generated skulls highly improve the segmentation process compared to using only the original unaugmented data. The generated skulls may improve the automatic design of personalized cranial implants for real medical cases.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/AYXTG4PX/Kwarciak y Wodzinski - 2023 - Deep Generative Networks for Heterogeneous Augment.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/IBS5UTFE/2308.html}
}

@online{labonneFinetuneMistral7bModel2024,
  title = {Fine-Tune a {{Mistral-7b}} Model with {{Direct Preference Optimization}}},
  author = {Labonne, Maxime},
  date = {2024-01-07T00:09:13},
  url = {https://towardsdatascience.com/fine-tune-a-mistral-7b-model-with-direct-preference-optimization-708042745aac},
  urldate = {2024-04-08},
  abstract = {Boost the performance of your supervised fine-tuned models},
  langid = {english},
  organization = {Medium},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/HZCG6BRB/fine-tune-a-mistral-7b-model-with-direct-preference-optimization-708042745aac.html}
}

@online{labrakBioMistralCollectionOpenSource2024,
  title = {{{BioMistral}}: {{A Collection}} of {{Open-Source Pretrained Large Language Models}} for {{Medical Domains}}},
  shorttitle = {{{BioMistral}}},
  author = {Labrak, Yanis and Bazoge, Adrien and Morin, Emmanuel and Gourraud, Pierre-Antoine and Rouvier, Mickael and Dufour, Richard},
  date = {2024-02-15},
  eprint = {2402.10373},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2402.10373},
  url = {http://arxiv.org/abs/2402.10373},
  urldate = {2024-04-09},
  abstract = {Large Language Models (LLMs) have demonstrated remarkable versatility in recent years, offering potential applications across specialized domains such as healthcare and medicine. Despite the availability of various open-source LLMs tailored for health contexts, adapting general-purpose LLMs to the medical domain presents significant challenges. In this paper, we introduce BioMistral, an open-source LLM tailored for the biomedical domain, utilizing Mistral as its foundation model and further pre-trained on PubMed Central. We conduct a comprehensive evaluation of BioMistral on a benchmark comprising 10 established medical question-answering (QA) tasks in English. We also explore lightweight models obtained through quantization and model merging approaches. Our results demonstrate BioMistral's superior performance compared to existing open-source medical models and its competitive edge against proprietary counterparts. Finally, to address the limited availability of data beyond English and to assess the multilingual generalization of medical LLMs, we automatically translated and evaluated this benchmark into 7 other languages. This marks the first large-scale multilingual evaluation of LLMs in the medical domain. Datasets, multilingual evaluation benchmarks, scripts, and all the models obtained during our experiments are freely released.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/PQZW65Z7/Labrak et al. - 2024 - BioMistral A Collection of Open-Source Pretrained.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/C5AP2B25/2402.html}
}

@online{lampleNeuralArchitecturesNamed2016,
  title = {Neural {{Architectures}} for {{Named Entity Recognition}}},
  author = {Lample, Guillaume and Ballesteros, Miguel and Subramanian, Sandeep and Kawakami, Kazuya and Dyer, Chris},
  date = {2016-04-07},
  eprint = {1603.01360},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1603.01360},
  urldate = {2022-11-19},
  abstract = {State-of-the-art named entity recognition systems rely heavily on hand-crafted features and domain-specific knowledge in order to learn effectively from the small, supervised training corpora that are available. In this paper, we introduce two new neural architectures---one based on bidirectional LSTMs and conditional random fields, and the other that constructs and labels segments using a transition-based approach inspired by shift-reduce parsers. Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora. Our models obtain state-of-the-art performance in NER in four languages without resorting to any language-specific knowledge or resources such as gazetteers.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/KQYE7YLJ/Lample et al. - 2016 - Neural Architectures for Named Entity Recognition.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/EX9U9JEY/1603.html}
}

@online{lampleNeuralArchitecturesNamed2016a,
  title = {Neural {{Architectures}} for {{Named Entity Recognition}}},
  author = {Lample, Guillaume and Ballesteros, Miguel and Subramanian, Sandeep and Kawakami, Kazuya and Dyer, Chris},
  date = {2016-04-07},
  eprint = {1603.01360},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1603.01360},
  urldate = {2022-11-20},
  abstract = {State-of-the-art named entity recognition systems rely heavily on hand-crafted features and domain-specific knowledge in order to learn effectively from the small, supervised training corpora that are available. In this paper, we introduce two new neural architectures---one based on bidirectional LSTMs and conditional random fields, and the other that constructs and labels segments using a transition-based approach inspired by shift-reduce parsers. Our models rely on two sources of information about words: character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora. Our models obtain state-of-the-art performance in NER in four languages without resorting to any language-specific knowledge or resources such as gazetteers.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/DV2QLDBC/Lample et al. - 2016 - Neural Architectures for Named Entity Recognition.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/2KMTK3FN/1603.html}
}

@article{langeroberttjarkoDiscoveringEvolutionStrategies2022,
  title = {Discovering {{Evolution Strategies}} via {{Meta-Black-Box Optimization}}},
  author = {{Lange, Robert Tjarko} and {Schaul, Tom} and {Chen, Yutian} and {Zahavy, Tom} and {Dallibard, Valentin} and {Lu, Chris} and {Singh, Satinder} and {Flennerhag, Sebastian}},
  date = {2022-11-21},
  journaltitle = {Cornell University - arXiv},
  doi = {10.48550/arxiv.2211.11260},
  abstract = {Optimizing functions without access to gradients is the remit of black-box methods such as evolution strategies. While highly general, their learning dynamics are often times heuristic and inflexible - exactly the limitations that meta-learning can address. Hence, we propose to discover effective update rules for evolution strategies via meta-learning. Concretely, our approach employs a search strategy parametrized by a self-attention-based architecture, which guarantees the update rule is invariant to the ordering of the candidate solutions. We show that meta-evolving this system on a small set of representative low-dimensional analytic optimization problems is sufficient to discover new evolution strategies capable of generalizing to unseen optimization problems, population sizes and optimization horizons. Furthermore, the same learned evolution strategy can outperform established neuroevolution baselines on supervised and continuous control tasks. As additional contributions, we ablate the individual neural network components of our method; reverse engineer the learned strategy into an explicit heuristic form, which remains highly competitive; and show that it is possible to self-referentially train an evolution strategy from scratch, with the learned update rule used to drive the outer meta-learning loop.},
  annotation = {ARXIV\_ID: 2211.11260\\
MAG ID: 4310266070\\
S2ID: dae69e513a0a5c4f10c11bb56e4e3fddedff714e}
}

@online{latifVariationalAutoencodersLearning2020,
  title = {Variational {{Autoencoders}} for {{Learning Latent Representations}} of {{Speech Emotion}}: {{A Preliminary Study}}},
  shorttitle = {Variational {{Autoencoders}} for {{Learning Latent Representations}} of {{Speech Emotion}}},
  author = {Latif, Siddique and Rana, Rajib and Qadir, Junaid and Epps, Julien},
  date = {2020-07-27},
  eprint = {1712.08708},
  eprinttype = {arxiv},
  eprintclass = {cs, eess, stat},
  doi = {10.48550/arXiv.1712.08708},
  url = {http://arxiv.org/abs/1712.08708},
  urldate = {2023-09-29},
  abstract = {Learning the latent representation of data in unsupervised fashion is a very interesting process that provides relevant features for enhancing the performance of a classifier. For speech emotion recognition tasks, generating effective features is crucial. Currently, handcrafted features are mostly used for speech emotion recognition, however, features learned automatically using deep learning have shown strong success in many problems, especially in image processing. In particular, deep generative models such as Variational Autoencoders (VAEs) have gained enormous success for generating features for natural images. Inspired by this, we propose VAEs for deriving the latent representation of speech signals and use this representation to classify emotions. To the best of our knowledge, we are the first to propose VAEs for speech emotion classification. Evaluations on the IEMOCAP dataset demonstrate that features learned by VAEs can produce state-of-the-art results for speech emotion classification.},
  pubstate = {preprint},
  keywords = {estado_arte},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ULWHI2X5/Latif et al. - 2020 - Variational Autoencoders for Learning Latent Repre.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/247WFICQ/1712.html}
}

@article{lecunGradientbasedLearningApplied1998,
  title = {Gradient-Based Learning Applied to Document Recognition},
  author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  date = {1998-11},
  journaltitle = {Proceedings of the IEEE},
  volume = {86},
  number = {11},
  pages = {2278--2324},
  issn = {1558-2256},
  doi = {10.1109/5.726791},
  url = {https://ieeexplore.ieee.org/document/726791},
  urldate = {2023-10-03},
  abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.},
  eventtitle = {Proceedings of the {{IEEE}}}
}

@article{lecunGradientBasedLearningApplied1998,
  title = {Gradient-{{Based Learning Applied}} to {{Document Recognition}}},
  author = {Lecun, Yann},
  date = {1998},
  journaltitle = {PROCEEDINGS OF THE IEEE},
  volume = {86},
  number = {11},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/7JCY6F5S/Lecun - 1998 - Gradient-Based Learning Applied to Document Recogn.pdf}
}

@article{leeAndroidMalwareDetection2021,
  title = {Android {{Malware Detection Using Machine Learning}} with {{Feature Selection Based}} on the {{Genetic Algorithm}}},
  author = {Lee, Jaehyeong and Jang, Hyuk and Ha, Sungmin and Yoon, Yourim},
  date = {2021-11-05},
  journaltitle = {Mathematics},
  shortjournal = {Mathematics},
  volume = {9},
  number = {21},
  pages = {2813},
  issn = {2227-7390},
  doi = {10.3390/math9212813},
  url = {https://www.mdpi.com/2227-7390/9/21/2813},
  urldate = {2023-09-28},
  abstract = {Since the discovery that machine learning can be used to effectively detect Android malware, many studies on machine learning-based malware detection techniques have been conducted. Several methods based on feature selection, particularly genetic algorithms, have been proposed to increase the performance and reduce costs. However, because they have yet to be compared with other methods and their many features have not been sufficiently verified, such methods have certain limitations. This study investigates whether genetic algorithm-based feature selection helps Android malware detection. We applied nine machine learning algorithms with genetic algorithmbased feature selection for 1104 static features through 5000 benign applications and 2500 malwares included in the Andro-AutoPsy dataset. Comparative experimental results show that the genetic algorithm performed better than the information gain-based method, which is generally used as a feature selection method. Moreover, machine learning using the proposed genetic algorithm-based feature selection has an absolute advantage in terms of time compared to machine learning without feature selection. The results indicate that incorporating genetic algorithms into Android malware detection is a valuable approach. Furthermore, to improve malware detection performance, it is useful to apply genetic algorithm-based feature selection to machine learning.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/5XYJE2FL/Lee et al. - 2021 - Android Malware Detection Using Machine Learning w.pdf}
}

@article{leeBioBERTPretrainedBiomedical2019,
  title = {{{BioBERT}}: A Pre-Trained Biomedical Language Representation Model for Biomedical Text Mining},
  shorttitle = {{{BioBERT}}},
  author = {Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
  editor = {Wren, Jonathan},
  date = {2019-09-10},
  journaltitle = {Bioinformatics},
  pages = {btz682},
  issn = {1367-4803, 1460-2059},
  doi = {10.1093/bioinformatics/btz682},
  url = {https://academic.oup.com/bioinformatics/advance-article/doi/10.1093/bioinformatics/btz682/5566506},
  urldate = {2022-11-04},
  abstract = {Motivation: Biomedical text mining is becoming increasingly important as the number of biomedical documents rapidly grows. With the progress in natural language processing (NLP), extracting valuable information from biomedical literature has gained popularity among researchers, and deep learning has boosted the development of effective biomedical text mining models. However, directly applying the advancements in NLP to biomedical text mining often yields unsatisfactory results due to a word distribution shift from general domain corpora to biomedical corpora. In this article, we investigate how the recently introduced pre-trained language model BERT can be adapted for biomedical corpora.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/8WGL72QZ/Lee et al. - 2019 - BioBERT a pre-trained biomedical language represe.pdf}
}

@online{leelarathnaEnhancingRepresentationLearning2023,
  title = {Enhancing {{Representation Learning}} on {{High-Dimensional}}, {{Small-Size Tabular Data}}: {{A Divide}} and {{Conquer Method}} with {{Ensembled VAEs}}},
  shorttitle = {Enhancing {{Representation Learning}} on {{High-Dimensional}}, {{Small-Size Tabular Data}}},
  author = {Leelarathna, Navindu and Margeloiu, Andrei and Jamnik, Mateja and Simidjievski, Nikola},
  date = {2023-06-27},
  eprint = {2306.15661},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2306.15661},
  urldate = {2023-09-15},
  abstract = {Variational Autoencoders and their many variants have displayed impressive ability to perform dimensionality reduction, often achieving state-of-the-art performance. Many current methods however, struggle to learn good representations in High Dimensional, Low Sample Size (HDLSS) tasks, which is an inherently challenging setting. We address this challenge by using an ensemble of lightweight VAEs to learn posteriors over subsets of the feature-space, which get aggregated into a joint posterior in a novel divide-and-conquer approach. Specifically, we present an alternative factorisation of the joint posterior that induces a form of implicit data augmentation that yields greater sample efficiency. Through a series of experiments on eight real-world datasets, we show that our method learns better latent representations in HDLSS settings, which leads to higher accuracy in a downstream classification task. Furthermore, we verify that our approach has a positive effect on disentanglement and achieves a lower estimated Total Correlation on learnt representations. Finally, we show that our approach is robust to partial features at inference, exhibiting little performance degradation even with most features missing.},
  pubstate = {preprint},
  keywords = {fs_desafios},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/VT3T2BCI/Leelarathna et al. - 2023 - Enhancing Representation Learning on High-Dimensio.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/C5DJ3WUI/2306.html}
}

@online{leiAnsweringNumericalReasoning2022,
  title = {Answering {{Numerical Reasoning Questions}} in {{Table-Text Hybrid Contents}} with {{Graph-based Encoder}} and {{Tree-based Decoder}}},
  author = {Lei, Fangyu and He, Shizhu and Li, Xiang and Zhao, Jun and Liu, Kang},
  date = {2022-10-20},
  eprint = {2209.07692},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2209.07692},
  url = {http://arxiv.org/abs/2209.07692},
  urldate = {2023-12-24},
  abstract = {In the real-world question answering scenarios, hybrid form combining both tabular and textual contents has attracted more and more attention, among which numerical reasoning problem is one of the most typical and challenging problems. Existing methods usually adopt encoder-decoder framework to represent hybrid contents and generate answers. However, it can not capture the rich relationship among numerical value, table schema, and text information on the encoder side. The decoder uses a simple predefined operator classifier which is not flexible enough to handle numerical reasoning processes with diverse expressions. To address these problems, this paper proposes a \textbackslash textbf\{Re\}lational \textbackslash textbf\{G\}raph enhanced \textbackslash textbf\{H\}ybrid table-text \textbackslash textbf\{N\}umerical reasoning model with \textbackslash textbf\{T\}ree decoder (\textbackslash textbf\{RegHNT\}). It models the numerical question answering over table-text hybrid contents as an expression tree generation task. Moreover, we propose a novel relational graph modeling method, which models alignment between questions, tables, and paragraphs. We validated our model on the publicly available table-text hybrid QA benchmark (TAT-QA). The proposed RegHNT significantly outperform the baseline model and achieve state-of-the-art results. We openly released the source code and data at https://github.com/lfy79001/RegHNT (2022-05-05).},
  pubstate = {preprint},
  keywords = {QA_hybrid_content},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/HEYS6U2X/Lei et al. - 2022 - Answering Numerical Reasoning Questions in Table-T.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/HVZ47C7T/2209.html}
}

@inproceedings{leitnerFineGrainedNamedEntity2019,
  title = {Fine-{{Grained Named Entity Recognition}} in {{Legal Documents}}},
  booktitle = {Semantic {{Systems}}. {{The Power}} of {{AI}} and {{Knowledge Graphs}}},
  author = {Leitner, Elena and Rehm, Georg and Moreno-Schneider, Julian},
  editor = {Acosta, Maribel and Cudré-Mauroux, Philippe and Maleshkova, Maria and Pellegrini, Tassilo and Sack, Harald and Sure-Vetter, York},
  date = {2019-01-01},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {272--287},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-33220-4_20},
  abstract = {This paper describes an approach at Named Entity Recognition (NER) in German language documents from the legal domain. For this purpose, a dataset consisting of German court decisions was developed. The source texts were manually annotated with 19 semantic classes: person, judge, lawyer, country, city, street, landscape, organization, company, institution, court, brand, law, ordinance, European legal norm, regulation, contract, court decision, and legal literature. The dataset consists of approx.~67,000 sentences and contains 54,000 annotated entities. The 19 fine-grained classes were automatically generalised to seven more coarse-grained classes (person, location, organization, legal norm, case-by-case regulation, court decision, and legal literature). Thus, the dataset includes two annotation variants, i.e., coarse- and fine-grained. For the task of NER, Conditional Random Fields (CRFs) and bidirectional Long-Short Term Memory Networks (BiLSTMs) were applied to the dataset as state of the art models. Three different models were developed for each of these two model families and tested with the coarse- and fine-grained annotations. The BiLSTM models achieve the best performance with an 95.46 F\$\$\_1\$\$score for the fine-grained classes and 95.95 for the coarse-grained ones. The CRF models reach a maximum of 93.23 for the fine-grained classes and 93.22 for the coarse-grained ones. The work presented in this paper was carried out under the umbrella of the European project LYNX that develops a semantic platform that enables the development of various document processing and analysis applications for the legal domain.},
  isbn = {978-3-030-33220-4},
  langid = {english},
  keywords = {BiLSTM,CRF,Curation technologies,Language technology,Legal processing,Legal technologies,LT,Named Entity Recognition,Natural Language Processing,NER,NLP},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/QD7EG7UY/Leitner et al. - 2019 - Fine-Grained Named Entity Recognition in Legal Doc.pdf}
}

@online{LeoLMIgnitingGermanLanguage,
  title = {{{LeoLM}}: {{Igniting German-Language LLM Research}} | {{LAION}}},
  shorttitle = {{{LeoLM}}},
  url = {https://laion.ai/blog/leo-lm},
  urldate = {2024-04-08},
  abstract = {{$<$}p{$>$}We proudly introduce LeoLM ({$<$}strong{$>$}L{$<$}/strong{$>$}inguistically {$<$}strong{$>$}E{$<$}/strong{$>$}nhanced {$<$}strong{$>$}O{$<$}/strong{$>$}pen {$<$}strong{$>$}L{$<$}/strong{$>$}anguage {$<$}strong{$>$}M{$<$}/strong{$>$}od...},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/FH46ARGI/leo-lm.html}
}

@online{LessonsLearnedLanguage,
  title = {Lessons Learned on Language Model Safety and Misuse},
  url = {https://openai.com/research/language-model-safety-and-misuse},
  urldate = {2023-05-30},
  abstract = {We describe our latest thinking in the hope of helping other AI developers address safety and misuse of deployed~models.},
  langid = {american},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/UW2KT5VX/language-model-safety-and-misuse.html}
}

@online{liLargeLanguageModels2023,
  title = {Large {{Language Models}} in {{Finance}}: {{A Survey}}},
  shorttitle = {Large {{Language Models}} in {{Finance}}},
  author = {Li, Yinheng and Wang, Shaofei and Ding, Han and Chen, Hang},
  date = {2023-09-28},
  eprint = {2311.10723},
  eprinttype = {arxiv},
  eprintclass = {cs, q-fin},
  doi = {10.48550/arXiv.2311.10723},
  url = {http://arxiv.org/abs/2311.10723},
  urldate = {2023-12-13},
  abstract = {Recent advances in large language models (LLMs) have opened new possibilities for artificial intelligence applications in finance. In this paper, we provide a practical survey focused on two key aspects of utilizing LLMs for financial tasks: existing solutions and guidance for adoption. First, we review current approaches employing LLMs in finance, including leveraging pretrained models via zero-shot or few-shot learning, fine-tuning on domain-specific data, and training custom LLMs from scratch. We summarize key models and evaluate their performance improvements on financial natural language processing tasks. Second, we propose a decision framework to guide financial professionals in selecting the appropriate LLM solution based on their use case constraints around data, compute, and performance needs. The framework provides a pathway from lightweight experimentation to heavy investment in customized LLMs. Lastly, we discuss limitations and challenges around leveraging LLMs in financial applications. Overall, this survey aims to synthesize the state-of-the-art and provide a roadmap for responsibly applying LLMs to advance financial AI.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/R7WRNBNM/Li et al. - 2023 - Large Language Models in Finance A Survey.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/GN8AEPU9/2311.html}
}

@online{liMoreAgentsAll2024,
  title = {More {{Agents Is All You Need}}},
  author = {Li, Junyou and Zhang, Qin and Yu, Yangbin and Fu, Qiang and Ye, Deheng},
  date = {2024-02-03},
  eprint = {2402.05120},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2402.05120},
  urldate = {2024-04-08},
  abstract = {We find that, simply via a sampling-and-voting method, the performance of large language models (LLMs) scales with the number of agents instantiated. Also, this method is orthogonal to existing complicated methods to further enhance LLMs, while the degree of enhancement is correlated to the task difficulty. We conduct comprehensive experiments on a wide range of LLM benchmarks to verify the presence of our finding, and to study the properties that can facilitate its occurrence. Our code is publicly available at: Git.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/FXMYR2N2/Li et al. - 2024 - More Agents Is All You Need.pdf}
}

@online{liMoreAgentsAll2024a,
  title = {More {{Agents Is All You Need}}},
  author = {Li, Junyou and Zhang, Qin and Yu, Yangbin and Fu, Qiang and Ye, Deheng},
  date = {2024-02-03},
  eprint = {2402.05120},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2402.05120},
  urldate = {2024-04-08},
  abstract = {We find that, simply via a sampling-and-voting method, the performance of large language models (LLMs) scales with the number of agents instantiated. Also, this method is orthogonal to existing complicated methods to further enhance LLMs, while the degree of enhancement is correlated to the task difficulty. We conduct comprehensive experiments on a wide range of LLM benchmarks to verify the presence of our finding, and to study the properties that can facilitate its occurrence. Our code is publicly available at: Git.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/FZYWAVA2/Li et al. - 2024 - More Agents Is All You Need.pdf}
}

@online{liMultimodalFoundationModels2023,
  title = {Multimodal {{Foundation Models}}: {{From Specialists}} to {{General-Purpose Assistants}}},
  shorttitle = {Multimodal {{Foundation Models}}},
  author = {Li, Chunyuan and Gan, Zhe and Yang, Zhengyuan and Yang, Jianwei and Li, Linjie and Wang, Lijuan and Gao, Jianfeng},
  date = {2023-09-18},
  eprint = {2309.10020},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2309.10020},
  urldate = {2024-03-20},
  abstract = {This paper presents a comprehensive survey of the taxonomy and evolution of multimodal foundation models that demonstrate vision and vision-language capabilities, focusing on the transition from specialist models to general-purpose assistants. The research landscape encompasses five core topics, categorized into two classes. (i) We start with a survey of well-established research areas: multimodal foundation models pre-trained for specific purposes, including two topics -- methods of learning vision backbones for visual understanding and text-to-image generation. (ii) Then, we present recent advances in exploratory, open research areas: multimodal foundation models that aim to play the role of general-purpose assistants, including three topics -- unified vision models inspired by large language models (LLMs), end-to-end training of multimodal LLMs, and chaining multimodal tools with LLMs. The target audiences of the paper are researchers, graduate students, and professionals in computer vision and vision-language multimodal communities who are eager to learn the basics and recent advances in multimodal foundation models.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/3YIFM25V/Li et al. - 2023 - Multimodal Foundation Models From Specialists to .pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/RPPDW6VT/2309.html}
}

@online{linHowTrainYour2023,
  title = {How to {{Train Your DRAGON}}: {{Diverse Augmentation Towards Generalizable Dense Retrieval}}},
  shorttitle = {How to {{Train Your DRAGON}}},
  author = {Lin, Sheng-Chieh and Asai, Akari and Li, Minghan and Oguz, Barlas and Lin, Jimmy and Mehdad, Yashar and Yih, Wen-tau and Chen, Xilun},
  date = {2023-02-14},
  eprint = {2302.07452},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2302.07452},
  url = {http://arxiv.org/abs/2302.07452},
  urldate = {2023-11-16},
  abstract = {Various techniques have been developed in recent years to improve dense retrieval (DR), such as unsupervised contrastive learning and pseudo-query generation. Existing DRs, however, often suffer from effectiveness tradeoffs between supervised and zero-shot retrieval, which some argue was due to the limited model capacity. We contradict this hypothesis and show that a generalizable DR can be trained to achieve high accuracy in both supervised and zero-shot retrieval without increasing model size. In particular, we systematically examine the contrastive learning of DRs, under the framework of Data Augmentation (DA). Our study shows that common DA practices such as query augmentation with generative models and pseudo-relevance label creation using a cross-encoder, are often inefficient and sub-optimal. We hence propose a new DA approach with diverse queries and sources of supervision to progressively train a generalizable DR. As a result, DRAGON, our dense retriever trained with diverse augmentation, is the first BERT-base-sized DR to achieve state-of-the-art effectiveness in both supervised and zero-shot evaluations and even competes with models using more complex late interaction (ColBERTv2 and SPLADE++).},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/IJK2ZPJL/Lin et al. - 2023 - How to Train Your DRAGON Diverse Augmentation Tow.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/H5FYUXUD/2302.html}
}

@online{linRADITRetrievalAugmentedDual2023,
  title = {{{RA-DIT}}: {{Retrieval-Augmented Dual Instruction Tuning}}},
  shorttitle = {{{RA-DIT}}},
  author = {Lin, Xi Victoria and Chen, Xilun and Chen, Mingda and Shi, Weijia and Lomeli, Maria and James, Rich and Rodriguez, Pedro and Kahn, Jacob and Szilvasy, Gergely and Lewis, Mike and Zettlemoyer, Luke and Yih, Scott},
  date = {2023-11-05},
  eprint = {2310.01352},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2310.01352},
  url = {http://arxiv.org/abs/2310.01352},
  urldate = {2023-11-11},
  abstract = {Retrieval-augmented language models (RALMs) improve performance by accessing long-tail and up-to-date knowledge from external data stores, but are challenging to build. Existing approaches require either expensive retrieval-specific modifications to LM pre-training or use post-hoc integration of the data store that leads to suboptimal performance. We introduce Retrieval-Augmented Dual Instruction Tuning (RA-DIT), a lightweight fine-tuning methodology that provides a third option by retrofitting any LLM with retrieval capabilities. Our approach operates in two distinct fine-tuning steps: (1) one updates a pre-trained LM to better use retrieved information, while (2) the other updates the retriever to return more relevant results, as preferred by the LM. By fine-tuning over tasks that require both knowledge utilization and contextual awareness, we demonstrate that each stage yields significant performance improvements, and using both leads to additional gains. Our best model, RA-DIT 65B, achieves state-of-the-art performance across a range of knowledge-intensive zero- and few-shot learning benchmarks, significantly outperforming existing in-context RALM approaches by up to +8.9\% in 0-shot setting and +1.4\% in 5-shot setting on average.},
  pubstate = {preprint},
  keywords = {RAG},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/6LJW6EFB/Lin et al. - 2023 - RA-DIT Retrieval-Augmented Dual Instruction Tunin.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/Z85DGANA/2310.html}
}

@online{liSurveyDeepLearning2020,
  title = {A {{Survey}} on {{Deep Learning}} for {{Named Entity Recognition}}},
  author = {Li, Jing and Sun, Aixin and Han, Jianglei and Li, Chenliang},
  date = {2020-03-18},
  eprint = {1812.09449},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1812.09449},
  urldate = {2022-11-09},
  abstract = {Named entity recognition (NER) is the task to identify mentions of rigid designators from text belonging to predefined semantic types such as person, location, organization etc. NER always serves as the foundation for many natural language applications such as question answering, text summarization, and machine translation. Early NER systems got a huge success in achieving good performance with the cost of human engineering in designing domain-specific features and rules. In recent years, deep learning, empowered by continuous real-valued vector representations and semantic composition through nonlinear processing, has been employed in NER systems, yielding stat-of-the-art performance. In this paper, we provide a comprehensive review on existing deep learning techniques for NER. We first introduce NER resources, including tagged NER corpora and off-the-shelf NER tools. Then, we systematically categorize existing works based on a taxonomy along three axes: distributed representations for input, context encoder, and tag decoder. Next, we survey the most representative methods for recent applied techniques of deep learning in new NER problem settings and applications. Finally, we present readers with the challenges faced by NER systems and outline future directions in this area.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/RR4DBILH/Li et al. - 2020 - A Survey on Deep Learning for Named Entity Recogni.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/2UI9BSV7/1812.html}
}

@online{liuChatQABuildingGPT42024,
  title = {{{ChatQA}}: {{Building GPT-4 Level Conversational QA Models}}},
  shorttitle = {{{ChatQA}}},
  author = {Liu, Zihan and Ping, Wei and Roy, Rajarshi and Xu, Peng and Shoeybi, Mohammad and Catanzaro, Bryan},
  date = {2024-01-18},
  eprint = {2401.10225},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2401.10225},
  url = {http://arxiv.org/abs/2401.10225},
  urldate = {2024-01-22},
  abstract = {In this work, we introduce ChatQA, a family of conversational question answering (QA) models, that obtain GPT-4 level accuracies. Specifically, we propose a two-stage instruction tuning method that can significantly improve the zero-shot conversational QA results from large language models (LLMs). To handle retrieval in conversational QA, we fine-tune a dense retriever on a multi-turn QA dataset, which provides comparable results to using the state-of-the-art query rewriting model while largely reducing deployment cost. Notably, our ChatQA-70B can outperform GPT-4 in terms of average score on 10 conversational QA datasets (54.14 vs. 53.90), without relying on any synthetic data from OpenAI GPT models.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Information Retrieval,Computer Science - Machine Learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/K4SSXZ78/Liu et al. - 2024 - ChatQA Building GPT-4 Level Conversational QA Mod.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ULIUF2GH/2401.html}
}

@online{liuChipNeMoDomainAdaptedLLMs2023,
  title = {{{ChipNeMo}}: {{Domain-Adapted LLMs}} for {{Chip Design}}},
  shorttitle = {{{ChipNeMo}}},
  author = {Liu, Mingjie and Ene, Teodor-Dumitru and Kirby, Robert and Cheng, Chris and Pinckney, Nathaniel and Liang, Rongjian and Alben, Jonah and Anand, Himyanshu and Banerjee, Sanmitra and Bayraktaroglu, Ismet and Bhaskaran, Bonita and Catanzaro, Bryan and Chaudhuri, Arjun and Clay, Sharon and Dally, Bill and Dang, Laura and Deshpande, Parikshit and Dhodhi, Siddhanth and Halepete, Sameer and Hill, Eric and Hu, Jiashang and Jain, Sumit and Khailany, Brucek and Kunal, Kishor and Li, Xiaowei and Liu, Hao and Oberman, Stuart and Omar, Sujeet and Pratty, Sreedhar and Raiman, Jonathan and Sarkar, Ambar and Shao, Zhengjiang and Sun, Hanfei and Suthar, Pratik P. and Tej, Varun and Xu, Kaizhe and Ren, Haoxing},
  date = {2023-11-13},
  eprint = {2311.00176},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2311.00176},
  url = {http://arxiv.org/abs/2311.00176},
  urldate = {2023-11-15},
  abstract = {ChipNeMo aims to explore the applications of large language models (LLMs) for industrial chip design. Instead of directly deploying off-the-shelf commercial or open-source LLMs, we instead adopt the following domain adaptation techniques: custom tokenizers, domain-adaptive continued pretraining, supervised fine-tuning (SFT) with domain-specific instructions, and domain-adapted retrieval models. We evaluate these methods on three selected LLM applications for chip design: an engineering assistant chatbot, EDA script generation, and bug summarization and analysis. Our results show that these domain adaptation techniques enable significant LLM performance improvements over general-purpose base models across the three evaluated applications, enabling up to 5x model size reduction with similar or better performance on a range of design tasks. Our findings also indicate that there's still room for improvement between our current results and ideal outcomes. We believe that further investigation of domain-adapted LLM approaches will help close this gap in the future.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/I8QX5QZQ/Liu et al. - 2023 - ChipNeMo Domain-Adapted LLMs for Chip Design.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/BWX8EC6P/2311.html}
}

@inproceedings{liuConstrainedGraphVariational2018,
  title = {Constrained {{Graph Variational Autoencoders}} for {{Molecule Design}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Liu, Qi and Allamanis, Miltiadis and Brockschmidt, Marc and Gaunt, Alexander},
  date = {2018},
  volume = {31},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper_files/paper/2018/hash/b8a03c5c15fcfa8dae0b03351eb1742f-Abstract.html},
  urldate = {2023-09-29},
  abstract = {Graphs are ubiquitous data structures for representing interactions between entities. With an emphasis on applications in chemistry, we explore the task of learning to generate graphs that conform to a distribution observed in training data. We propose a variational autoencoder model in which both encoder and decoder are graph-structured. Our decoder assumes a sequential ordering of graph extension steps and we discuss and analyze design choices that mitigate the potential downsides of this linearization. Experiments compare our approach with a wide range of baselines on the molecule generation task and show that our method is successful at matching the statistics of the original dataset on semantically important metrics. Furthermore, we show that by using appropriate shaping of the latent space, our model allows us to design molecules that are (locally) optimal in desired properties.},
  keywords = {estado_arte},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/INSBVLH3/Liu et al. - 2018 - Constrained Graph Variational Autoencoders for Mol.pdf}
}

@online{liuDeLLMaFrameworkDecision2024,
  title = {{{DeLLMa}}: {{A Framework}} for {{Decision Making Under Uncertainty}} with {{Large Language Models}}},
  shorttitle = {{{DeLLMa}}},
  author = {Liu, Ollie and Fu, Deqing and Yogatama, Dani and Neiswanger, Willie},
  date = {2024-02-04},
  eprint = {2402.02392},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2402.02392},
  url = {http://arxiv.org/abs/2402.02392},
  urldate = {2024-03-08},
  abstract = {Large language models (LLMs) are increasingly used across society, including in domains like business, engineering, and medicine. These fields often grapple with decision-making under uncertainty, a critical yet challenging task. In this paper, we show that directly prompting LLMs on these types of decision-making problems yields poor results, especially as the problem complexity increases. To overcome this limitation, we propose DeLLMa (Decision-making Large Language Model assistant), a framework designed to enhance decision-making accuracy in uncertain environments. DeLLMa involves a multi-step scaffolding procedure, drawing upon principles from decision theory and utility theory, to provide an optimal and human-auditable decision-making process. We validate our framework on decision-making environments involving real agriculture and finance data. Our results show that DeLLMa can significantly improve LLM decision-making performance, achieving up to a 40\% increase in accuracy over competing methods.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/JKDV2SKU/Liu et al. - 2024 - DeLLMa A Framework for Decision Making Under Unce.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/2FG8WI9X/2402.html}
}

@online{liuLLMConversationalAgent2024,
  title = {From {{LLM}} to {{Conversational Agent}}: {{A Memory Enhanced Architecture}} with {{Fine-Tuning}} of {{Large Language Models}}},
  shorttitle = {From {{LLM}} to {{Conversational Agent}}},
  author = {Liu, Na and Chen, Liangyu and Tian, Xiaoyu and Zou, Wei and Chen, Kaijiang and Cui, Ming},
  date = {2024-01-05},
  eprint = {2401.02777},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2401.02777},
  url = {http://arxiv.org/abs/2401.02777},
  urldate = {2024-01-22},
  abstract = {This paper introduces RAISE (Reasoning and Acting through Scratchpad and Examples), an advanced architecture enhancing the integration of Large Language Models (LLMs) like GPT-4 into conversational agents. RAISE, an enhancement of the ReAct framework, incorporates a dual-component memory system, mirroring human short-term and long-term memory, to maintain context and continuity in conversations. It entails a comprehensive agent construction scenario, including phases like Conversation Selection, Scene Extraction, CoT Completion, and Scene Augmentation, leading to the LLMs Training phase. This approach appears to enhance agent controllability and adaptability in complex, multi-turn dialogues. Our preliminary evaluations in a real estate sales context suggest that RAISE has some advantages over traditional agents, indicating its potential for broader applications. This work contributes to the AI field by providing a robust framework for developing more context-aware and versatile conversational agents.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/HQCJTKPF/Liu et al. - 2024 - From LLM to Conversational Agent A Memory Enhance.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/XQP4ZAKY/2401.html}
}

@online{liuLostMiddleHow2023,
  title = {Lost in the {{Middle}}: {{How Language Models Use Long Contexts}}},
  shorttitle = {Lost in the {{Middle}}},
  author = {Liu, Nelson F. and Lin, Kevin and Hewitt, John and Paranjape, Ashwin and Bevilacqua, Michele and Petroni, Fabio and Liang, Percy},
  date = {2023-07-31},
  eprint = {2307.03172},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2307.03172},
  url = {http://arxiv.org/abs/2307.03172},
  urldate = {2023-11-21},
  abstract = {While recent language models have the ability to take long contexts as input, relatively little is known about how well they use longer context. We analyze language model performance on two tasks that require identifying relevant information within their input contexts: multi-document question answering and key-value retrieval. We find that performance is often highest when relevant information occurs at the beginning or end of the input context, and significantly degrades when models must access relevant information in the middle of long contexts. Furthermore, performance substantially decreases as the input context grows longer, even for explicitly long-context models. Our analysis provides a better understanding of how language models use their input context and provides new evaluation protocols for future long-context models.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/Z737V6AM/Liu et al. - 2023 - Lost in the Middle How Language Models Use Long C.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/QAATBRN8/2307.html}
}

@online{liuLostMiddleHow2023a,
  title = {Lost in the {{Middle}}: {{How Language Models Use Long Contexts}}},
  shorttitle = {Lost in the {{Middle}}},
  author = {Liu, Nelson F. and Lin, Kevin and Hewitt, John and Paranjape, Ashwin and Bevilacqua, Michele and Petroni, Fabio and Liang, Percy},
  date = {2023-11-20},
  eprint = {2307.03172},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2307.03172},
  url = {http://arxiv.org/abs/2307.03172},
  urldate = {2023-12-22},
  abstract = {While recent language models have the ability to take long contexts as input, relatively little is known about how well they use longer context. We analyze the performance of language models on two tasks that require identifying relevant information in their input contexts: multi-document question answering and key-value retrieval. We find that performance can degrade significantly when changing the position of relevant information, indicating that current language models do not robustly make use of information in long input contexts. In particular, we observe that performance is often highest when relevant information occurs at the beginning or end of the input context, and significantly degrades when models must access relevant information in the middle of long contexts, even for explicitly long-context models. Our analysis provides a better understanding of how language models use their input context and provides new evaluation protocols for future long-context language models.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/4WWKKIAY/Liu et al. - 2023 - Lost in the Middle How Language Models Use Long C.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/GJTWCATX/2307.html}
}

@online{liuMonolithRealTime2022,
  title = {Monolith: {{Real Time Recommendation System With Collisionless Embedding Table}}},
  shorttitle = {Monolith},
  author = {Liu, Zhuoran and Zou, Leqi and Zou, Xuan and Wang, Caihua and Zhang, Biao and Tang, Da and Zhu, Bolin and Zhu, Yijie and Wu, Peng and Wang, Ke and Cheng, Youlong},
  date = {2022-09-27},
  eprint = {2209.07663},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2209.07663},
  url = {http://arxiv.org/abs/2209.07663},
  urldate = {2022-11-07},
  abstract = {Building a scalable and real-time recommendation system is vital for many businesses driven by time-sensitive customer feedback, such as short-videos ranking or online ads. Despite the ubiquitous adoption of production-scale deep learning frameworks like TensorFlow or PyTorch, these general-purpose frameworks fall short of business demands in recommendation scenarios for various reasons: on one hand, tweaking systems based on static parameters and dense computations for recommendation with dynamic and sparse features is detrimental to model quality; on the other hand, such frameworks are designed with batch-training stage and serving stage completely separated, preventing the model from interacting with customer feedback in real-time. These issues led us to reexamine traditional approaches and explore radically different design choices. In this paper, we present Monolith, a system tailored for online training. Our design has been driven by observations of our application workloads and production environment that reflects a marked departure from other recommendations systems. Our contributions are manifold: first, we crafted a collisionless embedding table with optimizations such as expirable embeddings and frequency filtering to reduce its memory footprint; second, we provide an production-ready online training architecture with high fault-tolerance; finally, we proved that system reliability could be traded-off for real-time learning. Monolith has successfully landed in the BytePlus Recommend product.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/L8QXDV2J/Liu et al. - 2022 - Monolith Real Time Recommendation System With Col.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/HAVHKWS6/2209.html}
}

@online{liUnifiedMRCFramework2020,
  title = {A {{Unified MRC Framework}} for {{Named Entity Recognition}}},
  author = {Li, Xiaoya and Feng, Jingrong and Meng, Yuxian and Han, Qinghong and Wu, Fei and Li, Jiwei},
  date = {2020-05-23},
  eprint = {1910.11476},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1910.11476},
  urldate = {2022-11-20},
  abstract = {The task of named entity recognition (NER) is normally divided into nested NER and flat NER depending on whether named entities are nested or not. Models are usually separately developed for the two tasks, since sequence labeling models, the most widely used backbone for flat NER, are only able to assign a single label to a particular token, which is unsuitable for nested NER where a token may be assigned several labels. In this paper, we propose a unified framework that is capable of handling both flat and nested NER tasks. Instead of treating the task of NER as a sequence labeling problem, we propose to formulate it as a machine reading comprehension (MRC) task. For example, extracting entities with the \textbackslash textsc\{per\} label is formalized as extracting answer spans to the question "\{\textbackslash it which person is mentioned in the text?\}". This formulation naturally tackles the entity overlapping issue in nested NER: the extraction of two overlapping entities for different categories requires answering two independent questions. Additionally, since the query encodes informative prior knowledge, this strategy facilitates the process of entity extraction, leading to better performances for not only nested NER, but flat NER. We conduct experiments on both \{\textbackslash em nested\} and \{\textbackslash em flat\} NER datasets. Experimental results demonstrate the effectiveness of the proposed formulation. We are able to achieve vast amount of performance boost over current SOTA models on nested NER datasets, i.e., +1.28, +2.55, +5.44, +6.37, respectively on ACE04, ACE05, GENIA and KBP17, along with SOTA results on flat NER datasets, i.e.,+0.24, +1.95, +0.21, +1.49 respectively on English CoNLL 2003, English OntoNotes 5.0, Chinese MSRA, Chinese OntoNotes 4.0.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/VCFCLIRW/Li et al. - 2020 - A Unified MRC Framework for Named Entity Recogniti.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/EB4IMN8V/1910.html}
}

@online{liuRainierReinforcedKnowledge2022,
  title = {Rainier: {{Reinforced Knowledge Introspector}} for {{Commonsense Question Answering}}},
  shorttitle = {Rainier},
  author = {Liu, Jiacheng and Hallinan, Skyler and Lu, Ximing and He, Pengfei and Welleck, Sean and Hajishirzi, Hannaneh and Choi, Yejin},
  date = {2022-10-22},
  eprint = {2210.03078},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2210.03078},
  url = {http://arxiv.org/abs/2210.03078},
  urldate = {2023-02-17},
  abstract = {Knowledge underpins reasoning. Recent research demonstrates that when relevant knowledge is provided as additional context to commonsense question answering (QA), it can substantially enhance the performance even on top of state-of-the-art. The fundamental challenge is where and how to find such knowledge that is high quality and on point with respect to the question; knowledge retrieved from knowledge bases are incomplete and knowledge generated from language models are inconsistent. We present Rainier, or Reinforced Knowledge Introspector, that learns to generate contextually relevant knowledge in response to given questions. Our approach starts by imitating knowledge generated by GPT-3, then learns to generate its own knowledge via reinforcement learning where rewards are shaped based on the increased performance on the resulting question answering. Rainier demonstrates substantial and consistent performance gains when tested over 9 different commonsense benchmarks: including 5 datasets that are seen during model training, as well as 4 datasets that are kept unseen. Our work is the first to report that knowledge generated by models that are orders of magnitude smaller than GPT-3, even without direct supervision on the knowledge itself, can exceed the quality of commonsense knowledge elicited from GPT-3.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/2D552HTJ/Liu et al. - 2022 - Rainier Reinforced Knowledge Introspector for Com.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/7UBB9E65/2210.html}
}

@software{Llama2_fullguide,
  title = {Llama2\_fullguide},
  url = {https://ai.meta.com/llama/get-started/?utm_source=linkedin&utm_medium=organic_social&utm_campaign=llama2&utm_content=image}
}

@online{LlmintroPdf,
  title = {Llmintro.Pdf},
  url = {https://drive.google.com/file/d/1pxx_ZI7O-Nwl7ZLNk5hI3WzAsTLwvNU7/view?usp=share_link&usp=embed_facebook},
  urldate = {2024-01-02},
  organization = {Google Docs}
}

@software{LLMOps,
  title = {{{LLMOps}}},
  url = {https://developer.nvidia.com/blog/mastering-llm-techniques-llmops/}
}

@online{longpreFlanCollectionDesigning2023,
  title = {The {{Flan Collection}}: {{Designing Data}} and {{Methods}} for {{Effective Instruction Tuning}}},
  shorttitle = {The {{Flan Collection}}},
  author = {Longpre, Shayne and Hou, Le and Vu, Tu and Webson, Albert and Chung, Hyung Won and Tay, Yi and Zhou, Denny and Le, Quoc V. and Zoph, Barret and Wei, Jason and Roberts, Adam},
  date = {2023-02-14},
  eprint = {2301.13688},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2301.13688},
  urldate = {2023-02-28},
  abstract = {We study the design decisions of publicly available instruction tuning methods, and break down the development of Flan 2022 (Chung et al., 2022). Through careful ablation studies on the Flan Collection of tasks and methods, we tease apart the effect of design decisions which enable Flan-T5 to outperform prior work by 3-17\%+ across evaluation settings. We find task balancing and enrichment techniques are overlooked but critical to effective instruction tuning, and in particular, training with mixed prompt settings (zero-shot, few-shot, and chain-of-thought) actually yields stronger (2\%+) performance in all settings. In further experiments, we show Flan-T5 requires less finetuning to converge higher and faster than T5 on single downstream tasks, motivating instruction-tuned models as more computationally-efficient starting checkpoints for new tasks. Finally, to accelerate research on instruction tuning, we make the Flan 2022 collection of datasets, templates, and methods publicly available at https://github.com/google-research/FLAN/tree/main/flan/v2.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/38WECT5S/Longpre et al. - 2023 - The Flan Collection Designing Data and Methods fo.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/PDJBKGX8/2301.html}
}

@online{luBBTFinComprehensiveConstruction2023,
  title = {{{BBT-Fin}}: {{Comprehensive Construction}} of {{Chinese Financial Domain Pre-trained Language Model}}, {{Corpus}} and {{Benchmark}}},
  shorttitle = {{{BBT-Fin}}},
  author = {Lu, Dakuan and Wu, Hengkui and Liang, Jiaqing and Xu, Yipei and He, Qianyu and Geng, Yipeng and Han, Mengkun and Xin, Yingsi and Xiao, Yanghua},
  date = {2023-02-26},
  eprint = {2302.09432},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2302.09432},
  urldate = {2023-12-14},
  abstract = {To advance Chinese financial natural language processing (NLP), we introduce BBT-FinT5, a new Chinese financial pre-training language model based on the T5 model. To support this effort, we have built BBT-FinCorpus, a large-scale financial corpus with approximately 300GB of raw text from four different sources. In general domain NLP, comprehensive benchmarks like GLUE and SuperGLUE have driven significant advancements in language model pre-training by enabling head-to-head comparisons among models. Drawing inspiration from these benchmarks, we propose BBT-CFLEB, a Chinese Financial Language understanding and generation Evaluation Benchmark, which includes six datasets covering both understanding and generation tasks. Our aim is to facilitate research in the development of NLP within the Chinese financial domain. Our model, corpus and benchmark are released at https://github.com/ssymmetry/BBT-FinCUGE-Applications. Our work belongs to the Big Bang Transformer (BBT), a large-scale pre-trained language model project.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/N5WM8ZUP/Lu et al. - 2023 - BBT-Fin Comprehensive Construction of Chinese Fin.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/VXPBSQ25/2302.html}
}

@book{lukeEssentialsMetaheuristicsSet2013,
  title = {Essentials of Metaheuristics: A Set of Undergraduate Lecture Notes; {{Online Version}} 2.0},
  shorttitle = {Essentials of Metaheuristics},
  author = {Luke, Sean},
  date = {2013},
  edition = {2. ed},
  publisher = {Lulu},
  location = {S.l.},
  isbn = {978-1-300-54962-8},
  langid = {english},
  pagetotal = {239},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/U9SL8JML/Luke - 2013 - Essentials of metaheuristics a set of undergradua.pdf}
}

@online{maEndtoendSequenceLabeling2016,
  title = {End-to-End {{Sequence Labeling}} via {{Bi-directional LSTM-CNNs-CRF}}},
  author = {Ma, Xuezhe and Hovy, Eduard},
  date = {2016-05-28},
  eprint = {1603.01354},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1603.01354},
  url = {http://arxiv.org/abs/1603.01354},
  urldate = {2022-11-19},
  abstract = {State-of-the-art sequence labeling systems traditionally require large amounts of task-specific knowledge in the form of hand-crafted features and data pre-processing. In this paper, we introduce a novel neutral network architecture that benefits from both word- and character-level representations automatically, by using combination of bidirectional LSTM, CNN and CRF. Our system is truly end-to-end, requiring no feature engineering or data pre-processing, thus making it applicable to a wide range of sequence labeling tasks. We evaluate our system on two data sets for two sequence labeling tasks --- Penn Treebank WSJ corpus for part-of-speech (POS) tagging and CoNLL 2003 corpus for named entity recognition (NER). We obtain state-of-the-art performance on both the two data --- 97.55\textbackslash\% accuracy for POS tagging and 91.21\textbackslash\% F1 for NER.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/TJ3G864Z/Ma y Hovy - 2016 - End-to-end Sequence Labeling via Bi-directional LS.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/SQG83Z7L/1603.html}
}

@online{MagentaMagentaModels,
  title = {Magenta/Magenta/Models/Music\_vae at Main · Magenta/Magenta},
  url = {https://github.com/magenta/magenta/tree/main/magenta/models/music_vae},
  urldate = {2023-09-29},
  abstract = {Magenta: Music and Art Generation with Machine Intelligence - magenta/magenta},
  langid = {english},
  organization = {GitHub},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/LF9XTQNX/music_vae.html}
}

@online{mahowaldDissociatingLanguageThought2023,
  title = {Dissociating Language and Thought in Large Language Models: A Cognitive Perspective},
  shorttitle = {Dissociating Language and Thought in Large Language Models},
  author = {Mahowald, Kyle and Ivanova, Anna A. and Blank, Idan A. and Kanwisher, Nancy and Tenenbaum, Joshua B. and Fedorenko, Evelina},
  date = {2023-01-16},
  eprint = {2301.06627},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2301.06627},
  url = {http://arxiv.org/abs/2301.06627},
  urldate = {2023-02-01},
  abstract = {Today's large language models (LLMs) routinely generate coherent, grammatical and seemingly meaningful paragraphs of text. This achievement has led to speculation that these networks are -- or will soon become -- "thinking machines", capable of performing tasks that require abstract knowledge and reasoning. Here, we review the capabilities of LLMs by considering their performance on two different aspects of language use: 'formal linguistic competence', which includes knowledge of rules and patterns of a given language, and 'functional linguistic competence', a host of cognitive abilities required for language understanding and use in the real world. Drawing on evidence from cognitive neuroscience, we show that formal competence in humans relies on specialized language processing mechanisms, whereas functional competence recruits multiple extralinguistic capacities that comprise human thought, such as formal reasoning, world knowledge, situation modeling, and social cognition. In line with this distinction, LLMs show impressive (although imperfect) performance on tasks requiring formal linguistic competence, but fail on many tests requiring functional competence. Based on this evidence, we argue that (1) contemporary LLMs should be taken seriously as models of formal linguistic skills; (2) models that master real-life language use would need to incorporate or develop not only a core language module, but also multiple non-language-specific cognitive capacities required for modeling thought. Overall, a distinction between formal and functional linguistic competence helps clarify the discourse surrounding LLMs' potential and provides a path toward building models that understand and use language in human-like ways.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/JYQT2KL3/Mahowald et al. - 2023 - Dissociating language and thought in large languag.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/9XCXCXAU/2301.html}
}

@online{majidiCombinationMultiObjectiveGenetic2022,
  title = {A {{Combination}} of {{Multi-Objective Genetic Algorithm}} and {{Deep Learning}} for {{Music Harmony Generation}}},
  author = {Majidi, Maryam and Toroghi, Rahil Mahdian},
  date = {2022-06-03},
  eprint = {2102.07960},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2102.07960},
  urldate = {2023-09-27},
  abstract = {Automatic Music Generation (AMG) has become an interesting research topic for many scientists in artificial intelligence, who are also interested in the music industry. One of the main challenges in AMG is that there is no clear objective evaluation criterion that can measure the music grammar, structural rules, and audience satisfaction. Also, original music contains different elements that should work together, such as melody, harmony, and rhythm; but in the most of previous works, AMG works only for one element (e.g., melody). Therefore, in this paper, we propose a Multi-Objective Genetic Algorithm (MO-GA) to generate polyphonic music pieces, considering grammar and listener satisfaction. In this method, we use three objective functions. The first objective function is the accuracy of the generated music piece, based on music theory; and the other two objective functions are modeled scores provided by music experts and ordinary listeners. The scoring of experts and listeners separately are modeled using Bi-directional Long Short-Term Memory (Bi-LSTM) neural networks. The proposed music generation system tries to maximize mentioned objective functions to generate a new piece of music, including melody and harmony. The results show that the proposed method can generate pleasant pieces with desired styles and lengths, along with harmonic sounds that follow the grammar.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/7TUZE2AB/Majidi y Toroghi - 2022 - A Combination of Multi-Objective Genetic Algorithm.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/N5N6S5XS/2102.html}
}

@inproceedings{maLargeLanguageModel2023,
  title = {Large {{Language Model Is Not}} a {{Good Few-shot Information Extractor}}, but a {{Good Reranker}} for {{Hard Samples}}!},
  booktitle = {Findings of the {{Association}} for {{Computational Linguistics}}: {{EMNLP}} 2023},
  author = {Ma, Yubo and Cao, Yixin and Hong, Yong and Sun, Aixin},
  date = {2023},
  pages = {10572--10601},
  publisher = {Association for Computational Linguistics},
  location = {Singapore},
  doi = {10.18653/v1/2023.findings-emnlp.710},
  url = {https://aclanthology.org/2023.findings-emnlp.710},
  urldate = {2024-01-10},
  abstract = {Large Language Models (LLMs) have made remarkable strides in various tasks. Whether LLMs are competitive few-shot solvers for information extraction (IE) tasks, however, remains an open problem. In this work, we aim to provide a thorough answer to this question. Through extensive experiments on nine datasets across four IE tasks, we demonstrate that current advanced LLMs consistently exhibit inferior performance, higher latency, and increased budget requirements compared to fine-tuned SLMs under most settings. Therefore, we conclude that LLMs are not effective few-shot information extractors in general 1. Nonetheless, we illustrate that with appropriate prompting strategies, LLMs can effectively complement SLMs and tackle challenging samples that SLMs struggle with. And moreover, we propose an adaptive filter-thenrerank paradigm to combine the strengths of LLMs and SLMs. In this paradigm, SLMs serve as filters and LLMs serve as rerankers. By prompting LLMs to rerank a small portion of difficult samples identified by SLMs, our preliminary system consistently achieves promising improvements (2.4\% F1-gain on average) on various IE tasks, with an acceptable time and cost investment. Our code is available at https://github.com/mayubo2333/LLM-IE.},
  eventtitle = {Findings of the {{Association}} for {{Computational Linguistics}}: {{EMNLP}} 2023},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/W323EJVH/2303.08559.pdf}
}

@online{mallawaarachchiHowDefineFitness2017,
  title = {How to Define a {{Fitness Function}} in a {{Genetic Algorithm}}?},
  author = {Mallawaarachchi, Vijini},
  date = {2017-11-10T05:21:04},
  url = {https://towardsdatascience.com/how-to-define-a-fitness-function-in-a-genetic-algorithm-be572b9ea3b4},
  urldate = {2023-09-27},
  abstract = {In my previous article, I have explained the basics about Genetic Algorithms. After it was published, I got many requests to discuss more…},
  langid = {english},
  organization = {Medium},
  keywords = {ea_fitness_function},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/3ZS2VT7E/how-to-define-a-fitness-function-in-a-genetic-algorithm-be572b9ea3b4.html}
}

@online{martinBetterCallGPT2024,
  title = {Better {{Call GPT}}, {{Comparing Large Language Models Against Lawyers}}},
  author = {Martin, Lauren and Whitehouse, Nick and Yiu, Stephanie and Catterson, Lizzie and Perera, Rivindu},
  date = {2024-01-23},
  eprint = {2401.16212},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2401.16212},
  urldate = {2024-03-05},
  abstract = {This paper presents a groundbreaking comparison between Large Language Models and traditional legal contract reviewers, Junior Lawyers and Legal Process Outsourcers. We dissect whether LLMs can outperform humans in accuracy, speed, and cost efficiency during contract review. Our empirical analysis benchmarks LLMs against a ground truth set by Senior Lawyers, uncovering that advanced models match or exceed human accuracy in determining legal issues. In speed, LLMs complete reviews in mere seconds, eclipsing the hours required by their human counterparts. Cost wise, LLMs operate at a fraction of the price, offering a staggering 99.97 percent reduction in cost over traditional methods. These results are not just statistics, they signal a seismic shift in legal practice. LLMs stand poised to disrupt the legal industry, enhancing accessibility and efficiency of legal services. Our research asserts that the era of LLM dominance in legal contract review is upon us, challenging the status quo and calling for a reimagined future of legal workflows.},
  pubstate = {preprint},
  version = {1},
  keywords = {Computer Science - Computation and Language,Computer Science - Computers and Society},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/V2KGLJEM/Martin et al. - 2024 - Better Call GPT, Comparing Large Language Models A.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/8TRFFA4C/2401.html}
}

@online{martinezEstablishingVocabularyTests2024,
  title = {Establishing {{Vocabulary Tests}} as a {{Benchmark}} for {{Evaluating Large Language Models}}},
  author = {Martínez, Gonzalo and Conde, Javier and Merino-Gómez, Elena and Bermúdez-Margaretto, Beatriz and Hernández, José Alberto and Reviriego, Pedro and Brysbaert, Marc},
  date = {2024-01-29},
  eprint = {2310.14703},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2310.14703},
  url = {http://arxiv.org/abs/2310.14703},
  urldate = {2024-04-08},
  abstract = {Vocabulary tests, once a cornerstone of language modeling evaluation, have been largely overlooked in the current landscape of Large Language Models (LLMs) like Llama, Mistral, and GPT. While most LLM evaluation benchmarks focus on specific tasks or domain-specific knowledge, they often neglect the fundamental linguistic aspects of language understanding and production. In this paper, we advocate for the revival of vocabulary tests as a valuable tool for assessing LLM performance. We evaluate seven LLMs using two vocabulary test formats across two languages and uncover surprising gaps in their lexical knowledge. These findings shed light on the intricacies of LLM word representations, their learning mechanisms, and performance variations across models and languages. Moreover, the ability to automatically generate and perform vocabulary tests offers new opportunities to expand the approach and provide a more complete picture of LLMs' language skills.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/CTYBZV3Z/Martínez et al. - 2024 - Establishing Vocabulary Tests as a Benchmark for E.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/75VKZ745/2310.html}
}

@inproceedings{martinsVariationalAutoencodersEvolutionary2022,
  title = {Variational {{Autoencoders}} and {{Evolutionary Algorithms}} for {{Targeted Novel Enzyme Design}}},
  booktitle = {2022 {{IEEE Congress}} on {{Evolutionary Computation}} ({{CEC}})},
  author = {Martins, Miguel and Rocha, Miguel and Pereira, Vítor},
  date = {2022-07},
  pages = {1--8},
  doi = {10.1109/CEC55065.2022.9870421},
  abstract = {Recent developments in Generative Deep Learning have fostered new engineering methods for protein design. Although deep generative models trained on protein sequence can learn biologically meaningful representations, the design of proteins with optimised properties remains a challenge. We combined deep learning architectures with evolutionary computation to steer the protein generative process towards specific sets of properties to address this problem. The latent space of a Variational Autoencoder is explored by evolutionary algorithms to find the best candidates. A set of single-objective and multi-objective problems were conceived to evaluate the algorithms' capacity to optimise proteins. The optimisation tasks consider the average proteins' hydrophobicity, their solubility and the probability of being generated by a defined functional Hidden Markov Model profile. The results show that Evolutionary Algorithms can achieve good results while allowing for more variability in the design of the experiment, thus resulting in a much greater set of possibly functional novel proteins.},
  eventtitle = {2022 {{IEEE Congress}} on {{Evolutionary Computation}} ({{CEC}})},
  keywords = {Biological system modeling,Computational modeling,Deep learning,Deep Learning,Evolutionary Algorithms,Evolutionary computation,Generative Models,Hidden Markov models,Novel Proteins,Protein Design,Proteins,Transfer learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/L9RMRZNG/Martins et al. - 2022 - Variational Autoencoders and Evolutionary Algorith.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/X24BCK67/9870421.html}
}

@inproceedings{martinsVariationalAutoencodersEvolutionary2022a,
  title = {Variational {{Autoencoders}} and {{Evolutionary Algorithms}} for {{Targeted Novel Enzyme Design}}},
  booktitle = {2022 {{IEEE Congress}} on {{Evolutionary Computation}} ({{CEC}})},
  author = {Martins, Miguel and Rocha, Miguel and Pereira, Vítor},
  date = {2022-07},
  pages = {1--8},
  doi = {10.1109/CEC55065.2022.9870421},
  abstract = {Recent developments in Generative Deep Learning have fostered new engineering methods for protein design. Although deep generative models trained on protein sequence can learn biologically meaningful representations, the design of proteins with optimised properties remains a challenge. We combined deep learning architectures with evolutionary computation to steer the protein generative process towards specific sets of properties to address this problem. The latent space of a Variational Autoencoder is explored by evolutionary algorithms to find the best candidates. A set of single-objective and multi-objective problems were conceived to evaluate the algorithms' capacity to optimise proteins. The optimisation tasks consider the average proteins' hydrophobicity, their solubility and the probability of being generated by a defined functional Hidden Markov Model profile. The results show that Evolutionary Algorithms can achieve good results while allowing for more variability in the design of the experiment, thus resulting in a much greater set of possibly functional novel proteins.},
  eventtitle = {2022 {{IEEE Congress}} on {{Evolutionary Computation}} ({{CEC}})},
  keywords = {Biological system modeling,Computational modeling,Deep learning,Deep Learning,Evolutionary Algorithms,Evolutionary computation,Generative Models,Hidden Markov models,Novel Proteins,Protein Design,Proteins,Transfer learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/9U2HQZ68/Martins et al. - 2022 - Variational Autoencoders and Evolutionary Algorith.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/E84MV774/9870421.html}
}

@inproceedings{martinsVariationalAutoencodersEvolutionary2022b,
  title = {Variational {{Autoencoders}} and {{Evolutionary Algorithms}} for {{Targeted Novel Enzyme Design}}},
  booktitle = {2022 {{IEEE Congress}} on {{Evolutionary Computation}} ({{CEC}})},
  author = {Martins, Miguel and Rocha, Miguel and Pereira, Vítor},
  date = {2022-07-18},
  pages = {1--8},
  publisher = {IEEE Press},
  location = {Padua, Italy},
  doi = {10.1109/CEC55065.2022.9870421},
  url = {https://doi.org/10.1109/CEC55065.2022.9870421},
  urldate = {2023-09-13},
  abstract = {Recent developments in Generative Deep Learning have fostered new engineering methods for protein design. Although deep generative models trained on protein sequence can learn biologically meaningful representations, the design of proteins with optimised properties remains a challenge. We combined deep learning architectures with evolutionary computation to steer the protein generative process towards specific sets of properties to address this problem. The latent space of a Variational Autoencoder is explored by evolutionary algorithms to find the best candidates. A set of single-objective and multi-objective problems were conceived to evaluate the algorithms\&\#x0027; capacity to optimise proteins. The optimisation tasks consider the average proteins\&\#x0027; hydrophobicity, their solubility and the probability of being generated by a defined functional Hidden Markov Model profile. The results show that Evolutionary Algorithms can achieve good results while allowing for more variability in the design of the experiment, thus resulting in a much greater set of possibly functional novel proteins.},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/RVIPQ6ZX/Martins et al. - 2022 - Variational Autoencoders and Evolutionary Algorith.pdf}
}

@online{mastermanLandscapeEmergingAI2024,
  title = {The {{Landscape}} of {{Emerging AI Agent Architectures}} for {{Reasoning}}, {{Planning}}, and {{Tool Calling}}: {{A Survey}}},
  shorttitle = {The {{Landscape}} of {{Emerging AI Agent Architectures}} for {{Reasoning}}, {{Planning}}, and {{Tool Calling}}},
  author = {Masterman, Tula and Besen, Sandi and Sawtell, Mason and Chao, Alex},
  date = {2024-04-17},
  eprint = {2404.11584},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2404.11584},
  urldate = {2024-04-23},
  abstract = {This survey paper examines the recent advancements in AI agent implementations, with a focus on their ability to achieve complex goals that require enhanced reasoning, planning, and tool execution capabilities. The primary objectives of this work are to a) communicate the current capabilities and limitations of existing AI agent implementations, b) share insights gained from our observations of these systems in action, and c) suggest important considerations for future developments in AI agent design. We achieve this by providing overviews of single-agent and multi-agent architectures, identifying key patterns and divergences in design choices, and evaluating their overall impact on accomplishing a provided goal. Our contribution outlines key themes when selecting an agentic architecture, the impact of leadership on agent systems, agent communication styles, and key phases for planning, execution, and reflection that enable robust AI agent systems.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/EPVDDY2T/Masterman et al. - 2024 - The Landscape of Emerging AI Agent Architectures f.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/EA4A5MYK/2404.html}
}

@online{mckinzieMM1MethodsAnalysis2024,
  title = {{{MM1}}: {{Methods}}, {{Analysis}} \& {{Insights}} from {{Multimodal LLM Pre-training}}},
  shorttitle = {{{MM1}}},
  author = {McKinzie, Brandon and Gan, Zhe and Fauconnier, Jean-Philippe and Dodge, Sam and Zhang, Bowen and Dufter, Philipp and Shah, Dhruti and Du, Xianzhi and Peng, Futang and Weers, Floris and Belyi, Anton and Zhang, Haotian and Singh, Karanjeet and Kang, Doug and Hè, Hongyu and Schwarzer, Max and Gunter, Tom and Kong, Xiang and Zhang, Aonan and Wang, Jianyu and Wang, Chong and Du, Nan and Lei, Tao and Wiseman, Sam and Lee, Mark and Wang, Zirui and Pang, Ruoming and Grasch, Peter and Toshev, Alexander and Yang, Yinfei},
  date = {2024-03-14},
  eprint = {2403.09611},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2403.09611},
  url = {http://arxiv.org/abs/2403.09611},
  urldate = {2024-03-19},
  abstract = {In this work, we discuss building performant Multimodal Large Language Models (MLLMs). In particular, we study the importance of various architecture components and data choices. Through careful and comprehensive ablations of the image encoder, the vision language connector, and various pre-training data choices, we identified several crucial design lessons. For example, we demonstrate that for large-scale multimodal pre-training using a careful mix of image-caption, interleaved image-text, and text-only data is crucial for achieving state-of-the-art (SOTA) few-shot results across multiple benchmarks, compared to other published pre-training results. Further, we show that the image encoder together with image resolution and the image token count has substantial impact, while the vision-language connector design is of comparatively negligible importance. By scaling up the presented recipe, we build MM1, a family of multimodal models up to 30B parameters, consisting of both dense models and mixture-of-experts (MoE) variants, that are SOTA in pre-training metrics and achieve competitive performance after supervised fine-tuning on a range of established multimodal benchmarks. Thanks to large-scale pre-training, MM1 enjoys appealing properties such as enhanced in-context learning, and multi-image reasoning, enabling few-shot chain-of-thought prompting.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ASHY8CMR/McKinzie et al. - 2024 - MM1 Methods, Analysis & Insights from Multimodal .pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/WQEVLNAT/2403.html}
}

@software{Meditron_LLM_Medicine,
  title = {Meditron\_{{LLM}}\_{{Medicine}}},
  url = {https://github.com/epfLLM/meditron}
}

@online{mehrabiSurveyBiasFairness2022,
  title = {A {{Survey}} on {{Bias}} and {{Fairness}} in {{Machine Learning}}},
  author = {Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
  date = {2022-01-25},
  eprint = {1908.09635},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1908.09635},
  url = {http://arxiv.org/abs/1908.09635},
  urldate = {2023-05-31},
  abstract = {With the widespread use of AI systems and applications in our everyday lives, it is important to take fairness issues into consideration while designing and engineering these types of systems. Such systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that the decisions do not reflect discriminatory behavior toward certain groups or populations. We have recently seen work in machine learning, natural language processing, and deep learning that addresses such challenges in different subdomains. With the commercialization of these systems, researchers are becoming aware of the biases that these applications can contain and have attempted to address them. In this survey we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined in order to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and how they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/FSKYNPR6/Mehrabi et al. - 2022 - A Survey on Bias and Fairness in Machine Learning.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/XPGDFWPZ/1908.html}
}

@online{metzVeLOTrainingVersatile2022,
  title = {{{VeLO}}: {{Training Versatile Learned Optimizers}} by {{Scaling Up}}},
  shorttitle = {{{VeLO}}},
  author = {Metz, Luke and Harrison, James and Freeman, C. Daniel and Merchant, Amil and Beyer, Lucas and Bradbury, James and Agrawal, Naman and Poole, Ben and Mordatch, Igor and Roberts, Adam and Sohl-Dickstein, Jascha},
  date = {2022-11-17},
  eprint = {2211.09760},
  eprinttype = {arxiv},
  eprintclass = {cs, math, stat},
  url = {http://arxiv.org/abs/2211.09760},
  urldate = {2022-11-18},
  abstract = {While deep learning models have replaced hand-designed features across many domains, these models are still trained with hand-designed optimizers. In this work, we leverage the same scaling approach behind the success of deep learning to learn versatile optimizers. We train an optimizer for deep learning which is itself a small neural network that ingests gradients and outputs parameter updates. Meta-trained with approximately four thousand TPU-months of compute on a wide variety of optimization tasks, our optimizer not only exhibits compelling performance, but optimizes in interesting and unexpected ways. It requires no hyperparameter tuning, instead automatically adapting to the specifics of the problem being optimized. We open source our learned optimizer, meta-training code, the associated train and test data, and an extensive optimizer benchmark suite with baselines at velo-code.github.io.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/9JPZIBLR/Metz et al. - 2022 - VeLO Training Versatile Learned Optimizers by Sca.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/PV2L46AY/2211.html}
}

@online{mialonAugmentedLanguageModels2023,
  title = {Augmented {{Language Models}}: A {{Survey}}},
  shorttitle = {Augmented {{Language Models}}},
  author = {Mialon, Grégoire and Dessì, Roberto and Lomeli, Maria and Nalmpantis, Christoforos and Pasunuru, Ram and Raileanu, Roberta and Rozière, Baptiste and Schick, Timo and Dwivedi-Yu, Jane and Celikyilmaz, Asli and Grave, Edouard and LeCun, Yann and Scialom, Thomas},
  date = {2023-02-15},
  eprint = {2302.07842},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2302.07842},
  urldate = {2023-02-17},
  abstract = {This survey reviews works in which language models (LMs) are augmented with reasoning skills and the ability to use tools. The former is defined as decomposing a potentially complex task into simpler subtasks while the latter consists in calling external modules such as a code interpreter. LMs can leverage these augmentations separately or in combination via heuristics, or learn to do so from demonstrations. While adhering to a standard missing tokens prediction objective, such augmented LMs can use various, possibly non-parametric external modules to expand their context processing ability, thus departing from the pure language modeling paradigm. We therefore refer to them as Augmented Language Models (ALMs). The missing token objective allows ALMs to learn to reason, use tools, and even act, while still performing standard natural language tasks and even outperforming most regular LMs on several benchmarks. In this work, after reviewing current advance in ALMs, we conclude that this new research direction has the potential to address common limitations of traditional LMs such as interpretability, consistency, and scalability issues.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/CYGG5SLL/Mialon et al. - 2023 - Augmented Language Models a Survey.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/YZVV66I5/2302.html}
}

@article{miaoSurveyFeatureSelection2016,
  title = {A {{Survey}} on {{Feature Selection}}},
  author = {Miao, Jianyu and Niu, Lingfeng},
  date = {2016},
  journaltitle = {Procedia Computer Science},
  shortjournal = {Procedia Computer Science},
  volume = {91},
  pages = {919--926},
  issn = {18770509},
  doi = {10.1016/j.procs.2016.07.111},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1877050916313047},
  urldate = {2023-09-05},
  abstract = {Feature selection, as a dimensionality reduction technique, aims to choosing a small subset of the relevant features from the original features by removing irrelevant, redundant or noisy features. Feature selection usually can lead to better learning performance, i.e., higher learning accuracy, lower computational cost, and better model interpretability. Recently, researchers from computer vision, text mining and so on have proposed a variety of feature selection algorithms and in terms of theory and experiment, show the effectiveness of their works. This paper is aimed at reviewing the state of the art on these techniques. Furthermore, a thorough experiment is conducted to check if the use of feature selection can improve the performance of learning, considering some of the approaches mentioned in the literature. The experimental results show that unsupervised feature selection algorithms benefits machine learning tasks improving the performance of clustering.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/52IVA87I/Miao y Niu - 2016 - A Survey on Feature Selection.pdf}
}

@online{mikolovEfficientEstimationWord2013,
  title = {Efficient {{Estimation}} of {{Word Representations}} in {{Vector Space}}},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  date = {2013-09-06},
  eprint = {1301.3781},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1301.3781},
  urldate = {2022-11-22},
  abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/6EH42E9L/Mikolov et al. - 2013 - Efficient Estimation of Word Representations in Ve.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/IL2XSGG7/1301.html}
}

@software{MISTRAL7B_ftinstrucchatbot,
  title = {{{MISTRAL-7B}}\_ft-Instruc-Chatbot},
  url = {https://www.kaggle.com/models/mistral-ai/mistral}
}

@online{monizReALMReferenceResolution2024,
  title = {{{ReALM}}: {{Reference Resolution As Language Modeling}}},
  shorttitle = {{{ReALM}}},
  author = {Moniz, Joel Ruben Antony and Krishnan, Soundarya and Ozyildirim, Melis and Saraf, Prathamesh and Ates, Halim Cagri and Zhang, Yuan and Yu, Hong and Rajshree, Nidhi},
  date = {2024-03-29},
  eprint = {2403.20329},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2403.20329},
  urldate = {2024-04-02},
  abstract = {Reference resolution is an important problem, one that is essential to understand and successfully handle context of different kinds. This context includes both previous turns and context that pertains to non-conversational entities, such as entities on the user’s screen or those running in the background. While LLMs have been shown to be extremely powerful for a variety of tasks, their use in reference resolution, particularly for non-conversational entities, remains underutilized. This paper demonstrates how LLMs can be used to create an extremely effective system to resolve references of various types, by showing how reference resolution can be converted into a language modeling problem, despite involving forms of entities like those on screen that are not traditionally conducive to being reduced to a text-only modality. We demonstrate large improvements over an existing system with similar functionality across different types of references, with our smallest model obtaining absolute gains of over 5\% for on-screen references. We also benchmark against GPT-3.5 and GPT-4, with our smallest model achieving performance comparable to that of GPT-4, and our larger models substantially outperforming it.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/CQG35VBC/Moniz et al. - 2024 - ReALM Reference Resolution As Language Modeling.pdf}
}

@online{monizReALMReferenceResolution2024a,
  title = {{{ReALM}}: {{Reference Resolution As Language Modeling}}},
  shorttitle = {{{ReALM}}},
  author = {Moniz, Joel Ruben Antony and Krishnan, Soundarya and Ozyildirim, Melis and Saraf, Prathamesh and Ates, Halim Cagri and Zhang, Yuan and Yu, Hong and Rajshree, Nidhi},
  date = {2024-03-29},
  eprint = {2403.20329},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2403.20329},
  urldate = {2024-04-02},
  abstract = {Reference resolution is an important problem, one that is essential to understand and successfully handle context of different kinds. This context includes both previous turns and context that pertains to non-conversational entities, such as entities on the user’s screen or those running in the background. While LLMs have been shown to be extremely powerful for a variety of tasks, their use in reference resolution, particularly for non-conversational entities, remains underutilized. This paper demonstrates how LLMs can be used to create an extremely effective system to resolve references of various types, by showing how reference resolution can be converted into a language modeling problem, despite involving forms of entities like those on screen that are not traditionally conducive to being reduced to a text-only modality. We demonstrate large improvements over an existing system with similar functionality across different types of references, with our smallest model obtaining absolute gains of over 5\% for on-screen references. We also benchmark against GPT-3.5 and GPT-4, with our smallest model achieving performance comparable to that of GPT-4, and our larger models substantially outperforming it.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/JQIF4KYH/Moniz et al. - 2024 - ReALM Reference Resolution As Language Modeling.pdf}
}

@online{munkhdalaiLeaveNoContext2024,
  title = {Leave {{No Context Behind}}: {{Efficient Infinite Context Transformers}} with {{Infini-attention}}},
  shorttitle = {Leave {{No Context Behind}}},
  author = {Munkhdalai, Tsendsuren and Faruqui, Manaal and Gopal, Siddharth},
  date = {2024-04-10},
  eprint = {2404.07143},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2404.07143},
  url = {http://arxiv.org/abs/2404.07143},
  urldate = {2024-04-18},
  abstract = {This work introduces an efficient method to scale Transformer-based Large Language Models (LLMs) to infinitely long inputs with bounded memory and computation. A key component in our proposed approach is a new attention technique dubbed Infini-attention. The Infini-attention incorporates a compressive memory into the vanilla attention mechanism and builds in both masked local attention and long-term linear attention mechanisms in a single Transformer block. We demonstrate the effectiveness of our approach on long-context language modeling benchmarks, 1M sequence length passkey context block retrieval and 500K length book summarization tasks with 1B and 8B LLMs. Our approach introduces minimal bounded memory parameters and enables fast streaming inference for LLMs.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/WZUGCT3T/Munkhdalai et al. - 2024 - Leave No Context Behind Efficient Infinite Contex.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/4AASEVJZ/2404.html}
}

@inproceedings{neumannScispaCyFastRobust2019,
  title = {{{ScispaCy}}: {{Fast}} and {{Robust Models}} for {{Biomedical Natural Language Processing}}},
  shorttitle = {{{ScispaCy}}},
  booktitle = {Proceedings of the 18th {{BioNLP Workshop}} and {{Shared Task}}},
  author = {Neumann, Mark and King, Daniel and Beltagy, Iz and Ammar, Waleed},
  date = {2019},
  eprint = {1902.07669},
  eprinttype = {arxiv},
  eprintclass = {cs},
  pages = {319--327},
  doi = {10.18653/v1/W19-5034},
  url = {http://arxiv.org/abs/1902.07669},
  urldate = {2022-11-19},
  abstract = {Despite recent advances in natural language processing, many statistical models for processing text perform extremely poorly under domain shift. Processing biomedical and clinical text is a critically important application area of natural language processing, for which there are few robust, practical, publicly available models. This paper describes scispaCy, a new tool for practical biomedical/scientific text processing, which heavily leverages the spaCy library. We detail the performance of two packages of models released in scispaCy and demonstrate their robustness on several tasks and datasets. Models and code are available at https://allenai.github.io/scispacy/},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/63C4D6H4/Neumann et al. - 2019 - ScispaCy Fast and Robust Models for Biomedical Na.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/67MPJJUY/1902.html}
}

@online{nguyenEnhancingDomainSpecificFineTuning2024,
  title = {Enhancing {{Q}}\&{{A}} with {{Domain-Specific Fine-Tuning}} and {{Iterative Reasoning}}: {{A Comparative Study}}},
  shorttitle = {Enhancing {{Q}}\&{{A}} with {{Domain-Specific Fine-Tuning}} and {{Iterative Reasoning}}},
  author = {Nguyen, Zooey and Annunziata, Anthony and Luong, Vinh and Dinh, Sang and Le, Quynh and Ha, Anh Hai and Le, Chanh and Phan, Hong An and Raghavan, Shruti and Nguyen, Christopher},
  date = {2024-04-19},
  eprint = {2404.11792},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2404.11792},
  url = {http://arxiv.org/abs/2404.11792},
  urldate = {2024-04-26},
  abstract = {This paper investigates the impact of domain-specific model fine-tuning and of reasoning mechanisms on the performance of question-answering (Q\&A) systems powered by large language models (LLMs) and Retrieval-Augmented Generation (RAG). Using the FinanceBench SEC financial filings dataset, we observe that, for RAG, combining a fine-tuned embedding model with a fine-tuned LLM achieves better accuracy than generic models, with relatively greater gains attributable to fine-tuned embedding models. Additionally, employing reasoning iterations on top of RAG delivers an even bigger jump in performance, enabling the Q\&A systems to get closer to human-expert quality. We discuss the implications of such findings, propose a structured technical design space capturing major technical components of Q\&A AI, and provide recommendations for making high-impact technical choices for such components. We plan to follow up on this work with actionable guides for AI teams and further investigations into the impact of domain-specific augmentation in RAG and into agentic AI capabilities such as advanced planning and reasoning.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/4BPTVK7K/Nguyen et al. - 2024 - Enhancing Q&A with Domain-Specific Fine-Tuning and.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/J3VWHIJ6/2404.html}
}

@online{noriCanGeneralistFoundation2023,
  title = {Can {{Generalist Foundation Models Outcompete Special-Purpose Tuning}}? {{Case Study}} in {{Medicine}}},
  shorttitle = {Can {{Generalist Foundation Models Outcompete Special-Purpose Tuning}}?},
  author = {Nori, Harsha and Lee, Yin Tat and Zhang, Sheng and Carignan, Dean and Edgar, Richard and Fusi, Nicolo and King, Nicholas and Larson, Jonathan and Li, Yuanzhi and Liu, Weishung and Luo, Renqian and McKinney, Scott Mayer and Ness, Robert Osazuwa and Poon, Hoifung and Qin, Tao and Usuyama, Naoto and White, Chris and Horvitz, Eric},
  date = {2023-11-27},
  eprint = {2311.16452},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2311.16452},
  urldate = {2023-12-04},
  abstract = {Generalist foundation models such as GPT-4 have displayed surprising capabilities in a wide variety of domains and tasks. Yet, there is a prevalent assumption that they cannot match specialist capabilities of fine-tuned models. For example, most explorations to date on medical competency benchmarks have leveraged domain-specific training, as exemplified by efforts on BioGPT and Med-PaLM. We build on a prior study of GPT-4's capabilities on medical challenge benchmarks in the absence of special training. Rather than using simple prompting to highlight the model's out-of-the-box capabilities, we perform a systematic exploration of prompt engineering. We find that prompting innovation can unlock deeper specialist capabilities and show that GPT-4 easily tops prior leading results for medical benchmarks. The prompting methods we explore are general purpose, and make no specific use of domain expertise, removing the need for expert-curated content. Our experimental design carefully controls for overfitting during the prompt engineering process. We introduce Medprompt, based on a composition of several prompting strategies. With Medprompt, GPT-4 achieves state-of-the-art results on all nine of the benchmark datasets in the MultiMedQA suite. The method outperforms leading specialist models such as Med-PaLM 2 by a significant margin with an order of magnitude fewer calls to the model. Steering GPT-4 with Medprompt achieves a 27\% reduction in error rate on the MedQA dataset over the best methods to date achieved with specialist models and surpasses a score of 90\% for the first time. Beyond medical problems, we show the power of Medprompt to generalize to other domains and provide evidence for the broad applicability of the approach via studies of the strategy on exams in electrical engineering, machine learning, philosophy, accounting, law, nursing, and clinical psychology.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/9HF84UPV/Nori et al. - 2023 - Can Generalist Foundation Models Outcompete Specia.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/I55WBV8D/2311.html}
}

@misc{NotaDesigningNeural,
  title = {Nota: {{Designing}} Neural Networks through Neuroevolution}
}

@article{opdahlSemanticKnowledgeGraphs2023,
  title = {Semantic {{Knowledge Graphs}} for the {{News}}: {{A Review}}},
  shorttitle = {Semantic {{Knowledge Graphs}} for the {{News}}},
  author = {Opdahl, Andreas L. and Al-Moslmi, Tareq and Dang-Nguyen, Duc-Tien and Gallofré Ocaña, Marc and Tessem, Bjørnar and Veres, Csaba},
  date = {2023-07-31},
  journaltitle = {ACM Computing Surveys},
  shortjournal = {ACM Comput. Surv.},
  volume = {55},
  number = {7},
  pages = {1--38},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3543508},
  url = {https://dl.acm.org/doi/10.1145/3543508},
  urldate = {2023-08-05},
  abstract = {ICT platforms for news production, distribution, and consumption must exploit the ever-growing availability of digital data. These data originate from different sources and in different formats; they arrive at different velocities and in different volumes. Semantic knowledge graphs (KGs) is an established technique for integrating such heterogeneous information. It is therefore well-aligned with the needs of news producers and distributors, and it is likely to become increasingly important for the news industry. This article reviews the research on using semantic knowledge graphs for production, distribution, and consumption of news. The purpose is to present an overview of the field; to investigate what it means; and to suggest opportunities and needs for further research and development.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/UBVSDGDW/Opdahl et al. - 2023 - Semantic Knowledge Graphs for the News A Review.pdf}
}

@article{osmanMultiScaleSkinSample2018,
  title = {Multi-{{Scale Skin Sample Approach}} for {{Dynamic Skin Color Detection}}: {{An Analysis}}},
  shorttitle = {Multi-{{Scale Skin Sample Approach}} for {{Dynamic Skin Color Detection}}},
  author = {Osman, Mohd Zamri and Maarof, Mohd Aizaini and Rohani, Mohd Foad and Moorthy, Kohbalan and Awang, Suryanti},
  date = {2018-10-01},
  journaltitle = {Advanced Science Letters},
  shortjournal = {adv sci lett},
  volume = {24},
  number = {10},
  pages = {7662--7667},
  issn = {1936-6612},
  doi = {10.1166/asl.2018.12996},
  url = {http://www.ingentaconnect.com/content/10.1166/asl.2018.12996},
  urldate = {2023-09-28},
  abstract = {Skin detection is an important step in many computer vision applications. It has been employed in face detection, hand gesture recognition, illicit image filtering, steganography and content based image retrieval. This is due to the skin colour that attractive feature in detecting the skin in coloured image. In contrast, skin colour detection suffers in low accuracy due to colour properties between the real skin surface and the skin-like objects. Therefore, this paper proposes a dynamic skin colour detection using multi-scales online skin sampling approach. This dynamic skin colour detection involved two procedures for generating the dynamic threshold in colour spaces. Moreover, six colour spaces have been studied to find the best colour models for our proposed method. The first procedure is the online skin sampling that obtained directly from the face candidates to generate the dynamic threshold values of each studied colour spaces. Alongside with the first procedure, we obtained optimal scale for skin sample with 0.25, 0.2 reduction, Meanwhile, the second procedure known as skin pixel classification uses the dynamic threshold obtained from the first procedure to classify the skin in the image. We achieved a satisfactory result in term of precision, recall, accuracy and F1. The experimental result shows that the proposed dynamic skin colour detection achieved good performance via 𝑌𝐶𝑟 colour model.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/V96GZ2P3/Osman et al. - 2018 - Multi-Scale Skin Sample Approach for Dynamic Skin .pdf}
}

@online{packerMemGPTLLMsOperating2023,
  title = {{{MemGPT}}: {{Towards LLMs}} as {{Operating Systems}}},
  shorttitle = {{{MemGPT}}},
  author = {Packer, Charles and Fang, Vivian and Patil, Shishir G. and Lin, Kevin and Wooders, Sarah and Gonzalez, Joseph E.},
  date = {2023-10-12},
  url = {https://arxiv.org/abs/2310.08560v1},
  urldate = {2024-01-01},
  abstract = {Large language models (LLMs) have revolutionized AI, but are constrained by limited context windows, hindering their utility in tasks like extended conversations and document analysis. To enable using context beyond limited context windows, we propose virtual context management, a technique drawing inspiration from hierarchical memory systems in traditional operating systems that provide the appearance of large memory resources through data movement between fast and slow memory. Using this technique, we introduce MemGPT (Memory-GPT), a system that intelligently manages different memory tiers in order to effectively provide extended context within the LLM's limited context window, and utilizes interrupts to manage control flow between itself and the user. We evaluate our OS-inspired design in two domains where the limited context windows of modern LLMs severely handicaps their performance: document analysis, where MemGPT is able to analyze large documents that far exceed the underlying LLM's context window, and multi-session chat, where MemGPT can create conversational agents that remember, reflect, and evolve dynamically through long-term interactions with their users. We release MemGPT code and data for our experiments at https://memgpt.ai.},
  langid = {english},
  organization = {arXiv.org},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/IMU3NSXQ/Packer et al. - 2023 - MemGPT Towards LLMs as Operating Systems.pdf}
}

@online{packerMemGPTLLMsOperating2023a,
  title = {{{MemGPT}}: {{Towards LLMs}} as {{Operating Systems}}},
  shorttitle = {{{MemGPT}}},
  author = {Packer, Charles and Fang, Vivian and Patil, Shishir G. and Lin, Kevin and Wooders, Sarah and Gonzalez, Joseph E.},
  date = {2023-10-12},
  eprint = {2310.08560},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2310.08560},
  urldate = {2024-01-01},
  abstract = {Large language models (LLMs) have revolutionized AI, but are constrained by limited context windows, hindering their utility in tasks like extended conversations and document analysis. To enable using context beyond limited context windows, we propose virtual context management, a technique drawing inspiration from hierarchical memory systems in traditional operating systems that provide the appearance of large memory resources through data movement between fast and slow memory. Using this technique, we introduce MemGPT (Memory-GPT), a system that intelligently manages different memory tiers in order to effectively provide extended context within the LLM’s limited context window, and utilizes interrupts to manage control flow between itself and the user. We evaluate our OS-inspired design in two domains where the limited context windows of modern LLMs severely handicaps their performance: document analysis, where MemGPT is able to analyze large documents that far exceed the underlying LLM’s context window, and multi-session chat, where MemGPT can create conversational agents that remember, reflect, and evolve dynamically through long-term interactions with their users. We release MemGPT code and data for our experiments at https://memgpt.ai.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/2RSBZPNR/Packer et al. - 2023 - MemGPT Towards LLMs as Operating Systems.pdf}
}

@inproceedings{paisNamedEntityRecognition2021,
  title = {Named {{Entity Recognition}} in the {{Romanian Legal Domain}}},
  booktitle = {Proceedings of the {{Natural Legal Language Processing Workshop}} 2021},
  author = {Pais, Vasile and Mitrofan, Maria and Gasan, Carol Luca and Coneschi, Vlad and Ianov, Alexandru},
  date = {2021-11},
  pages = {9--18},
  publisher = {Association for Computational Linguistics},
  location = {Punta Cana, Dominican Republic},
  doi = {10.18653/v1/2021.nllp-1.2},
  url = {https://aclanthology.org/2021.nllp-1.2},
  urldate = {2022-11-09},
  abstract = {Recognition of named entities present in text is an important step towards information extraction and natural language understanding. This work presents a named entity recognition system for the Romanian legal domain. The system makes use of the gold annotated LegalNERo corpus. Furthermore, the system combines multiple distributional representations of words, including word embeddings trained on a large legal domain corpus. All the resources, including the corpus, model and word embeddings are open sourced. Finally, the best system is available for direct usage in the RELATE platform.},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/46F72B57/Pais et al. - 2021 - Named Entity Recognition in the Romanian Legal Dom.pdf}
}

@inproceedings{paivaContinuedPretrainingLLMs2024,
  title = {Continued Pre-Training of {{LLMs}} for {{Portuguese}} and {{Government}} Domain: {{A}} Proposal for Product Identification in Textual Purchase Descriptions},
  shorttitle = {Continued Pre-Training of {{LLMs}} for {{Portuguese}} and {{Government}} Domain},
  author = {family=Paiva, given=Eduardo Soares, prefix=de, useprefix=false and Pereira, Fernando Sola and Carvalho, David da Guia and Junior, Nilson Romero Michiles and family=Oliveira, given=Rennis Sousa, prefix=de, useprefix=false and Bonifacio, Stella Mendes Meireles and family=Rocha, given=Andre Luiz Monteiro, prefix=da, useprefix=false and family=Oliveira, given=Hamilton Luiz Rodrigues, prefix=de, useprefix=false and Cezar, Felipe de Abreu Moreira and Junior, Helio Theodoro},
  date = {2024-02-26},
  url = {https://openreview.net/forum?id=HBDb1ybEcs},
  urldate = {2024-04-08},
  abstract = {The present study addresses the issue of identifying products in non-standardized invoices, presenting an approach based on large language models (LLMs). Faced with the scarcity of models trained in the Portuguese language, we proceeded with the pre-training of two LLMs, Lamma2-7B and Mistral-Instruct-7B, followed by fine-tuning for the specific task of product identification. Our central hypothesis, "continuing the pre-training of LLMs with Portuguese texts enhances the model's ability to identify products in textual purchase descriptions", was supported by the results, revealing significant improvements when compared to the original models. This research contributes not only to solving a practical problem but also highlights the effectiveness of continuing the pre-training of a LLM in specific linguistic contexts, such as Portuguese.},
  eventtitle = {{{AAAI-2024 Workshop}} on {{Public Sector LLMs}}: {{Algorithmic}} and {{Sociotechnical Design}}},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/YWHMU3AR/Paiva et al. - 2024 - Continued pre-training of LLMs for Portuguese and .pdf}
}

@article{papadimitriouNLPLinguisticCS224N,
  title = {{{NLP}} and {{Linguistic}}: {{CS224N}}/{{Ling284}}},
  author = {Papadimitriou, Isabel},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/M48BTXQM/Papadimitriou - Natural Language Processing with Deep Learning CS2.pdf}
}

@article{papadopoulosVariationalAutoencodersData2023,
  title = {Variational {{Autoencoders}} for {{Data Augmentation}} in {{Clinical Studies}}},
  author = {Papadopoulos, Dimitris and Karalis, Vangelis D.},
  date = {2023-01},
  journaltitle = {Applied Sciences},
  volume = {13},
  number = {15},
  pages = {8793},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2076-3417},
  doi = {10.3390/app13158793},
  url = {https://www.mdpi.com/2076-3417/13/15/8793},
  urldate = {2023-11-29},
  abstract = {Sample size estimation is critical in clinical trials. A sample of adequate size can provide insights into a given population, but the collection of substantial amounts of data is costly and time-intensive. The aim of this study was to introduce a novel data augmentation approach in the field of clinical trials by employing variational autoencoders (VAEs). Several forms of VAEs were developed and used for the generation of virtual subjects. Various types of VAEs were explored and employed in the production of virtual individuals, and several different scenarios were investigated. The VAE-generated data exhibited similar performance to the original data, even in cases where a small proportion of them (e.g., 30–40\%) was used for the reconstruction of the generated data. Additionally, the generated data showed even higher statistical power than the original data in cases of high variability. This represents an additional advantage for the use of VAEs in situations of high variability, as they can act as noise reduction. The application of VAEs in clinical trials can be a useful tool for decreasing the required sample size and, consequently, reducing the costs and time involved. Furthermore, it aligns with ethical concerns surrounding human participation in trials.},
  issue = {15},
  langid = {english},
  keywords = {clinical trials,data augmentation,sample size,variational autoencoders},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/AL8IDXHT/Papadopoulos y Karalis - 2023 - Variational Autoencoders for Data Augmentation in .pdf}
}

@online{PapersCodeBioBERT,
  title = {Papers with {{Code}} - {{BioBERT}}: A Pre-Trained Biomedical Language Representation Model for Biomedical Text Mining},
  shorttitle = {Papers with {{Code}} - {{BioBERT}}},
  url = {https://paperswithcode.com/paper/biobert-a-pre-trained-biomedical-language},
  urldate = {2022-11-04},
  abstract = {\#3 best model for Named Entity Recognition on NCBI-disease (F1 metric)},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/WRUDBTYE/biobert-a-pre-trained-biomedical-language.html}
}

@online{patilGorillaLargeLanguage2023,
  title = {Gorilla: {{Large Language Model Connected}} with {{Massive APIs}}},
  shorttitle = {Gorilla},
  author = {Patil, Shishir G. and Zhang, Tianjun and Wang, Xin and Gonzalez, Joseph E.},
  date = {2023-05-24},
  eprint = {2305.15334},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2305.15334},
  url = {http://arxiv.org/abs/2305.15334},
  urldate = {2024-04-07},
  abstract = {Large Language Models (LLMs) have seen an impressive wave of advances recently, with models now excelling in a variety of tasks, such as mathematical reasoning and program synthesis. However, their potential to effectively use tools via API calls remains unfulfilled. This is a challenging task even for today's state-of-the-art LLMs such as GPT-4, largely due to their inability to generate accurate input arguments and their tendency to hallucinate the wrong usage of an API call. We release Gorilla, a finetuned LLaMA-based model that surpasses the performance of GPT-4 on writing API calls. When combined with a document retriever, Gorilla demonstrates a strong capability to adapt to test-time document changes, enabling flexible user updates or version changes. It also substantially mitigates the issue of hallucination, commonly encountered when prompting LLMs directly. To evaluate the model's ability, we introduce APIBench, a comprehensive dataset consisting of HuggingFace, TorchHub, and TensorHub APIs. The successful integration of the retrieval system with Gorilla demonstrates the potential for LLMs to use tools more accurately, keep up with frequently updated documentation, and consequently increase the reliability and applicability of their outputs. Gorilla's code, model, data, and demo are available at https://gorilla.cs.berkeley.edu},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/4MTBFHQ2/Patil et al. - 2023 - Gorilla Large Language Model Connected with Massi.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/QSFUBJJY/2305.html}
}

@online{PDFMultiScaleSkin,
  title = {({{PDF}}) {{Multi-Scale Skin Sample Approach}} for {{Dynamic Skin Color Detection}}: {{An Analysis}}},
  url = {https://www.researchgate.net/publication/327992805_Multi-Scale_Skin_Sample_Approach_for_Dynamic_Skin_Color_Detection_An_Analysis},
  urldate = {2023-09-28}
}

@online{pradeepRankZephyrEffectiveRobust2023,
  title = {{{RankZephyr}}: {{Effective}} and {{Robust Zero-Shot Listwise Reranking}} Is a {{Breeze}}!},
  shorttitle = {{{RankZephyr}}},
  author = {Pradeep, Ronak and Sharifymoghaddam, Sahel and Lin, Jimmy},
  date = {2023-12-05},
  eprint = {2312.02724},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2312.02724},
  url = {http://arxiv.org/abs/2312.02724},
  urldate = {2023-12-11},
  abstract = {In information retrieval, proprietary large language models (LLMs) such as GPT-4 and open-source counterparts such as LLaMA and Vicuna have played a vital role in reranking. However, the gap between open-source and closed models persists, with reliance on proprietary, non-transparent models constraining reproducibility. Addressing this gap, we introduce RankZephyr, a state-of-the-art, open-source LLM for listwise zero-shot reranking. RankZephyr not only bridges the effectiveness gap with GPT-4 but in some cases surpasses the proprietary model. Our comprehensive evaluations across several datasets (TREC Deep Learning Tracks; NEWS and COVID from BEIR) showcase this ability. RankZephyr benefits from strategic training choices and is resilient against variations in initial document ordering and the number of documents reranked. Additionally, our model outperforms GPT-4 on the NovelEval test set, comprising queries and passages past its training period, which addresses concerns about data contamination. To foster further research in this rapidly evolving field, we provide all code necessary to reproduce our results at https://github.com/castorini/rank\_llm.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/L6NRGWNR/Pradeep et al. - 2023 - RankZephyr Effective and Robust Zero-Shot Listwis.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/XDCZ6A4L/2312.html}
}

@online{qiStanzaPythonNatural2020,
  title = {Stanza: {{A Python Natural Language Processing Toolkit}} for {{Many Human Languages}}},
  shorttitle = {Stanza},
  author = {Qi, Peng and Zhang, Yuhao and Zhang, Yuhui and Bolton, Jason and Manning, Christopher D.},
  date = {2020-04-23},
  eprint = {2003.07082},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2003.07082},
  urldate = {2022-11-04},
  abstract = {We introduce Stanza, an open-source Python natural language processing toolkit supporting 66 human languages. Compared to existing widely used toolkits, Stanza features a language-agnostic fully neural pipeline for text analysis, including tokenization, multi-word token expansion, lemmatization, part-of-speech and morphological feature tagging, dependency parsing, and named entity recognition. We have trained Stanza on a total of 112 datasets, including the Universal Dependencies treebanks and other multilingual corpora, and show that the same neural architecture generalizes well and achieves competitive performance on all languages tested. Additionally, Stanza includes a native Python interface to the widely used Java Stanford CoreNLP software, which further extends its functionality to cover other tasks such as coreference resolution and relation extraction. Source code, documentation, and pretrained models for 66 languages are available at https://stanfordnlp.github.io/stanza.},
  pubstate = {preprint},
  version = {2},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/SJF6V4R8/Qi et al. - 2020 - Stanza A Python Natural Language Processing Toolk.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/W363Z694/2003.html}
}

@article{r.langeDiscoveringAttentionBasedGenetic2023,
  title = {Discovering {{Attention-Based Genetic Algorithms}} via {{Meta-Black-Box Optimization}}},
  author = {{R. Lange} and {T. Schaul} and {Yutian Chen} and {Chris Xiaoxuan Lu} and {Tom Zahavy} and {Valentin Dalibard} and {Sebastian Flennerhag}},
  date = {2023},
  journaltitle = {arXiv.org},
  doi = {10.48550/arxiv.2304.03995},
  abstract = {Genetic algorithms constitute a family of black-box optimization algorithms, which take inspiration from the principles of biological evolution. While they provide a general-purpose tool for optimization, their particular instantiations can be heuristic and motivated by loose biological intuition. In this work we explore a fundamentally different approach: Given a sufficiently flexible parametrization of the genetic operators, we discover entirely new genetic algorithms in a data-driven fashion. More specifically, we parametrize selection and mutation rate adaptation as cross- and self-attention modules and use Meta-Black-Box-Optimization to evolve their parameters on a set of diverse optimization tasks. The resulting Learned Genetic Algorithm outperforms state-of-the-art adaptive baseline genetic algorithms and generalizes far beyond its meta-training settings. The learned algorithm can be applied to previously unseen optimization problems, search dimensions\&evaluation budgets. We conduct extensive analysis of the discovered operators and provide ablation experiments, which highlight the benefits of flexible module parametrization and the ability to transfer (`plug-in') the learned operators to conventional genetic algorithms.},
  annotation = {ARXIV\_ID: 2304.03995\\
S2ID: 67e4c70a76217ea46751b0dd3bccc7a4a971757d}
}

@video{RADIT,
  entrysubtype = {video},
  title = {{{RA-DIT}}},
  url = {https://www.youtube.com/watch?v=rBpZvMAim5E}
}

@online{rafailovDirectPreferenceOptimization2023,
  title = {Direct {{Preference Optimization}}: {{Your Language Model}} Is {{Secretly}} a {{Reward Model}}},
  shorttitle = {Direct {{Preference Optimization}}},
  author = {Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Ermon, Stefano and Manning, Christopher D. and Finn, Chelsea},
  date = {2023-05-29},
  eprint = {2305.18290},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2305.18290},
  url = {http://arxiv.org/abs/2305.18290},
  urldate = {2023-11-16},
  abstract = {While large-scale unsupervised language models (LMs) learn broad world knowledge and some reasoning skills, achieving precise control of their behavior is difficult due to the completely unsupervised nature of their training. Existing methods for gaining such steerability collect human labels of the relative quality of model generations and fine-tune the unsupervised LM to align with these preferences, often with reinforcement learning from human feedback (RLHF). However, RLHF is a complex and often unstable procedure, first fitting a reward model that reflects the human preferences, and then fine-tuning the large unsupervised LM using reinforcement learning to maximize this estimated reward without drifting too far from the original model. In this paper, we leverage a mapping between reward functions and optimal policies to show that this constrained reward maximization problem can be optimized exactly with a single stage of policy training, essentially solving a classification problem on the human preference data. The resulting algorithm, which we call Direct Preference Optimization (DPO), is stable, performant and computationally lightweight, eliminating the need for fitting a reward model, sampling from the LM during fine-tuning, or performing significant hyperparameter tuning. Our experiments show that DPO can fine-tune LMs to align with human preferences as well as or better than existing methods. Notably, fine-tuning with DPO exceeds RLHF's ability to control sentiment of generations and improves response quality in summarization and single-turn dialogue while being substantially simpler to implement and train.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/EXJZHNMA/Rafailov et al. - 2023 - Direct Preference Optimization Your Language Mode.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/RC8UPDVQ/2305.html}
}

@online{rafailovDirectPreferenceOptimization2023a,
  title = {Direct {{Preference Optimization}}: {{Your Language Model}} Is {{Secretly}} a {{Reward Model}}},
  shorttitle = {Direct {{Preference Optimization}}},
  author = {Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Ermon, Stefano and Manning, Christopher D. and Finn, Chelsea},
  date = {2023-05-29},
  url = {https://arxiv.org/abs/2305.18290v2},
  urldate = {2024-01-12},
  abstract = {While large-scale unsupervised language models (LMs) learn broad world knowledge and some reasoning skills, achieving precise control of their behavior is difficult due to the completely unsupervised nature of their training. Existing methods for gaining such steerability collect human labels of the relative quality of model generations and fine-tune the unsupervised LM to align with these preferences, often with reinforcement learning from human feedback (RLHF). However, RLHF is a complex and often unstable procedure, first fitting a reward model that reflects the human preferences, and then fine-tuning the large unsupervised LM using reinforcement learning to maximize this estimated reward without drifting too far from the original model. In this paper we introduce a new parameterization of the reward model in RLHF that enables extraction of the corresponding optimal policy in closed form, allowing us to solve the standard RLHF problem with only a simple classification loss. The resulting algorithm, which we call Direct Preference Optimization (DPO), is stable, performant, and computationally lightweight, eliminating the need for sampling from the LM during fine-tuning or performing significant hyperparameter tuning. Our experiments show that DPO can fine-tune LMs to align with human preferences as well as or better than existing methods. Notably, fine-tuning with DPO exceeds PPO-based RLHF in ability to control sentiment of generations, and matches or improves response quality in summarization and single-turn dialogue while being substantially simpler to implement and train.},
  langid = {english},
  organization = {arXiv.org},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/B6DUSY95/Rafailov et al. - 2023 - Direct Preference Optimization Your Language Mode.pdf}
}

@article{ramaswamyMulticlassCancerDiagnosis2001,
  title = {Multiclass Cancer Diagnosis Using Tumor Gene Expression Signatures},
  author = {Ramaswamy, Sridhar and Tamayo, Pablo and Rifkin, Ryan and Mukherjee, Sayan and Yeang, Chen-Hsiang and Angelo, Michael and Ladd, Christine and Reich, Michael and Latulippe, Eva and Mesirov, Jill P. and Poggio, Tomaso and Gerald, William and Loda, Massimo and Lander, Eric S. and Golub, Todd R.},
  date = {2001-12-18},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proc. Natl. Acad. Sci. U.S.A.},
  volume = {98},
  number = {26},
  pages = {15149--15154},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.211566398},
  url = {https://pnas.org/doi/full/10.1073/pnas.211566398},
  urldate = {2023-09-18},
  abstract = {The optimal treatment of patients with cancer depends on  establishing accurate diagnoses by using a complex combination of  clinical and histopathological data. In some instances, this task is  difficult or impossible because of atypical clinical presentation or  histopathology. To determine whether the diagnosis of multiple common  adult malignancies could be achieved purely by molecular  classification, we subjected 218 tumor samples, spanning 14  common tumor types, and 90 normal tissue samples to oligonucleotide  microarray gene expression analysis. The expression levels of 16,063  genes and expressed sequence tags were used to evaluate the accuracy of  a multiclass classifier based on a support vector machine algorithm.  Overall classification accuracy was 78\%, far exceeding the accuracy of  random classification (9\%). Poorly differentiated cancers resulted in  low-confidence predictions and could not be accurately classified  according to their tissue of origin, indicating that they are  molecularly distinct entities with dramatically different gene  expression patterns compared with their well differentiated  counterparts. Taken together, these results demonstrate the feasibility  of accurate, multiclass molecular cancer classification and suggest a  strategy for future clinical implementation of molecular cancer  diagnostics.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/YV5QGH9A/Ramaswamy et al. - 2001 - Multiclass cancer diagnosis using tumor gene expre.pdf}
}

@article{ramaswamyMulticlassCancerDiagnosis2001a,
  title = {Multiclass Cancer Diagnosis Using Tumor Gene Expression Signatures},
  author = {Ramaswamy, Sridhar and Tamayo, Pablo and Rifkin, Ryan and Mukherjee, Sayan and Yeang, Chen-Hsiang and Angelo, Michael and Ladd, Christine and Reich, Michael and Latulippe, Eva and Mesirov, Jill P. and Poggio, Tomaso and Gerald, William and Loda, Massimo and Lander, Eric S. and Golub, Todd R.},
  date = {2001-12-18},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {98},
  number = {26},
  pages = {15149--15154},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.211566398},
  url = {https://www.pnas.org/doi/10.1073/pnas.211566398},
  urldate = {2023-09-19},
  abstract = {The optimal treatment of patients with cancer depends on establishing accurate diagnoses by using a complex combination of clinical and histopathological data. In some instances, this task is difficult or impossible because of atypical clinical presentation or histopathology. To determine whether the diagnosis of multiple common adult malignancies could be achieved purely by molecular classification, we subjected 218 tumor samples, spanning 14 common tumor types, and 90 normal tissue samples to oligonucleotide microarray gene expression analysis. The expression levels of 16,063 genes and expressed sequence tags were used to evaluate the accuracy of a multiclass classifier based on a support vector machine algorithm. Overall classification accuracy was 78\%, far exceeding the accuracy of random classification (9\%). Poorly differentiated cancers resulted in low-confidence predictions and could not be accurately classified according to their tissue of origin, indicating that they are molecularly distinct entities with dramatically different gene expression patterns compared with their well differentiated counterparts. Taken together, these results demonstrate the feasibility of accurate, multiclass molecular cancer classification and suggest a strategy for future clinical implementation of molecular cancer diagnostics.},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ZW5VENNW/Ramaswamy et al. - 2001 - Multiclass cancer diagnosis using tumor gene expre.pdf}
}

@article{ramaswamyMulticlassCancerDiagnosis2001b,
  title = {Multiclass Cancer Diagnosis Using Tumor Gene Expression Signatures},
  author = {Ramaswamy, Sridhar and Tamayo, Pablo and Rifkin, Ryan and Mukherjee, Sayan and Yeang, Chen-Hsiang and Angelo, Michael and Ladd, Christine and Reich, Michael and Latulippe, Eva and Mesirov, Jill P. and Poggio, Tomaso and Gerald, William and Loda, Massimo and Lander, Eric S. and Golub, Todd R.},
  date = {2001-12-18},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {98},
  number = {26},
  pages = {15149--15154},
  publisher = {Proceedings of the National Academy of Sciences},
  doi = {10.1073/pnas.211566398},
  url = {https://www.pnas.org/doi/full/10.1073/pnas.211566398},
  urldate = {2023-11-24},
  abstract = {The optimal treatment of patients with cancer depends on establishing accurate diagnoses by using a complex combination of clinical and histopathological data. In some instances, this task is difficult or impossible because of atypical clinical presentation or histopathology. To determine whether the diagnosis of multiple common adult malignancies could be achieved purely by molecular classification, we subjected 218 tumor samples, spanning 14 common tumor types, and 90 normal tissue samples to oligonucleotide microarray gene expression analysis. The expression levels of 16,063 genes and expressed sequence tags were used to evaluate the accuracy of a multiclass classifier based on a support vector machine algorithm. Overall classification accuracy was 78\%, far exceeding the accuracy of random classification (9\%). Poorly differentiated cancers resulted in low-confidence predictions and could not be accurately classified according to their tissue of origin, indicating that they are molecularly distinct entities with dramatically different gene expression patterns compared with their well differentiated counterparts. Taken together, these results demonstrate the feasibility of accurate, multiclass molecular cancer classification and suggest a strategy for future clinical implementation of molecular cancer diagnostics.},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/7A5FL6A6/Ramaswamy et al. - 2001 - Multiclass cancer diagnosis using tumor gene expre.pdf}
}

@online{ramchandranLearningConditionalVariational2022,
  title = {Learning {{Conditional Variational Autoencoders}} with {{Missing Covariates}}},
  author = {Ramchandran, Siddharth and Tikhonov, Gleb and Lönnroth, Otto and Tiikkainen, Pekka and Lähdesmäki, Harri},
  date = {2022-03-02},
  eprint = {2203.01218},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2203.01218},
  urldate = {2023-08-27},
  abstract = {Conditional variational autoencoders (CVAEs) are versatile deep generative models that extend the standard VAE framework by conditioning the generative model with auxiliary covariates. The original CVAE model assumes that the data samples are independent, whereas more recent conditional VAE models, such as the Gaussian process (GP) prior VAEs, can account for complex correlation structures across all data samples. While several methods have been proposed to learn standard VAEs from partially observed datasets, these methods fall short for conditional VAEs. In this work, we propose a method to learn conditional VAEs from datasets in which auxiliary covariates can contain missing values as well. The proposed method augments the conditional VAEs with a prior distribution for the missing covariates and estimates their posterior using amortised variational inference. At training time, our method marginalises the uncertainty associated with the missing covariates while simultaneously maximising the evidence lower bound. We develop computationally efficient methods to learn CVAEs and GP prior VAEs that are compatible with mini-batching. Our experiments on simulated datasets as well as on a clinical trial study show that the proposed method outperforms previous methods in learning conditional VAEs from non-temporal, temporal, and longitudinal datasets.},
  langid = {english},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/83PMV4I4/Ramchandran et al. - 2022 - Learning Conditional Variational Autoencoders with.pdf}
}

@article{remeseiroReviewFeatureSelection2019,
  title = {A Review of Feature Selection Methods in Medical Applications},
  author = {Remeseiro, Beatriz and Bolon-Canedo, Veronica},
  date = {2019-09},
  journaltitle = {Computers in Biology and Medicine},
  shortjournal = {Computers in Biology and Medicine},
  volume = {112},
  pages = {103375},
  issn = {00104825},
  doi = {10.1016/j.compbiomed.2019.103375},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0010482519302525},
  urldate = {2023-08-26},
  abstract = {Feature selection is a preprocessing technique that identifies the key features of a given problem. It has traditionally been applied in a wide range of problems that include biological data processing, finance, and intrusion detection systems. In particular, feature selection has been successfully used in medical applications, where it can not only reduce dimensionality but also help us understand the causes of a disease. We describe some basic concepts related to medical applications and provide some necessary background information on feature selection. We review the most recent feature selection methods developed for and applied in medical problems, covering prolific research fields such as medical imaging, biomedical signal processing, and DNA microarray data analysis. A case study of two medical applications that includes actual patient data is used to demonstrate the suitability of applying feature selection methods in medical problems and to illustrate how these methods work in real-world scenarios.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/THRRJQAX/Remeseiro y Bolon-Canedo - 2019 - A review of feature selection methods in medical a.pdf}
}

@online{richardsonFrameworkFairnessSystematic2021,
  title = {A {{Framework}} for {{Fairness}}: {{A Systematic Review}} of {{Existing Fair AI Solutions}}},
  shorttitle = {A {{Framework}} for {{Fairness}}},
  author = {Richardson, Brianna and Gilbert, Juan E.},
  date = {2021-12-10},
  eprint = {2112.05700},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2112.05700},
  url = {http://arxiv.org/abs/2112.05700},
  urldate = {2023-05-30},
  abstract = {In a world of daily emerging scientific inquisition and discovery, the prolific launch of machine learning across industries comes to little surprise for those familiar with the potential of ML. Neither so should the congruent expansion of ethics-focused research that emerged as a response to issues of bias and unfairness that stemmed from those very same applications. Fairness research, which focuses on techniques to combat algorithmic bias, is now more supported than ever before. A large portion of fairness research has gone to producing tools that machine learning practitioners can use to audit for bias while designing their algorithms. Nonetheless, there is a lack of application of these fairness solutions in practice. This systematic review provides an in-depth summary of the algorithmic bias issues that have been defined and the fairness solution space that has been proposed. Moreover, this review provides an in-depth breakdown of the caveats to the solution space that have arisen since their release and a taxonomy of needs that have been proposed by machine learning practitioners, fairness researchers, and institutional stakeholders. These needs have been organized and addressed to the parties most influential to their implementation, which includes fairness researchers, organizations that produce ML algorithms, and the machine learning practitioners themselves. These findings can be used in the future to bridge the gap between practitioners and fairness experts and inform the creation of usable fair ML toolkits.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/Y65K7WLD/Richardson y Gilbert - 2021 - A Framework for Fairness A Systematic Review of E.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/CZ2AESLC/2112.html}
}

@online{robertsHierarchicalLatentVector2019,
  title = {A {{Hierarchical Latent Vector Model}} for {{Learning Long-Term Structure}} in {{Music}}},
  author = {Roberts, Adam and Engel, Jesse and Raffel, Colin and Hawthorne, Curtis and Eck, Douglas},
  date = {2019-11-11},
  eprint = {1803.05428},
  eprinttype = {arxiv},
  eprintclass = {cs, eess, stat},
  url = {http://arxiv.org/abs/1803.05428},
  urldate = {2023-09-29},
  abstract = {The Variational Autoencoder (VAE) has proven to be an effective model for producing semantically meaningful latent representations for natural data. However, it has thus far seen limited application to sequential data, and, as we demonstrate, existing recurrent VAE models have difficulty modeling sequences with long-term structure. To address this issue, we propose the use of a hierarchical decoder, which first outputs embeddings for subsequences of the input and then uses these embeddings to generate each subsequence independently. This structure encourages the model to utilize its latent code, thereby avoiding the "posterior collapse" problem, which remains an issue for recurrent VAEs. We apply this architecture to modeling sequences of musical notes and find that it exhibits dramatically better sampling, interpolation, and reconstruction performance than a "flat" baseline model. An implementation of our "MusicVAE" is available online at http://g.co/magenta/musicvae-code.},
  pubstate = {preprint},
  keywords = {estado_arte},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/88QSK53K/Roberts et al. - 2019 - A Hierarchical Latent Vector Model for Learning Lo.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/F7NA557Q/1803.html}
}

@article{rogersPrimerBERTologyWhat2020,
  title = {A {{Primer}} in {{BERTology}}: {{What}} We Know about How {{BERT}} Works},
  shorttitle = {A {{Primer}} in {{BERTology}}},
  author = {Rogers, Anna and Kovaleva, Olga and Rumshisky, Anna},
  date = {2020-02-27},
  doi = {10.48550/arXiv.2002.12327},
  url = {https://arxiv.org/abs/2002.12327v3},
  urldate = {2022-11-03},
  abstract = {Transformer-based models have pushed state of the art in many areas of NLP, but our understanding of what is behind their success is still limited. This paper is the first survey of over 150 studies of the popular BERT model. We review the current state of knowledge about how BERT works, what kind of information it learns and how it is represented, common modifications to its training objectives and architecture, the overparameterization issue and approaches to compression. We then outline directions for future research.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/HK3VZEZZ/Rogers et al. - 2020 - A Primer in BERTology What we know about how BERT.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/UN2KLT2Y/2002.html}
}

@article{rogersPrimerBERTologyWhat2020a,
  title = {A {{Primer}} in {{BERTology}}: {{What We Know About How BERT Works}}},
  shorttitle = {A {{Primer}} in {{BERTology}}},
  author = {Rogers, Anna and Kovaleva, Olga and Rumshisky, Anna},
  date = {2020-12},
  journaltitle = {Transactions of the Association for Computational Linguistics},
  shortjournal = {Transactions of the Association for Computational Linguistics},
  volume = {8},
  pages = {842--866},
  issn = {2307-387X},
  doi = {10.1162/tacl_a_00349},
  url = {https://direct.mit.edu/tacl/article/96482},
  urldate = {2022-11-03},
  abstract = {Transformer-based models have pushed state of the art in many areas of NLP, but our understanding of what is behind their success is still limited. This paper is the first survey of over 150 studies of the popular BERT model. We review the current state of knowledge about how BERT works, what kind of information it learns and how it is represented, common modifications to its training objectives and architecture, the overparameterization issue and approaches to compression. We then outline directions for future research.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/MII4XP9S/Rogers et al. - 2020 - A Primer in BERTology What We Know About How BERT.pdf}
}

@online{rosattiSentenciasJudicialesDeben2022,
  title = {Las sentencias judiciales deben ser profundas y claras},
  shorttitle = {Horacio Rosatti},
  author = {Rosatti, Horacio},
  date = {2022-10-27},
  url = {https://www.jusentrerios.gov.ar/2022/10/27/horacio-rosatti-las-sentencias-judiciales-deben-ser-profundas-y-claras/},
  urldate = {2022-11-04},
  langid = {spanish},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/33GJPDX9/horacio-rosatti-las-sentencias-judiciales-deben-ser-profundas-y-claras.html}
}

@online{royRecentTrendsNamed2021,
  title = {Recent {{Trends}} in {{Named Entity Recognition}} ({{NER}})},
  author = {Roy, Arya},
  date = {2021-01-25},
  eprint = {2101.11420},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2101.11420},
  urldate = {2022-11-06},
  abstract = {The availability of large amounts of computer-readable textual data and hardware that can process the data has shifted the focus of knowledge projects towards deep learning architecture. Natural Language Processing, particularly the task of Named Entity Recognition is no exception. The bulk of the learning methods that have produced state-of-the-art results have changed the deep learning model, the training method used, the training data itself or the encoding of the output of the NER system. In this paper, we review significant learning methods that have been employed for NER in the recent past and how they came about from the linear learning methods of the past. We also cover the progress of related tasks that are upstream or downstream to NER, e.g., sequence tagging, entity linking, etc., wherever the processes in question have also improved NER results.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/26G4W85H/Roy - 2021 - Recent Trends in Named Entity Recognition (NER).pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/3ZXUEQIL/2101.html}
}

@book{russellArtificialIntelligenceModern2021,
  title = {Artificial Intelligence: A Modern Approach},
  shorttitle = {Artificial Intelligence},
  author = {Russell, Stuart J. and Norvig, Peter},
  date = {2021},
  series = {Pearson Series in Artificial Intelligence},
  edition = {Fourth edition},
  publisher = {Pearson},
  location = {Hoboken},
  abstract = {"Updated edition of popular textbook on Artificial Intelligence. This edition specific looks at ways of keeping artificial intelligence under control"--},
  isbn = {978-0-13-461099-3},
  langid = {english},
  keywords = {Artificial intelligence},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/DY92ALHR/Russell y Norvig - 2021 - Artificial intelligence a modern approach.pdf}
}

@online{saad-falconARESAutomatedEvaluation2023,
  title = {{{ARES}}: {{An Automated Evaluation Framework}} for {{Retrieval-Augmented Generation Systems}}},
  shorttitle = {{{ARES}}},
  author = {Saad-Falcon, Jon and Khattab, Omar and Potts, Christopher and Zaharia, Matei},
  date = {2023-11-15},
  eprint = {2311.09476},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2311.09476},
  url = {http://arxiv.org/abs/2311.09476},
  urldate = {2023-12-30},
  abstract = {Evaluating retrieval-augmented generation (RAG) systems traditionally relies on hand annotations for input queries, passages to retrieve, and responses to generate. We introduce ARES, an Automated RAG Evaluation System, for evaluating RAG systems along the dimensions of context relevance, answer faithfulness, and answer relevance. Using synthetic training data, ARES finetunes lightweight LM judges to assess the quality of individual RAG components. To mitigate potential prediction errors, ARES utilizes a small set of human-annotated datapoints for prediction-powered inference (PPI). Across six different knowledge-intensive tasks in KILT and SuperGLUE, ARES accurately evaluates RAG systems while using a few hundred human annotations during evaluation. Furthermore, ARES judges remain effective across domain shifts, proving accurate even after changing the type of queries and/or documents used in the evaluated RAG systems. We make our datasets and code for replication and deployment available at https://github.com/stanford-futuredata/ARES.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Information Retrieval},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/68G57RUT/Saad-Falcon et al. - 2023 - ARES An Automated Evaluation Framework for Retrie.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/WRZ2GQWK/2311.html}
}

@article{saeysReviewFeatureSelection2007,
  title = {A Review of Feature Selection Techniques in Bioinformatics},
  author = {Saeys, Yvan and Inza, Iñaki and Larrañaga, Pedro},
  date = {2007-10-01},
  journaltitle = {Bioinformatics},
  volume = {23},
  number = {19},
  pages = {2507--2517},
  issn = {1367-4811, 1367-4803},
  doi = {10.1093/bioinformatics/btm344},
  url = {https://academic.oup.com/bioinformatics/article/23/19/2507/185254},
  urldate = {2023-09-05},
  abstract = {Feature selection techniques have become an apparent need in many bioinformatics applications. In addition to the large pool of techniques that have already been developed in the machine learning and data mining fields, specific applications in bioinformatics have led to a wealth of newly proposed techniques.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/4B5L8CSC/2021 - (Lee) - Android Malware Detection Using Machine Learning with Feature Selection Based on the Genetic Algorithm.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/K4TS2XAR/Saeys et al. - 2007 - A review of feature selection techniques in bioinf.pdf}
}

@online{SAIJNuevaGestion,
  title = {{{SAIJ}} - {{Nueva}} Gestión Judicial},
  url = {http://www.saij.gob.ar/nueva-gestion-judicial-oralidad-procesos-civiles-coordinadores-hector-mario-chayer-juan-pablo-marcet-ministerio-justicia-derechos-humanos-nacion-lb000200-2016-06/123456789-0abc-defg-g00-2000blsorbil},
  urldate = {2022-11-07},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/36BR8ZKR/123456789-0abc-defg-g00-2000blsorbil.html}
}

@inproceedings{samyLegalESSetLarge2020,
  title = {Legal-{{ES}}: {{A Set}} of {{Large Scale Resources}} for {{Spanish Legal Text Processing}}},
  shorttitle = {Legal-{{ES}}},
  booktitle = {Proceedings of the 1st {{Workshop}} on {{Language Technologies}} for {{Government}} and {{Public Administration}} ({{LT4Gov}})},
  author = {Samy, Doaa and Arenas-García, Jerónimo and Pérez-Fernández, David},
  date = {2020-05},
  pages = {32--36},
  publisher = {European Language Resources Association},
  location = {Marseille, France},
  url = {https://aclanthology.org/2020.lt4gov-1.6},
  urldate = {2022-11-08},
  abstract = {Legal-ES is an open source resource kit for legal Spanish. It consists of a large scale Spanish corpus of open legal texts and different kinds of language models including word embeddings and topic models. The corpus includes over 1000 million words covering a collection of legislative and administrative open access documents in Spanish from different sources representing international, national and regional entities. The corpus is pre-processed and tokenized using Spacy. For the word embeddings, gensim was used on the collection of tokens, producing a representation space that is especially suited to reflect the inherent characteristics of the legal domain. We calculate also topic models to obtain a convenient tool to understand the main topics in the corpus and to navigate through the documents exploiting the semantic similarity among documents. We will analyse the time structure of a dynamic topic model to infer changes in the legal production of Spanish jurisdiction that have occurred over the analysed time framework.},
  isbn = {979-10-95546-62-7},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/M2MSPCLI/Samy et al. - 2020 - Legal-ES A Set of Large Scale Resources for Spani.pdf}
}

@article{samyReconocimientoClasificacionEntidades2021,
  title = {Reconocimiento y clasificación de entidades nombradas en textos legales en español},
  author = {Samy, Doaa},
  date = {2021-09-01},
  journaltitle = {Procesamiento del Lenguaje Natural},
  pages = {103--114},
  issn = {1989-7553},
  doi = {10.26342/2021-67-9},
  url = {https://doi.org/10.26342/2021-67-9},
  urldate = {2022-11-04},
  abstract = {Named Entity Recognition and Classification (NER/NERC) is a major task in Natural Language Processing (NLP) and Information Extraction (IE). In the legal domain, NERC is indispensable in developing legal intelligent systems. This study pretends to take a first step towards a baseline for Spanish NERC in the legal domain. The main objective is to provide a linguistic resource by annotating five basic categories of Named Entities in Spanish legislative texts. These five categories are Person, Organization, Location, Dates (absolute expressions) and, finally References to aws, decrees, regulations, etc. To achieve this goal, we adopt a hybrid approach by combining three techniques: hand-crafted patterns through regular expressions, look-up lists and training of three NERC models using the architecture of spaCy. The best model achieved a general f-score of 0.93 with some types of entities such as Legal entities and Dates reaching up to 0.98 and 0.97 respectively. The worst model achieved a general f-score of 0.85, which is still satisfactory given the state of the art.},
  langid = {spanish},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/527D9WEZ/Samy - 2021 - Reconocimiento y clasificación de entidades nombra.pdf}
}

@online{sanhDistilBERTDistilledVersion2020,
  title = {{{DistilBERT}}, a Distilled Version of {{BERT}}: Smaller, Faster, Cheaper and Lighter},
  shorttitle = {{{DistilBERT}}, a Distilled Version of {{BERT}}},
  author = {Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  date = {2020-02-29},
  eprint = {1910.01108},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1910.01108},
  url = {http://arxiv.org/abs/1910.01108},
  urldate = {2022-11-03},
  abstract = {As Transfer Learning from large-scale pre-trained models becomes more prevalent in Natural Language Processing (NLP), operating these large models in on-the-edge and/or under constrained computational training or inference budgets remains challenging. In this work, we propose a method to pre-train a smaller general-purpose language representation model, called DistilBERT, which can then be fine-tuned with good performances on a wide range of tasks like its larger counterparts. While most prior work investigated the use of distillation for building task-specific models, we leverage knowledge distillation during the pre-training phase and show that it is possible to reduce the size of a BERT model by 40\%, while retaining 97\% of its language understanding capabilities and being 60\% faster. To leverage the inductive biases learned by larger models during pre-training, we introduce a triple loss combining language modeling, distillation and cosine-distance losses. Our smaller, faster and lighter model is cheaper to pre-train and we demonstrate its capabilities for on-device computations in a proof-of-concept experiment and a comparative on-device study.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/73X6T6JP/Sanh et al. - 2020 - DistilBERT, a distilled version of BERT smaller, .pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/KTIIKN5P/1910.html}
}

@online{santosBoostingNamedEntity2015,
  title = {Boosting {{Named Entity Recognition}} with {{Neural Character Embeddings}}},
  author = {family=Santos, given=Cicero Nogueira, prefix=dos, useprefix=false and Guimarães, Victor},
  date = {2015-05-25},
  eprint = {1505.05008},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1505.05008},
  urldate = {2022-11-19},
  abstract = {Most state-of-the-art named entity recognition (NER) systems rely on handcrafted features and on the output of other NLP tasks such as part-of-speech (POS) tagging and text chunking. In this work we propose a language-independent NER system that uses automatically learned features only. Our approach is based on the CharWNN deep neural network, which uses word-level and character-level representations (embeddings) to perform sequential classification. We perform an extensive number of experiments using two annotated corpora in two different languages: HAREM I corpus, which contains texts in Portuguese; and the SPA CoNLL-2002 corpus, which contains texts in Spanish. Our experimental results shade light on the contribution of neural character embeddings for NER. Moreover, we demonstrate that the same neural network which has been successfully applied to POS tagging can also achieve state-of-the-art results for language-independet NER, using the same hyperparameters, and without any handcrafted features. For the HAREM I corpus, CharWNN outperforms the state-of-the-art system by 7.9 points in the F1-score for the total scenario (ten NE classes), and by 7.2 points in the F1 for the selective scenario (five NE classes).},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/7V9UXXL8/Santos y Guimarães - 2015 - Boosting Named Entity Recognition with Neural Char.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/GYCLAC9L/1505.html}
}

@online{schickToolformerLanguageModels2023,
  title = {Toolformer: {{Language Models Can Teach Themselves}} to {{Use Tools}}},
  shorttitle = {Toolformer},
  author = {Schick, Timo and Dwivedi-Yu, Jane and Dessì, Roberto and Raileanu, Roberta and Lomeli, Maria and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  date = {2023-02-09},
  eprint = {2302.04761},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2302.04761},
  url = {http://arxiv.org/abs/2302.04761},
  urldate = {2024-04-08},
  abstract = {Language models (LMs) exhibit remarkable abilities to solve new tasks from just a few examples or textual instructions, especially at scale. They also, paradoxically, struggle with basic functionality, such as arithmetic or factual lookup, where much simpler and smaller models excel. In this paper, we show that LMs can teach themselves to use external tools via simple APIs and achieve the best of both worlds. We introduce Toolformer, a model trained to decide which APIs to call, when to call them, what arguments to pass, and how to best incorporate the results into future token prediction. This is done in a self-supervised way, requiring nothing more than a handful of demonstrations for each API. We incorporate a range of tools, including a calculator, a Q\textbackslash\&A system, two different search engines, a translation system, and a calendar. Toolformer achieves substantially improved zero-shot performance across a variety of downstream tasks, often competitive with much larger models, without sacrificing its core language modeling abilities.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/HWSMCXZ5/Schick et al. - 2023 - Toolformer Language Models Can Teach Themselves t.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/AK5JFZR8/2302.html}
}

@online{sequedaBenchmarkUnderstandRole2023,
  title = {A {{Benchmark}} to {{Understand}} the {{Role}} of {{Knowledge Graphs}} on {{Large Language Model}}'s {{Accuracy}} for {{Question Answering}} on {{Enterprise SQL Databases}}},
  author = {Sequeda, Juan and Allemang, Dean and Jacob, Bryon},
  date = {2023-11-13},
  eprint = {2311.07509},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2311.07509},
  url = {http://arxiv.org/abs/2311.07509},
  urldate = {2024-01-17},
  abstract = {Enterprise applications of Large Language Models (LLMs) hold promise for question answering on enterprise SQL databases. However, the extent to which LLMs can accurately respond to enterprise questions in such databases remains unclear, given the absence of suitable Text-to-SQL benchmarks tailored to enterprise settings. Additionally, the potential of Knowledge Graphs (KGs) to enhance LLM-based question answering by providing business context is not well understood. This study aims to evaluate the accuracy of LLM-powered question answering systems in the context of enterprise questions and SQL databases, while also exploring the role of knowledge graphs in improving accuracy. To achieve this, we introduce a benchmark comprising an enterprise SQL schema in the insurance domain, a range of enterprise queries encompassing reporting to metrics, and a contextual layer incorporating an ontology and mappings that define a knowledge graph. Our primary finding reveals that question answering using GPT-4, with zero-shot prompts directly on SQL databases, achieves an accuracy of 16\%. Notably, this accuracy increases to 54\% when questions are posed over a Knowledge Graph representation of the enterprise SQL database. Therefore, investing in Knowledge Graph provides higher accuracy for LLM powered question answering systems.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Databases},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/7NYH4VY3/Sequeda et al. - 2023 - A Benchmark to Understand the Role of Knowledge Gr.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/9EZCNPCH/2311.html}
}

@online{serraGettingDeepRecommenders2017,
  title = {Getting Deep Recommenders Fit: {{Bloom}} Embeddings for Sparse Binary Input/Output Networks},
  shorttitle = {Getting Deep Recommenders Fit},
  author = {Serrà, Joan and Karatzoglou, Alexandros},
  date = {2017-06-13},
  eprint = {1706.03993},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1706.03993},
  urldate = {2022-11-15},
  abstract = {Recommendation algorithms that incorporate techniques from deep learning are becoming increasingly popular. Due to the structure of the data coming from recommendation domains (i.e., one-hot-encoded vectors of item preferences), these algorithms tend to have large input and output dimensionalities that dominate their overall size. This makes them difficult to train, due to the limited memory of graphical processing units, and difficult to deploy on mobile devices with limited hardware. To address these difficulties, we propose Bloom embeddings, a compression technique that can be applied to the input and output of neural network models dealing with sparse high-dimensional binary-coded instances. Bloom embeddings are computationally efficient, and do not seriously compromise the accuracy of the model up to 1/5 compression ratios. In some cases, they even improve over the original accuracy, with relative increases up to 12\%. We evaluate Bloom embeddings on 7 data sets and compare it against 4 alternative methods, obtaining favorable results. We also discuss a number of further advantages of Bloom embeddings, such as 'on-the-fly' constant-time operation, zero or marginal space requirements, training time speedups, or the fact that they do not require any change to the core model architecture or training configuration.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/WQIQB82R/Serrà y Karatzoglou - 2017 - Getting deep recommenders fit Bloom embeddings fo.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/8XZT2UYU/1706.html}
}

@online{serranoRigoBERTaStateoftheArtLanguage2022,
  title = {{{RigoBERTa}}: {{A State-of-the-Art Language Model For Spanish}}},
  shorttitle = {{{RigoBERTa}}},
  author = {Serrano, Alejandro Vaca and Subies, Guillem Garcia and Zamorano, Helena Montoro and Garcia, Nuria Aldama and Samy, Doaa and Sanchez, David Betancur and Sandoval, Antonio Moreno and Nieto, Marta Guerrero and Jimenez, Alvaro Barbero},
  date = {2022-06-03},
  eprint = {2205.10233},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2205.10233},
  urldate = {2022-11-04},
  abstract = {This paper presents RigoBERTa, a State-of-the-Art Language Model for Spanish. RigoBERTa is trained over a well-curated corpus formed up from different subcorpora with key features. It follows the DeBERTa architecture, which has several advantages over other architectures of similar size as BERT or RoBERTa. RigoBERTa performance is assessed over 13 NLU tasks in comparison with other available Spanish language models, namely, MarIA, BERTIN and BETO. RigoBERTa outperformed the three models in 10 out of the 13 tasks, achieving new "State-of-the-Art" results.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/NV7K3WFR/Serrano et al. - 2022 - RigoBERTa A State-of-the-Art Language Model For S.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/Y88P6528/2205.html}
}

@inproceedings{shahWhenFLUEMeets2022,
  title = {When {{FLUE Meets FLANG}}: {{Benchmarks}} and {{Large Pretrained Language Model}} for {{Financial Domain}}},
  shorttitle = {When {{FLUE Meets FLANG}}},
  booktitle = {Proceedings of the 2022 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Shah, Raj and Chawla, Kunal and Eidnani, Dheeraj and Shah, Agam and Du, Wendi and Chava, Sudheer and Raman, Natraj and Smiley, Charese and Chen, Jiaao and Yang, Diyi},
  editor = {Goldberg, Yoav and Kozareva, Zornitsa and Zhang, Yue},
  date = {2022-12},
  pages = {2322--2335},
  publisher = {Association for Computational Linguistics},
  location = {Abu Dhabi, United Arab Emirates},
  doi = {10.18653/v1/2022.emnlp-main.148},
  url = {https://aclanthology.org/2022.emnlp-main.148},
  urldate = {2023-12-24},
  abstract = {Pre-trained language models have shown impressive performance on a variety of tasks and domains. Previous research on financial language models usually employs a generic training scheme to train standard model architectures, without completely leveraging the richness of the financial data. We propose a novel domain specific Financial LANGuage model (FLANG) which uses financial keywords and phrases for better masking, together with span boundary objective and in-filing objective. Additionally, the evaluation benchmarks in the field have been limited. To this end, we contribute the Financial Language Understanding Evaluation (FLUE), an open-source comprehensive suite of benchmarks for the financial domain. These include new benchmarks across 5 NLP tasks in financial domain as well as common benchmarks used in the previous research. Experiments on these benchmarks suggest that our model outperforms those in prior literature on a variety of NLP tasks. Our models, code and benchmark data will be made publicly available on Github and Huggingface.},
  eventtitle = {{{EMNLP}} 2022},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/FKIQVNWK/Shah et al. - 2022 - When FLUE Meets FLANG Benchmarks and Large Pretra.pdf}
}

@inproceedings{shaoEnhancingRetrievalAugmentedLarge2023,
  title = {Enhancing {{Retrieval-Augmented Large Language Models}} with {{Iterative Retrieval-Generation Synergy}}},
  booktitle = {Findings of the {{Association}} for {{Computational Linguistics}}: {{EMNLP}} 2023},
  author = {Shao, Zhihong and Gong, Yeyun and Shen, Yelong and Huang, Minlie and Duan, Nan and Chen, Weizhu},
  date = {2023},
  pages = {9248--9274},
  publisher = {Association for Computational Linguistics},
  location = {Singapore},
  doi = {10.18653/v1/2023.findings-emnlp.620},
  url = {https://aclanthology.org/2023.findings-emnlp.620},
  urldate = {2024-01-10},
  abstract = {Retrieval-augmented generation has raise extensive attention as it is promising to address the limitations of large language models including outdated knowledge and hallucinations. However, retrievers struggle to capture relevance, especially for queries with complex information needs. Recent work has proposed to improve relevance modeling by having large language models actively involved in retrieval, i.e., to guide retrieval with generation. In this paper, we show that strong performance can be achieved by a method we call ITER-RETGEN, which synergizes retrieval and generation in an iterative manner: a model’s response to a task input shows what might be needed to finish the task, and thus can serve as an informative context for retrieving more relevant knowledge which in turn helps generate a better response in another iteration. Compared with recent work which interleaves retrieval with generation when completing a single output, ITERRETGEN processes all retrieved knowledge as a whole and largely preserves the flexibility in generation without structural constraints. We evaluate ITER-RETGEN on multi-hop question answering, fact verification, and commonsense reasoning, and show that it can flexibly leverage parametric knowledge and non-parametric knowledge, and is superior to or competitive with state-of-the-art retrieval-augmented baselines while causing fewer overheads of retrieval and generation. We can further improve performance via generation-augmented retrieval adaptation.},
  eventtitle = {Findings of the {{Association}} for {{Computational Linguistics}}: {{EMNLP}} 2023},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/FEJKDLBI/Shao et al. - 2023 - Enhancing Retrieval-Augmented Large Language Model.pdf}
}

@inproceedings{shaoEnhancingRetrievalAugmentedLarge2023a,
  title = {Enhancing {{Retrieval-Augmented Large Language Models}} with {{Iterative Retrieval-Generation Synergy}}},
  booktitle = {Findings of the {{Association}} for {{Computational Linguistics}}: {{EMNLP}} 2023},
  author = {Shao, Zhihong and Gong, Yeyun and Shen, Yelong and Huang, Minlie and Duan, Nan and Chen, Weizhu},
  date = {2023},
  pages = {9248--9274},
  publisher = {Association for Computational Linguistics},
  location = {Singapore},
  doi = {10.18653/v1/2023.findings-emnlp.620},
  url = {https://aclanthology.org/2023.findings-emnlp.620},
  urldate = {2024-01-10},
  abstract = {Retrieval-augmented generation has raise extensive attention as it is promising to address the limitations of large language models including outdated knowledge and hallucinations. However, retrievers struggle to capture relevance, especially for queries with complex information needs. Recent work has proposed to improve relevance modeling by having large language models actively involved in retrieval, i.e., to guide retrieval with generation. In this paper, we show that strong performance can be achieved by a method we call ITER-RETGEN, which synergizes retrieval and generation in an iterative manner: a model’s response to a task input shows what might be needed to finish the task, and thus can serve as an informative context for retrieving more relevant knowledge which in turn helps generate a better response in another iteration. Compared with recent work which interleaves retrieval with generation when completing a single output, ITERRETGEN processes all retrieved knowledge as a whole and largely preserves the flexibility in generation without structural constraints. We evaluate ITER-RETGEN on multi-hop question answering, fact verification, and commonsense reasoning, and show that it can flexibly leverage parametric knowledge and non-parametric knowledge, and is superior to or competitive with state-of-the-art retrieval-augmented baselines while causing fewer overheads of retrieval and generation. We can further improve performance via generation-augmented retrieval adaptation.},
  eventtitle = {Findings of the {{Association}} for {{Computational Linguistics}}: {{EMNLP}} 2023},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/NXVMRN2Q/Shao et al. - 2023 - Enhancing Retrieval-Augmented Large Language Model.pdf}
}

@inproceedings{shaoEnhancingRetrievalAugmentedLarge2023b,
  title = {Enhancing {{Retrieval-Augmented Large Language Models}} with {{Iterative Retrieval-Generation Synergy}}},
  booktitle = {Findings of the {{Association}} for {{Computational Linguistics}}: {{EMNLP}} 2023},
  author = {Shao, Zhihong and Gong, Yeyun and Shen, Yelong and Huang, Minlie and Duan, Nan and Chen, Weizhu},
  date = {2023},
  pages = {9248--9274},
  publisher = {Association for Computational Linguistics},
  location = {Singapore},
  doi = {10.18653/v1/2023.findings-emnlp.620},
  url = {https://aclanthology.org/2023.findings-emnlp.620},
  urldate = {2024-01-10},
  abstract = {Retrieval-augmented generation has raise extensive attention as it is promising to address the limitations of large language models including outdated knowledge and hallucinations. However, retrievers struggle to capture relevance, especially for queries with complex information needs. Recent work has proposed to improve relevance modeling by having large language models actively involved in retrieval, i.e., to guide retrieval with generation. In this paper, we show that strong performance can be achieved by a method we call ITER-RETGEN, which synergizes retrieval and generation in an iterative manner: a model’s response to a task input shows what might be needed to finish the task, and thus can serve as an informative context for retrieving more relevant knowledge which in turn helps generate a better response in another iteration. Compared with recent work which interleaves retrieval with generation when completing a single output, ITERRETGEN processes all retrieved knowledge as a whole and largely preserves the flexibility in generation without structural constraints. We evaluate ITER-RETGEN on multi-hop question answering, fact verification, and commonsense reasoning, and show that it can flexibly leverage parametric knowledge and non-parametric knowledge, and is superior to or competitive with state-of-the-art retrieval-augmented baselines while causing fewer overheads of retrieval and generation. We can further improve performance via generation-augmented retrieval adaptation.},
  eventtitle = {Findings of the {{Association}} for {{Computational Linguistics}}: {{EMNLP}} 2023},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/H5G5BTK6/Shao et al. - 2023 - Enhancing Retrieval-Augmented Large Language Model.pdf}
}

@article{sharmaComprehensiveAnalysisNatureInspired2021,
  title = {A {{Comprehensive Analysis}} of {{Nature-Inspired Meta-Heuristic Techniques}} for {{Feature Selection Problem}}},
  author = {Sharma, Manik and Kaur, Prableen},
  date = {2021-05},
  journaltitle = {Archives of Computational Methods in Engineering},
  shortjournal = {Arch Computat Methods Eng},
  volume = {28},
  number = {3},
  pages = {1103--1127},
  issn = {1134-3060, 1886-1784},
  doi = {10.1007/s11831-020-09412-6},
  url = {https://link.springer.com/10.1007/s11831-020-09412-6},
  urldate = {2023-08-26},
  abstract = {Meta-heuristics are problem-independent optimization techniques which provide an optimal solution by exploring and exploiting the entire search space iteratively. These techniques have been successfully engaged to solve distinct real-life and multidisciplinary problems. A good amount of literature has been already published on the design and role of various metaheuristic algorithms and on their variants. The aim of this study is to present a comprehensive analysis of nature-inspired meta-heuristic utilized in the domain of feature selection. A systematic review methodology has been used for synthesis and analysis of one hundered and seventy six articles. It is one of the important multidisciplinary research areas that assist in finding an optimal set of features so that a better rate of classification can be achieved. The concept of feature selection process along with relevance and redundancy metric is briefly elucidated. A categorical list of nature-inspired meta-heuristic techniques has been presented. The major applications of these techniques are explored to highlight the least and most explored areas. The area of disease diagnosis has been extensively assessed. In addition, the special attention has been given on highlighting the role and performance of binary and chaotic variants of different nature-inspired meta-heuristic techniques. The summary of nature-inspired meta-heuristic methods and their variants along with datasets, performance (mean, best, worst, error rate and standard deviation) is also depicted. In addition, the detailed publication trend of meta-heuristic feature selection approaches has also been presented. The research gaps have been identified for the researcher who inclines to design or analyze the performance of divergent meta-heuristic techniques in solving feature selection problem.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/HDRWRYDC/Sharma y Kaur - 2021 - A Comprehensive Analysis of Nature-Inspired Meta-H.pdf}
}

@online{shenMixtureofExpertsMeetsInstruction2023,
  title = {Mixture-of-{{Experts Meets Instruction Tuning}}:{{A Winning Combination}} for {{Large Language Models}}},
  shorttitle = {Mixture-of-{{Experts Meets Instruction Tuning}}},
  author = {Shen, Sheng and Hou, Le and Zhou, Yanqi and Du, Nan and Longpre, Shayne and Wei, Jason and Chung, Hyung Won and Zoph, Barret and Fedus, William and Chen, Xinyun and Vu, Tu and Wu, Yuexin and Chen, Wuyang and Webson, Albert and Li, Yunxuan and Zhao, Vincent and Yu, Hongkun and Keutzer, Kurt and Darrell, Trevor and Zhou, Denny},
  date = {2023-07-05},
  eprint = {2305.14705},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2305.14705},
  url = {http://arxiv.org/abs/2305.14705},
  urldate = {2024-03-28},
  abstract = {Sparse Mixture-of-Experts (MoE) is a neural architecture design that can be utilized to add learnable parameters to Large Language Models (LLMs) without increasing inference cost. Instruction tuning is a technique for training LLMs to follow instructions. We advocate combining these two approaches, as we find that MoE models benefit more from instruction tuning than dense models. In particular, we conduct empirical studies across three experimental setups: (i) Direct finetuning on individual downstream tasks devoid of instruction tuning; (ii) Instructiontuning followed by in-context few-shot or zero-shot generalization on downstream tasks; and (iii) Instruction tuning supplemented by further finetuning on individual downstream tasks. In the first scenario, MoE models overall underperform dense models of identical computational capacity. This narrative, however, dramatically changes with the introduction of instruction tuning (second and third scenario), used independently or in conjunction with task-specific finetuning. Our most powerful model, FLAN-MOE-32B, surpasses the performance of FLAN-PALM-62B on four benchmark tasks, while using only a third of the FLOPs. The advancements embodied byFLAN-MOE inspire a reevaluation of the design principles of large-scale, high-performance language models in the framework of task-agnostic learning.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/9JHIUMT5/Shen et al. - 2023 - Mixture-of-Experts Meets Instruction TuningA Winn.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/GQJ9E2KX/2305.html}
}

@article{shortenSurveyImageData2019,
  title = {A Survey on {{Image Data Augmentation}} for {{Deep Learning}}},
  author = {Shorten, Connor and Khoshgoftaar, Taghi M.},
  date = {2019-12},
  journaltitle = {Journal of Big Data},
  shortjournal = {J Big Data},
  volume = {6},
  number = {1},
  pages = {60},
  issn = {2196-1115},
  doi = {10.1186/s40537-019-0197-0},
  url = {https://journalofbigdata.springeropen.com/articles/10.1186/s40537-019-0197-0},
  urldate = {2023-09-28},
  abstract = {Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfortunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The application of augmentation methods based on GANs are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other characteristics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/V23STZGN/Shorten y Khoshgoftaar - 2019 - A survey on Image Data Augmentation for Deep Learn.pdf}
}

@online{singhalExpertLevelMedicalQuestion2023,
  title = {Towards {{Expert-Level Medical Question Answering}} with {{Large Language Models}}},
  author = {Singhal, Karan and Tu, Tao and Gottweis, Juraj and Sayres, Rory and Wulczyn, Ellery and Hou, Le and Clark, Kevin and Pfohl, Stephen and Cole-Lewis, Heather and Neal, Darlene and Schaekermann, Mike and Wang, Amy and Amin, Mohamed and Lachgar, Sami and Mansfield, Philip and Prakash, Sushant and Green, Bradley and Dominowska, Ewa and family=Arcas, given=Blaise Aguera, prefix=y, useprefix=false and Tomasev, Nenad and Liu, Yun and Wong, Renee and Semturs, Christopher and Mahdavi, S. Sara and Barral, Joelle and Webster, Dale and Corrado, Greg S. and Matias, Yossi and Azizi, Shekoofeh and Karthikesalingam, Alan and Natarajan, Vivek},
  date = {2023-05-16},
  eprint = {2305.09617},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2305.09617},
  urldate = {2024-04-17},
  abstract = {Recent artificial intelligence (AI) systems have reached milestones in "grand challenges" ranging from Go to protein-folding. The capability to retrieve medical knowledge, reason over it, and answer medical questions comparably to physicians has long been viewed as one such grand challenge. Large language models (LLMs) have catalyzed significant progress in medical question answering; Med-PaLM was the first model to exceed a "passing" score in US Medical Licensing Examination (USMLE) style questions with a score of 67.2\% on the MedQA dataset. However, this and other prior work suggested significant room for improvement, especially when models' answers were compared to clinicians' answers. Here we present Med-PaLM 2, which bridges these gaps by leveraging a combination of base LLM improvements (PaLM 2), medical domain finetuning, and prompting strategies including a novel ensemble refinement approach. Med-PaLM 2 scored up to 86.5\% on the MedQA dataset, improving upon Med-PaLM by over 19\% and setting a new state-of-the-art. We also observed performance approaching or exceeding state-of-the-art across MedMCQA, PubMedQA, and MMLU clinical topics datasets. We performed detailed human evaluations on long-form questions along multiple axes relevant to clinical applications. In pairwise comparative ranking of 1066 consumer medical questions, physicians preferred Med-PaLM 2 answers to those produced by physicians on eight of nine axes pertaining to clinical utility (p {$<$} 0.001). We also observed significant improvements compared to Med-PaLM on every evaluation axis (p {$<$} 0.001) on newly introduced datasets of 240 long-form "adversarial" questions to probe LLM limitations. While further studies are necessary to validate the efficacy of these models in real-world settings, these results highlight rapid progress towards physician-level performance in medical question answering.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/FYVEFNR6/Singhal et al. - 2023 - Towards Expert-Level Medical Question Answering wi.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/TQ36YUIG/2305.html}
}

@article{sipperInvestigatingParameterSpace2018,
  title = {Investigating the Parameter Space of Evolutionary Algorithms.},
  author = {Sipper, Moshe and Fu, Weixuan and Ahuja, Karuna and Moore, Jason H.},
  date = {2018-02-17},
  journaltitle = {Biodata Mining},
  volume = {11},
  number = {1},
  pages = {1--14},
  doi = {10.1186/s13040-018-0164-x},
  abstract = {Evolutionary computation (EC) has been widely applied to biological and biomedical data. The practice of EC involves the tuning of many parameters, such as population size, generation count, selection size, and crossover and mutation rates. Through an extensive series of experiments over multiple evolutionary algorithm implementations and 25 problems we show that parameter space tends to be rife with viable parameters, at least for the problems studied herein. We discuss the implications of this finding in practice for the researcher employing EC.},
  annotation = {MAG ID: 2763934033\\
S2ID: b947eccf85f240c9fa35bf8e5f6761b651898853}
}

@online{sipperMeltingPotEvolution2023,
  title = {A {{Melting Pot}} of {{Evolution}} and {{Learning}}},
  author = {Sipper, Moshe and Elyasaf, Achiya and Halperin, Tomer and Haramaty, Zvika and Lapid, Raz and Segal, Eyal and Tzruia, Itai and Tamam, Snir Vitrack},
  date = {2023-06-08},
  eprint = {2306.04971},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2306.04971},
  urldate = {2023-06-27},
  abstract = {We survey eight recent works by our group, involving the successful blending of evolutionary algorithms with machine learning and deep learning: 1. Binary and Multinomial Classification through Evolutionary Symbolic Regression, 2. Classy Ensemble: A Novel Ensemble Algorithm for Classification, 3. EC-KitY: Evolutionary Computation Tool Kit in Python, 4. Evolution of Activation Functions for Deep Learning-Based Image Classification, 5. Adaptive Combination of a Genetic Algorithm and Novelty Search for Deep Neuroevolution, 6. An Evolutionary, Gradient-Free, Query-Efficient, Black-Box Algorithm for Generating Adversarial Instances in Deep Networks, 7. Foiling Explanations in Deep Neural Networks, 8. Patch of Invisibility: Naturalistic Black-Box Adversarial Attacks on Object Detectors.},
  pubstate = {preprint}
}

@online{skylakiNamedEntityRecognition2020,
  title = {Named {{Entity Recognition}} in the {{Legal Domain}} Using a {{Pointer Generator Network}}},
  author = {Skylaki, Stavroula and Oskooei, Ali and Bari, Omar and Herger, Nadja and Kriegman, Zac},
  date = {2020-12-17},
  eprint = {2012.09936},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2012.09936},
  urldate = {2022-11-09},
  abstract = {Named Entity Recognition (NER) is the task of identifying and classifying named entities in unstructured text. In the legal domain, named entities of interest may include the case parties, judges, names of courts, case numbers, references to laws etc. We study the problem of legal NER with noisy text extracted from PDF files of filed court cases from US courts. The "gold standard" training data for NER systems provide annotation for each token of the text with the corresponding entity or non-entity label. We work with only partially complete training data, which differ from the gold standard NER data in that the exact location of the entities in the text is unknown and the entities may contain typos and/or OCR mistakes. To overcome the challenges of our noisy training data, e.g. text extraction errors and/or typos and unknown label indices, we formulate the NER task as a text-to-text sequence generation task and train a pointer generator network to generate the entities in the document rather than label them. We show that the pointer generator can be effective for NER in the absence of gold standard data and outperforms the common NER neural network architectures in long legal documents.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/AZF2EWVY/Skylaki et al. - 2020 - Named Entity Recognition in the Legal Domain using.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/8JB392QW/2012.html}
}

@online{sloss2019EvolutionaryAlgorithms2019,
  title = {2019 {{Evolutionary Algorithms Review}}},
  author = {Sloss, Andrew N. and Gustafson, Steven},
  date = {2019-06-03},
  eprint = {1906.08870},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1906.08870},
  url = {http://arxiv.org/abs/1906.08870},
  urldate = {2023-09-05},
  abstract = {Evolutionary algorithm research and applications began over 50 years ago. Like other artificial intelligence techniques, evolutionary algorithms will likely see increased use and development due to the increased availability of computation, more robust and available open source software libraries, and the increasing demand for artificial intelligence techniques. As these techniques become more adopted and capable, it is the right time to take a perspective of their ability to integrate into society and the human processes they intend to augment. In this review, we explore a new taxonomy of evolutionary algorithms and resulting classifications that look at five main areas: the ability to manage the control of the environment with limiters, the ability to explain and repeat the search process, the ability to understand input and output causality within a solution, the ability to manage algorithm bias due to data or user design, and lastly, the ability to add corrective measures. These areas are motivated by today's pressures on industry to conform to both societies concerns and new government regulatory rules. As many reviews of evolutionary algorithms exist, after motivating this new taxonomy, we briefly classify a broad range of algorithms and identify areas of future research.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/C2YSNM3L/Sloss y Gustafson - 2019 - 2019 Evolutionary Algorithms Review.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/8V2L9GBA/1906.html}
}

@article{solorio-fernandezReviewUnsupervisedFeature2020,
  title = {A Review of Unsupervised Feature Selection Methods},
  author = {Solorio-Fernández, Saúl and Carrasco-Ochoa, J. Ariel and Martínez-Trinidad, José Fco.},
  date = {2020-02},
  journaltitle = {Artificial Intelligence Review},
  shortjournal = {Artif Intell Rev},
  volume = {53},
  number = {2},
  pages = {907--948},
  issn = {0269-2821, 1573-7462},
  doi = {10.1007/s10462-019-09682-y},
  url = {http://link.springer.com/10.1007/s10462-019-09682-y},
  urldate = {2023-08-26},
  abstract = {In recent years, unsupervised feature selection methods have raised considerable interest in many research areas; this is mainly due to their ability to identify and select relevant features without needing class label information. In this paper, we provide a comprehensive and structured review of the most relevant and recent unsupervised feature selection methods reported in the literature. We present a taxonomy of these methods and describe the main characteristics and the fundamental ideas they are based on. Additionally, we summarized the advantages and disadvantages of the general lines in which we have categorized the methods analyzed in this review. Moreover, an experimental comparison among the most representative methods of each approach is also presented. Finally, we discuss some important open challenges in this research area.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/N5EREN6L/Solorio-Fernández et al. - 2020 - A review of unsupervised feature selection methods.pdf}
}

@online{srivastavaImitationGameQuantifying2022,
  title = {Beyond the {{Imitation Game}}: {{Quantifying}} and Extrapolating the Capabilities of Language Models},
  shorttitle = {Beyond the {{Imitation Game}}},
  author = {Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R. and Santoro, Adam and Gupta, Aditya and Garriga-Alonso, Adrià and Kluska, Agnieszka and Lewkowycz, Aitor and Agarwal, Akshat and Power, Alethea and Ray, Alex and Warstadt, Alex and Kocurek, Alexander W. and Safaya, Ali and Tazarv, Ali and Xiang, Alice and Parrish, Alicia and Nie, Allen and Hussain, Aman and Askell, Amanda and Dsouza, Amanda and Slone, Ambrose and Rahane, Ameet and Iyer, Anantharaman S. and Andreassen, Anders and Madotto, Andrea and Santilli, Andrea and Stuhlmüller, Andreas and Dai, Andrew and La, Andrew and Lampinen, Andrew and Zou, Andy and Jiang, Angela and Chen, Angelica and Vuong, Anh and Gupta, Animesh and Gottardi, Anna and Norelli, Antonio and Venkatesh, Anu and Gholamidavoodi, Arash and Tabassum, Arfa and Menezes, Arul and Kirubarajan, Arun and Mullokandov, Asher and Sabharwal, Ashish and Herrick, Austin and Efrat, Avia and Erdem, Aykut and Karakaş, Ayla and Roberts, B. Ryan and Loe, Bao Sheng and Zoph, Barret and Bojanowski, Bartłomiej and Özyurt, Batuhan and Hedayatnia, Behnam and Neyshabur, Behnam and Inden, Benjamin and Stein, Benno and Ekmekci, Berk and Lin, Bill Yuchen and Howald, Blake and Diao, Cameron and Dour, Cameron and Stinson, Catherine and Argueta, Cedrick and Ramírez, César Ferri and Singh, Chandan and Rathkopf, Charles and Meng, Chenlin and Baral, Chitta and Wu, Chiyu and Callison-Burch, Chris and Waites, Chris and Voigt, Christian and Manning, Christopher D. and Potts, Christopher and Ramirez, Cindy and Rivera, Clara E. and Siro, Clemencia and Raffel, Colin and Ashcraft, Courtney and Garbacea, Cristina and Sileo, Damien and Garrette, Dan and Hendrycks, Dan and Kilman, Dan and Roth, Dan and Freeman, Daniel and Khashabi, Daniel and Levy, Daniel and González, Daniel Moseguí and Perszyk, Danielle and Hernandez, Danny and Chen, Danqi and Ippolito, Daphne and Gilboa, Dar and Dohan, David and Drakard, David and Jurgens, David and Datta, Debajyoti and Ganguli, Deep and Emelin, Denis and Kleyko, Denis and Yuret, Deniz and Chen, Derek and Tam, Derek and Hupkes, Dieuwke and Misra, Diganta and Buzan, Dilyar and Mollo, Dimitri Coelho and Yang, Diyi and Lee, Dong-Ho and Shutova, Ekaterina and Cubuk, Ekin Dogus and Segal, Elad and Hagerman, Eleanor and Barnes, Elizabeth and Donoway, Elizabeth and Pavlick, Ellie and Rodola, Emanuele and Lam, Emma and Chu, Eric and Tang, Eric and Erdem, Erkut and Chang, Ernie and Chi, Ethan A. and Dyer, Ethan and Jerzak, Ethan and Kim, Ethan and Manyasi, Eunice Engefu and Zheltonozhskii, Evgenii and Xia, Fanyue and Siar, Fatemeh and Martínez-Plumed, Fernando and Happé, Francesca and Chollet, Francois and Rong, Frieda and Mishra, Gaurav and Winata, Genta Indra and family=Melo, given=Gerard, prefix=de, useprefix=true and Kruszewski, Germán and Parascandolo, Giambattista and Mariani, Giorgio and Wang, Gloria and Jaimovitch-López, Gonzalo and Betz, Gregor and Gur-Ari, Guy and Galijasevic, Hana and Kim, Hannah and Rashkin, Hannah and Hajishirzi, Hannaneh and Mehta, Harsh and Bogar, Hayden and Shevlin, Henry and Schütze, Hinrich and Yakura, Hiromu and Zhang, Hongming and Wong, Hugh Mee and Ng, Ian and Noble, Isaac and Jumelet, Jaap and Geissinger, Jack and Kernion, Jackson and Hilton, Jacob and Lee, Jaehoon and Fisac, Jaime Fernández and Simon, James B. and Koppel, James and Zheng, James and Zou, James and Kocoń, Jan and Thompson, Jana and Kaplan, Jared and Radom, Jarema and Sohl-Dickstein, Jascha and Phang, Jason and Wei, Jason and Yosinski, Jason and Novikova, Jekaterina and Bosscher, Jelle and Marsh, Jennifer and Kim, Jeremy and Taal, Jeroen and Engel, Jesse and Alabi, Jesujoba and Xu, Jiacheng and Song, Jiaming and Tang, Jillian and Waweru, Joan and Burden, John and Miller, John and Balis, John U. and Berant, Jonathan and Frohberg, Jörg and Rozen, Jos and Hernandez-Orallo, Jose and Boudeman, Joseph and Jones, Joseph and Tenenbaum, Joshua B. and Rule, Joshua S. and Chua, Joyce and Kanclerz, Kamil and Livescu, Karen and Krauth, Karl and Gopalakrishnan, Karthik and Ignatyeva, Katerina and Markert, Katja and Dhole, Kaustubh D. and Gimpel, Kevin and Omondi, Kevin and Mathewson, Kory and Chiafullo, Kristen and Shkaruta, Ksenia and Shridhar, Kumar and McDonell, Kyle and Richardson, Kyle and Reynolds, Laria and Gao, Leo and Zhang, Li and Dugan, Liam and Qin, Lianhui and Contreras-Ochando, Lidia and Morency, Louis-Philippe and Moschella, Luca and Lam, Lucas and Noble, Lucy and Schmidt, Ludwig and He, Luheng and Colón, Luis Oliveros and Metz, Luke and Şenel, Lütfi Kerem and Bosma, Maarten and Sap, Maarten and family=Hoeve, given=Maartje, prefix=ter, useprefix=true and Farooqi, Maheen and Faruqui, Manaal and Mazeika, Mantas and Baturan, Marco and Marelli, Marco and Maru, Marco and Quintana, Maria Jose Ramírez and Tolkiehn, Marie and Giulianelli, Mario and Lewis, Martha and Potthast, Martin and Leavitt, Matthew L. and Hagen, Matthias and Schubert, Mátyás and Baitemirova, Medina Orduna and Arnaud, Melody and McElrath, Melvin and Yee, Michael A. and Cohen, Michael and Gu, Michael and Ivanitskiy, Michael and Starritt, Michael and Strube, Michael and Swędrowski, Michał and Bevilacqua, Michele and Yasunaga, Michihiro and Kale, Mihir and Cain, Mike and Xu, Mimee and Suzgun, Mirac and Tiwari, Mo and Bansal, Mohit and Aminnaseri, Moin and Geva, Mor and Gheini, Mozhdeh and T, Mukund Varma and Peng, Nanyun and Chi, Nathan and Lee, Nayeon and Krakover, Neta Gur-Ari and Cameron, Nicholas and Roberts, Nicholas and Doiron, Nick and Nangia, Nikita and Deckers, Niklas and Muennighoff, Niklas and Keskar, Nitish Shirish and Iyer, Niveditha S. and Constant, Noah and Fiedel, Noah and Wen, Nuan and Zhang, Oliver and Agha, Omar and Elbaghdadi, Omar and Levy, Omer and Evans, Owain and Casares, Pablo Antonio Moreno and Doshi, Parth and Fung, Pascale and Liang, Paul Pu and Vicol, Paul and Alipoormolabashi, Pegah and Liao, Peiyuan and Liang, Percy and Chang, Peter and Eckersley, Peter and Htut, Phu Mon and Hwang, Pinyu and Miłkowski, Piotr and Patil, Piyush and Pezeshkpour, Pouya and Oli, Priti and Mei, Qiaozhu and Lyu, Qing and Chen, Qinlang and Banjade, Rabin and Rudolph, Rachel Etta and Gabriel, Raefer and Habacker, Rahel and Delgado, Ramón Risco and Millière, Raphaël and Garg, Rhythm and Barnes, Richard and Saurous, Rif A. and Arakawa, Riku and Raymaekers, Robbe and Frank, Robert and Sikand, Rohan and Novak, Roman and Sitelew, Roman and LeBras, Ronan and Liu, Rosanne and Jacobs, Rowan and Zhang, Rui and Salakhutdinov, Ruslan and Chi, Ryan and Lee, Ryan and Stovall, Ryan and Teehan, Ryan and Yang, Rylan and Singh, Sahib and Mohammad, Saif M. and Anand, Sajant and Dillavou, Sam and Shleifer, Sam and Wiseman, Sam and Gruetter, Samuel and Bowman, Samuel R. and Schoenholz, Samuel S. and Han, Sanghyun and Kwatra, Sanjeev and Rous, Sarah A. and Ghazarian, Sarik and Ghosh, Sayan and Casey, Sean and Bischoff, Sebastian and Gehrmann, Sebastian and Schuster, Sebastian and Sadeghi, Sepideh and Hamdan, Shadi and Zhou, Sharon and Srivastava, Shashank and Shi, Sherry and Singh, Shikhar and Asaadi, Shima and Gu, Shixiang Shane and Pachchigar, Shubh and Toshniwal, Shubham and Upadhyay, Shyam and Shyamolima and Debnath and Shakeri, Siamak and Thormeyer, Simon and Melzi, Simone and Reddy, Siva and Makini, Sneha Priscilla and Lee, Soo-Hwan and Torene, Spencer and Hatwar, Sriharsha and Dehaene, Stanislas and Divic, Stefan and Ermon, Stefano and Biderman, Stella and Lin, Stephanie and Prasad, Stephen and Piantadosi, Steven T. and Shieber, Stuart M. and Misherghi, Summer and Kiritchenko, Svetlana and Mishra, Swaroop and Linzen, Tal and Schuster, Tal and Li, Tao and Yu, Tao and Ali, Tariq and Hashimoto, Tatsu and Wu, Te-Lin and Desbordes, Théo and Rothschild, Theodore and Phan, Thomas and Wang, Tianle and Nkinyili, Tiberius and Schick, Timo and Kornev, Timofei and Telleen-Lawton, Timothy and Tunduny, Titus and Gerstenberg, Tobias and Chang, Trenton and Neeraj, Trishala and Khot, Tushar and Shultz, Tyler and Shaham, Uri and Misra, Vedant and Demberg, Vera and Nyamai, Victoria and Raunak, Vikas and Ramasesh, Vinay and Prabhu, Vinay Uday and Padmakumar, Vishakh and Srikumar, Vivek and Fedus, William and Saunders, William and Zhang, William and Vossen, Wout and Ren, Xiang and Tong, Xiaoyu and Zhao, Xinran and Wu, Xinyi and Shen, Xudong and Yaghoobzadeh, Yadollah and Lakretz, Yair and Song, Yangqiu and Bahri, Yasaman and Choi, Yejin and Yang, Yichi and Hao, Yiding and Chen, Yifu and Belinkov, Yonatan and Hou, Yu and Hou, Yufang and Bai, Yuntao and Seid, Zachary and Zhao, Zhuoye and Wang, Zijian and Wang, Zijie J. and Wang, Zirui and Wu, Ziyi},
  date = {2022-06-10},
  eprint = {2206.04615},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.2206.04615},
  url = {http://arxiv.org/abs/2206.04615},
  urldate = {2023-05-17},
  abstract = {Language models demonstrate both quantitative improvement and new qualitative capabilities with increasing scale. Despite their potentially transformative impact, these new capabilities are as yet poorly characterized. In order to inform future research, prepare for disruptive new model capabilities, and ameliorate socially harmful effects, it is vital that we understand the present and near-future capabilities and limitations of language models. To address this challenge, we introduce the Beyond the Imitation Game benchmark (BIG-bench). BIG-bench currently consists of 204 tasks, contributed by 442 authors across 132 institutions. Task topics are diverse, drawing problems from linguistics, childhood development, math, common-sense reasoning, biology, physics, social bias, software development, and beyond. BIG-bench focuses on tasks that are believed to be beyond the capabilities of current language models. We evaluate the behavior of OpenAI's GPT models, Google-internal dense transformer architectures, and Switch-style sparse transformers on BIG-bench, across model sizes spanning millions to hundreds of billions of parameters. In addition, a team of human expert raters performed all tasks in order to provide a strong baseline. Findings include: model performance and calibration both improve with scale, but are poor in absolute terms (and when compared with rater performance); performance is remarkably similar across model classes, though with benefits from sparsity; tasks that improve gradually and predictably commonly involve a large knowledge or memorization component, whereas tasks that exhibit "breakthrough" behavior at a critical scale often involve multiple steps or components, or brittle metrics; social bias typically increases with scale in settings with ambiguous context, but this can be improved with prompting.},
  pubstate = {preprint},
  keywords = {Computer Science - Computers and Society},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/4RQH4XC7/Srivastava et al. - 2022 - Beyond the Imitation Game Quantifying and extrapo.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/LS8WDS8C/2206.html}
}

@book{stanczykFeatureSelectionData2015,
  title = {Feature {{Selection}} for {{Data}} and {{Pattern Recognition}}},
  editor = {Stańczyk, Urszula and Jain, Lakhmi C.},
  date = {2015},
  series = {Studies in {{Computational Intelligence}}},
  volume = {584},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-662-45620-0},
  url = {https://link.springer.com/10.1007/978-3-662-45620-0},
  urldate = {2023-09-05},
  isbn = {978-3-662-45619-4 978-3-662-45620-0},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/MNCGR9QF/Stańczyk y Jain - 2015 - Feature Selection for Data and Pattern Recognition.pdf}
}

@article{stanleyDesigningNeuralNetworks2019,
  title = {Designing Neural Networks through Neuroevolution},
  author = {Stanley, Kenneth and Clune, Jeff and Lehman, Joel and Miikkulainen, Risto},
  date = {2019-01-07},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nature Machine Intelligence},
  volume = {1},
  doi = {10.1038/s42256-018-0006-z},
  abstract = {Much of recent machine learning has focused on deep learning, in which neural network weights are trained through variants of stochastic gradient descent. An alternative approach comes from the field of neuroevolution, which harnesses evolutionary algorithms to optimize neural networks, inspired by the fact that natural brains themselves are the products of an evolutionary process. Neuroevolution enables important capabilities that are typically unavailable to gradient-based approaches, including learning neural network building blocks (for example activation functions), hyperparameters, architectures and even the algorithms for learning themselves. Neuroevolution also differs from deep learning (and deep reinforcement learning) by maintaining a population of solutions during search, enabling extreme exploration and massive parallelization. Finally, because neuroevolution research has (until recently) developed largely in isolation from gradient-based neural network research, it has developed many unique and effective techniques that should be effective in other machine learning areas too. This Review looks at several key aspects of modern neuroevolution, including large-scale computing, the benefits of novelty and diversity, the power of indirect encoding, and the field’s contributions to meta-learning and architecture search. Our hope is to inspire renewed interest in the field as it meets the potential of the increasing computation available today, to highlight how many of its ideas can provide an exciting resource for inspiration and hybridization to the deep learning, deep reinforcement learning and machine learning communities, and to explain how neuroevolution could prove to be a critical tool in the long-term pursuit of artificial general intelligence.}
}

@online{steckCosineSimilarityEmbeddingsReally2024,
  title = {Is {{Cosine-Similarity}} of {{Embeddings Really About Similarity}}?},
  author = {Steck, Harald and Ekanadham, Chaitanya and Kallus, Nathan},
  date = {2024-03-08},
  eprint = {2403.05440},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.1145/3589335.3651526},
  url = {http://arxiv.org/abs/2403.05440},
  urldate = {2024-03-12},
  abstract = {Cosine-similarity is the cosine of the angle between two vectors, or equivalently the dot product between their normalizations. A popular application is to quantify semantic similarity between high-dimensional objects by applying cosine-similarity to a learned low-dimensional feature embedding. This can work better but sometimes also worse than the unnormalized dot-product between embedded vectors in practice. To gain insight into this empirical observation, we study embeddings derived from regularized linear models, where closed-form solutions facilitate analytical insights. We derive analytically how cosine-similarity can yield arbitrary and therefore meaningless `similarities.' For some linear models the similarities are not even unique, while for others they are implicitly controlled by the regularization. We discuss implications beyond linear models: a combination of different regularizations are employed when learning deep models; these have implicit and unintended effects when taking cosine-similarities of the resulting embeddings, rendering results opaque and possibly arbitrary. Based on these insights, we caution against blindly using cosine-similarity and outline alternatives.},
  pubstate = {preprint},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/DBYZYQKJ/Steck et al. - 2024 - Is Cosine-Similarity of Embeddings Really About Si.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/VT2KVDMI/2403.html}
}

@online{StepbyStepGuideFineTuning,
  title = {A {{Step-by-Step Guide}} to {{Fine-Tuning}} the {{Mistral 7B LLM}}},
  url = {https://www.e2enetworks.com/blog/a-step-by-step-guide-to-fine-tuning-the-mistral-7b-llm},
  urldate = {2024-04-08},
  abstract = {We'll delve deep into the process of fine-tuning the Mistral 7B LLM and explore the theoretical underpinnings that drive this adaptation.},
  langid = {english}
}

@online{sunSurveyReasoningFoundation2023,
  title = {A {{Survey}} of {{Reasoning}} with {{Foundation Models}}},
  author = {Sun, Jiankai and Zheng, Chuanyang and Xie, Enze and Liu, Zhengying and Chu, Ruihang and Qiu, Jianing and Xu, Jiaqi and Ding, Mingyu and Li, Hongyang and Geng, Mengzhe and Wu, Yue and Wang, Wenhai and Chen, Junsong and Yin, Zhangyue and Ren, Xiaozhe and Fu, Jie and He, Junxian and Yuan, Wu and Liu, Qi and Liu, Xihui and Li, Yu and Dong, Hao and Cheng, Yu and Zhang, Ming and Heng, Pheng Ann and Dai, Jifeng and Luo, Ping and Wang, Jingdong and Wen, Ji-Rong and Qiu, Xipeng and Guo, Yike and Xiong, Hui and Liu, Qun and Li, Zhenguo},
  date = {2023-12-26},
  eprint = {2312.11562},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2312.11562},
  urldate = {2023-12-30},
  abstract = {Reasoning, a crucial ability for complex problem-solving, plays a pivotal role in various real-world settings such as negotiation, medical diagnosis, and criminal investigation. It serves as a fundamental methodology in the field of Artificial General Intelligence (AGI). With the ongoing development of foundation models, there is a growing interest in exploring their abilities in reasoning tasks. In this paper, we introduce seminal foundation models proposed or adaptable for reasoning, highlighting the latest advancements in various reasoning tasks, methods, and benchmarks. We then delve into the potential future directions behind the emergence of reasoning abilities within foundation models. We also discuss the relevance of multimodal learning, autonomous agents, and super alignment in the context of reasoning. By discussing these future research directions, we hope to inspire researchers in their exploration of this field, stimulate further advancements in reasoning with foundation models, and contribute to the development of AGI.},
  pubstate = {preprint},
  version = {4},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ZDZ9R5YG/Sun et al. - 2023 - A Survey of Reasoning with Foundation Models.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/WRTQ64MY/2312.html}
}

@online{SystematicReviewData,
  title = {A {{Systematic Review}} on {{Data Scarcity Problem}} in {{Deep Learning}}: {{Solution}} and {{Applications}} | {{ScienceGate}}},
  url = {https://www.sciencegate.app/document/10.1145/3502287},
  urldate = {2023-09-15},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/QB52HYSD/3502287.html}
}

@online{tanBlindedGeneratedContexts2024,
  title = {Blinded by {{Generated Contexts}}: {{How Language Models Merge Generated}} and {{Retrieved Contexts}} for {{Open-Domain QA}}?},
  shorttitle = {Blinded by {{Generated Contexts}}},
  author = {Tan, Hexiang and Sun, Fei and Yang, Wanli and Wang, Yuanzhuo and Cao, Qi and Cheng, Xueqi},
  date = {2024-01-22},
  eprint = {2401.11911},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2401.11911},
  urldate = {2024-01-30},
  abstract = {While auxiliary information has become a key to enhance Large Language Models (LLMs), relatively little is known about how well LLMs merge these contexts, specifically generated and retrieved. To study this, we formulate a task specifically designed to identify whether the answers, derived from the integration of generated and retrieved contexts, are attributed to either generated or retrieved contexts. To support this task, we develop a methodology to construct datasets with conflicting contexts, where each question is paired with both generated and retrieved contexts, yet only one of them contains the correct answer. Our experiments reveal a significant bias in LLMs towards generated contexts, as evidenced across state-of-the-art open (Llama2-7b/13b) and closed (GPT 3.5/4) systems. We further identify two key factors contributing to this bias: i) Contexts generated by LLMs typically show greater similarity to the questions, increasing their likelihood of selection; ii) The segmentation process used in retrieved contexts disrupts their completeness, thereby hindering their full utilization in LLMs. Our analysis enhances the understanding of how LLMs merge diverse contexts, offering valuable insights for advancing current augmentation methods for LLMs.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/CVC7PHRY/Tan et al. - 2024 - Blinded by Generated Contexts How Language Models.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/6UXKA3A2/2401.html}
}

@article{tangFeatureSelectionClassification,
  title = {Feature {{Selection}} for {{Classiﬁcation}}: {{A Review}}},
  author = {Tang, Jiliang and Alelyani, Salem and Liu, Huan},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/GR6V6TRQ/Tang et al. - Feature Selection for Classiﬁcation A Review.pdf}
}

@online{tangMiniCheckEfficientFactChecking2024,
  title = {{{MiniCheck}}: {{Efficient Fact-Checking}} of {{LLMs}} on {{Grounding Documents}}},
  shorttitle = {{{MiniCheck}}},
  author = {Tang, Liyan and Laban, Philippe and Durrett, Greg},
  date = {2024-04-16},
  eprint = {2404.10774},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2404.10774},
  url = {http://arxiv.org/abs/2404.10774},
  urldate = {2024-04-19},
  abstract = {Recognizing if LLM output can be grounded in evidence is central to many tasks in NLP: retrieval-augmented generation, summarization, document-grounded dialogue, and more. Current approaches to this kind of "fact-checking" are based on verifying each piece of a model generation against potential evidence using an LLM. However, this process can be very computationally expensive, requiring many calls to LLMs to check a single response. In this work, we show how to build small models that have GPT-4-level performance but for 400x lower cost. We do this by constructing synthetic training data with GPT-4, which involves creating realistic yet challenging instances of factual errors via a structured generation procedure. Training on this data teaches models to check each fact in the claim and recognize synthesis of information across sentences. For evaluation, we unify pre-existing datasets into a benchmark LLM-AggreFact, collected from recent work on fact-checking and grounding LLM generations. Our best system MiniCheck-FT5 (770M parameters) outperforms all systems of comparable size and reaches GPT-4 accuracy. We release LLM-AggreFact, code for data synthesis, and models.},
  pubstate = {preprint},
  version = {1},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/FUFL95QF/Tang et al. - 2024 - MiniCheck Efficient Fact-Checking of LLMs on Grou.pdf}
}

@online{tanLargeLanguageModels2024,
  title = {Large {{Language Models}} for {{Data Annotation}}: {{A Survey}}},
  shorttitle = {Large {{Language Models}} for {{Data Annotation}}},
  author = {Tan, Zhen and Beigi, Alimohammad and Wang, Song and Guo, Ruocheng and Bhattacharjee, Amrita and Jiang, Bohan and Karami, Mansooreh and Li, Jundong and Cheng, Lu and Liu, Huan},
  date = {2024-02-20},
  eprint = {2402.13446},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2402.13446},
  url = {http://arxiv.org/abs/2402.13446},
  urldate = {2024-02-23},
  abstract = {Data annotation is the labeling or tagging of raw data with relevant information, essential for improving the efficacy of machine learning models. The process, however, is labor-intensive and expensive. The emergence of advanced Large Language Models (LLMs), exemplified by GPT-4, presents an unprecedented opportunity to revolutionize and automate the intricate process of data annotation. While existing surveys have extensively covered LLM architecture, training, and general applications, this paper uniquely focuses on their specific utility for data annotation. This survey contributes to three core aspects: LLM-Based Data Annotation, Assessing LLM-generated Annotations, and Learning with LLM-generated annotations. Furthermore, the paper includes an in-depth taxonomy of methodologies employing LLMs for data annotation, a comprehensive review of learning strategies for models incorporating LLM-generated annotations, and a detailed discussion on primary challenges and limitations associated with using LLMs for data annotation. As a key guide, this survey aims to direct researchers and practitioners in exploring the potential of the latest LLMs for data annotation, fostering future advancements in this critical domain. We provide a comprehensive papers list at \textbackslash url\{https://github.com/Zhen-Tan-dmml/LLM4Annotation.git\}.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ZTMFWY3S/Tan et al. - 2024 - Large Language Models for Data Annotation A Surve.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/UGHDVS6S/2402.html}
}

@online{TasksHuggingFace,
  title = {Tasks - {{Hugging Face}}},
  url = {https://huggingface.co/tasks},
  urldate = {2023-01-27},
  abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/MK7ZCH3D/tasks.html}
}

@online{teamKerasDocumentationNamed,
  title = {Keras Documentation: {{Named Entity Recognition}} Using {{Transformers}}},
  shorttitle = {Keras Documentation},
  author = {Team, Keras},
  url = {https://keras.io/examples/nlp/ner_transformers/},
  urldate = {2022-11-08},
  abstract = {Keras documentation},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/SC5EN23H/ner_transformers.html}
}

@book{theodoridisPatternRecognition2009,
  title = {Pattern Recognition},
  author = {Theodoridis, Sergios and Koutroumbas, Konstantinos},
  date = {2009},
  edition = {4th ed},
  publisher = {Academic Press},
  location = {Burlington, MA London},
  abstract = {"This book considers classical and current theory and practice of supervised, unsupervised and semi-supervised pattern recognition, to build a complete background for professionals and students of engineering. The authors have provided an up-to-date, self-contained volume encapsulating this wide spectrum of information. The very latest methods are incorporated in this edition including semi-supervised learning, non-linear dimensionality reduction techniques and spectral clustering."--Jacket},
  isbn = {978-1-59749-272-0},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/F2QRZQTY/Theodoridis y Koutroumbas - 2009 - Pattern recognition.pdf}
}

@online{tianFinetuningLanguageModels2023,
  title = {Fine-Tuning {{Language Models}} for {{Factuality}}},
  author = {Tian, Katherine and Mitchell, Eric and Yao, Huaxiu and Manning, Christopher D. and Finn, Chelsea},
  date = {2023-11-14},
  eprint = {2311.08401},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2311.08401},
  url = {http://arxiv.org/abs/2311.08401},
  urldate = {2023-11-20},
  abstract = {The fluency and creativity of large pre-trained language models (LLMs) have led to their widespread use, sometimes even as a replacement for traditional search engines. Yet language models are prone to making convincing but factually inaccurate claims, often referred to as 'hallucinations.' These errors can inadvertently spread misinformation or harmfully perpetuate misconceptions. Further, manual fact-checking of model responses is a time-consuming process, making human factuality labels expensive to acquire. In this work, we fine-tune language models to be more factual, without human labeling and targeting more open-ended generation settings than past work. We leverage two key recent innovations in NLP to do so. First, several recent works have proposed methods for judging the factuality of open-ended text by measuring consistency with an external knowledge base or simply a large model's confidence scores. Second, the direct preference optimization algorithm enables straightforward fine-tuning of language models on objectives other than supervised imitation, using a preference ranking over possible model responses. We show that learning from automatically generated factuality preference rankings, generated either through existing retrieval systems or our novel retrieval-free approach, significantly improves the factuality (percent of generated claims that are correct) of Llama-2 on held-out topics compared with RLHF or decoding strategies targeted at factuality. At 7B scale, compared to Llama-2-chat, we observe 58\% and 40\% reduction in factual error rate when generating biographies and answering medical questions, respectively.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/PEQVTK83/Tian et al. - 2023 - Fine-tuning Language Models for Factuality.pdf}
}

@article{tibshiraniValeriePatrickHastie,
  title = {Valerie and {{Patrick Hastie}}},
  author = {Tibshirani, Sami and Friedman, Harry},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/EUZ6AMNU/Tibshirani y Friedman - Valerie and Patrick Hastie.pdf}
}

@article{tongSurrogateModelsEvolutionary2021,
  title = {Surrogate Models in Evolutionary Single-Objective Optimization: {{A}} New Taxonomy and Experimental Study},
  shorttitle = {Surrogate Models in Evolutionary Single-Objective Optimization},
  author = {Tong, Hao and Huang, Changwu and Minku, Leandro L. and Yao, Xin},
  date = {2021-07-01},
  journaltitle = {Information Sciences},
  shortjournal = {Information Sciences},
  volume = {562},
  pages = {414--437},
  issn = {0020-0255},
  doi = {10.1016/j.ins.2021.03.002},
  url = {https://www.sciencedirect.com/science/article/pii/S0020025521002395},
  urldate = {2023-09-27},
  abstract = {Surrogate-assisted evolutionary algorithms (SAEAs), which use efficient surrogate models or meta-models to approximate the fitness function in evolutionary algorithms (EAs), are effective and popular methods for solving computationally expensive optimization problems. During the past decades, a number of SAEAs have been proposed by combining different surrogate models and EAs. This paper dedicates to providing a more systematical review and comprehensive empirical study of surrogate models used in single-objective SAEAs. A new taxonomy of surrogate models in SAEAs for single-objective optimization is introduced in this paper. Surrogate models are classified into two major categories: absolute fitness models, which directly approximate the fitness function values of candidate solutions, and relative fitness models, which estimates the relative rank or preference of candidates rather than their fitness values. Then, the characteristics of different models are analyzed and compared by conducting a series of experiments in terms of time complexity (execution time), model accuracy, parameter influence, and the overall performance when used in EAs. The empirical results are helpful for researchers to select suitable surrogate models when designing SAEAs. Open research questions and future work are discussed at the end of the paper.},
  keywords = {Absolute fitness models,Evolutionary algorithms,Expensive optimization problems,Relative fitness models,Surrogate models},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/UN95MP9I/Tong et al. - 2021 - Surrogate models in evolutionary single-objective .pdf}
}

@online{torres-morenoArtexAnotheRTEXt2012,
  title = {Artex Is {{AnotheR TEXt}} Summarizer},
  author = {Torres-Moreno, Juan-Manuel},
  date = {2012-10-11},
  eprint = {1210.3312},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1210.3312},
  urldate = {2022-11-15},
  abstract = {This paper describes Artex, another algorithm for Automatic Text Summarization. In order to rank sentences, a simple inner product is calculated between each sentence, a document vector (text topic) and a lexical vector (vocabulary used by a sentence). Summaries are then generated by assembling the highest ranked sentences. No ruled-based linguistic post-processing is necessary in order to obtain summaries. Tests over several datasets (coming from Document Understanding Conferences (DUC), Text Analysis Conferences (TAC), evaluation campaigns, etc.) in French, English and Spanish have shown that summarizer achieves interesting results.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/6J7GZZAR/Torres-Moreno - 2012 - Artex is AnotheR TEXt summarizer.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/DFTCYQZM/1210.html}
}

@article{touvronLLaMAOpenEfficient,
  title = {{{LLaMA}}: {{Open}} and {{Efficient Foundation Language Models}}},
  author = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timothee and Rozière, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume},
  abstract = {We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla70B and PaLM-540B. We release all our models to the research community1.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/7HDEHTBG/Touvron et al. - LLaMA Open and Efficient Foundation Language Mode.pdf}
}

@online{tranArtificialNeuralNetworkbased2022,
  title = {An Artificial Neural Network-Based System for Detecting Machine Failures Using Tiny Sound Data: {{A}} Case Study},
  shorttitle = {An Artificial Neural Network-Based System for Detecting Machine Failures Using Tiny Sound Data},
  author = {Tran, Thanh and Bader, Sebastian and Lundgren, Jan},
  date = {2022-09-23},
  eprint = {2209.11527},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  url = {http://arxiv.org/abs/2209.11527},
  urldate = {2023-09-15},
  abstract = {In an effort to advocate the research for a deep learning-based machine failure detection system, we present a case study of our proposed system based on a tiny sound dataset. Our case study investigates a variational autoencoder (VAE) for augmenting a small drill sound dataset from Valmet AB. A Valmet dataset contains 134 sounds that have been divided into two categories: "Anomaly" and "Normal" recorded from a drilling machine in Valmet AB, a company in Sundsvall, Sweden that supplies equipment and processes for the production of biofuels. Using deep learning models to detect failure drills on such a small sound dataset is typically unsuccessful. We employed a VAE to increase the number of sounds in the tiny dataset by synthesizing new sounds from original sounds. The augmented dataset was created by combining these synthesized sounds with the original sounds. We used a high-pass filter with a passband frequency of 1000 Hz and a low-pass filter with a passband frequency of 22\textbackslash kern 0.16667em000 Hz to pre-process sounds in the augmented dataset before transforming them to Mel spectrograms. The pre-trained 2D-CNN Alexnet was then trained using these Mel spectrograms. When compared to using the original tiny sound dataset to train pre-trained Alexnet, using the augmented sound dataset enhanced the CNN model's classification results by 6.62\textbackslash\%(94.12\textbackslash\% when trained on the augmented dataset versus 87.5\textbackslash\% when trained on the original dataset).},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/LVDZS8V4/Tran et al. - 2022 - An artificial neural network-based system for dete.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/SY9S65MU/2209.html}
}

@online{trevisoEfficientMethodsNatural2022,
  title = {Efficient {{Methods}} for {{Natural Language Processing}}: {{A Survey}}},
  shorttitle = {Efficient {{Methods}} for {{Natural Language Processing}}},
  author = {Treviso, Marcos and Ji, Tianchu and Lee, Ji-Ung and family=Aken, given=Betty, prefix=van, useprefix=true and Cao, Qingqing and Ciosici, Manuel R. and Hassid, Michael and Heafield, Kenneth and Hooker, Sara and Martins, Pedro H. and Martins, André F. T. and Milder, Peter and Raffel, Colin and Simpson, Edwin and Slonim, Noam and Balasubramanian, Niranjan and Derczynski, Leon and Schwartz, Roy},
  date = {2022-08-31},
  eprint = {2209.00099},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2209.00099},
  urldate = {2022-11-16},
  abstract = {Getting the most out of limited resources allows advances in natural language processing (NLP) research and practice while being conservative with resources. Those resources may be data, time, storage, or energy. Recent work in NLP has yielded interesting results from scaling; however, using only scale to improve results means that resource consumption also scales. That relationship motivates research into efficient methods that require less resources to achieve similar results. This survey relates and synthesises methods and findings in those efficiencies in NLP, aiming to guide new researchers in the field and inspire the development of new methods.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/GRW2JNDZ/Treviso et al. - 2022 - Efficient Methods for Natural Language Processing.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/8Q8ZBBA7/2209.html}
}

@online{trivediInterleavingRetrievalChainofThought2023,
  title = {Interleaving {{Retrieval}} with {{Chain-of-Thought Reasoning}} for {{Knowledge-Intensive Multi-Step Questions}}},
  author = {Trivedi, Harsh and Balasubramanian, Niranjan and Khot, Tushar and Sabharwal, Ashish},
  date = {2023-06-22},
  eprint = {2212.10509},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2212.10509},
  url = {http://arxiv.org/abs/2212.10509},
  urldate = {2024-01-18},
  abstract = {Prompting-based large language models (LLMs) are surprisingly powerful at generating natural language reasoning steps or Chains-of-Thoughts (CoT) for multi-step question answering (QA). They struggle, however, when the necessary knowledge is either unavailable to the LLM or not up-to-date within its parameters. While using the question to retrieve relevant text from an external knowledge source helps LLMs, we observe that this one-step retrieve-and-read approach is insufficient for multi-step QA. Here, \textbackslash textit\{what to retrieve\} depends on \textbackslash textit\{what has already been derived\}, which in turn may depend on \textbackslash textit\{what was previously retrieved\}. To address this, we propose IRCoT, a new approach for multi-step QA that interleaves retrieval with steps (sentences) in a CoT, guiding the retrieval with CoT and in turn using retrieved results to improve CoT. Using IRCoT with GPT3 substantially improves retrieval (up to 21 points) as well as downstream QA (up to 15 points) on four datasets: HotpotQA, 2WikiMultihopQA, MuSiQue, and IIRC. We observe similar substantial gains in out-of-distribution (OOD) settings as well as with much smaller models such as Flan-T5-large without additional training. IRCoT reduces model hallucination, resulting in factually more accurate CoT reasoning. Code, data, and prompts are available at \textbackslash url\{https://github.com/stonybrooknlp/ircot\}},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/KFWNZR4G/Trivedi et al. - 2023 - Interleaving Retrieval with Chain-of-Thought Reaso.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ZIIJ6M4F/2212.html}
}

@online{TuringComputingMachinery,
  title = {On {{Turing}}’s “{{Computing Machinery}} and {{Intelligence}}” - {{Ozaner}}’s {{Notes}}},
  url = {https://ozaner.github.io/turing-test/},
  urldate = {2023-05-29},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/V6ATVVQN/turing-test.html}
}

@article{turingCOMPUTINGMACHINERYINTELLIGENCE1950,
  title = {I.—{{COMPUTING MACHINERY AND INTELLIGENCE}}},
  author = {Turing, A. M.},
  date = {1950-10-01},
  journaltitle = {Mind},
  volume = {LIX},
  number = {236},
  pages = {433--460},
  issn = {1460-2113, 0026-4423},
  doi = {10.1093/mind/LIX.236.433},
  url = {https://academic.oup.com/mind/article/LIX/236/433/986238},
  urldate = {2023-05-29},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/F4BV2ZFU/Turing - 1950 - I.—COMPUTING MACHINERY AND INTELLIGENCE.pdf}
}

@article{urbanowiczReliefbasedFeatureSelection2018,
  title = {Relief-Based Feature Selection: {{Introduction}} and Review},
  shorttitle = {Relief-Based Feature Selection},
  author = {Urbanowicz, Ryan J. and Meeker, Melissa and La Cava, William and Olson, Randal S. and Moore, Jason H.},
  date = {2018-09},
  journaltitle = {Journal of Biomedical Informatics},
  shortjournal = {Journal of Biomedical Informatics},
  volume = {85},
  pages = {189--203},
  issn = {15320464},
  doi = {10.1016/j.jbi.2018.07.014},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1532046418301400},
  urldate = {2023-09-05},
  abstract = {Feature selection plays a critical role in biomedical data mining, driven by increasing feature dimensionality in target problems and growing interest in advanced but computationally expensive methodologies able to model complex associations. Specifically, there is a need for feature selection methods that are computationally efficient, yet sensitive to complex patterns of association, e.g. interactions, so that informative features are not mistakenly eliminated prior to downstream modeling. This paper focuses on Relief-based algorithms (RBAs), a unique family of filter-style feature selection algorithms that have gained appeal by striking an effective balance between these objectives while flexibly adapting to various data characteristics, e.g. classification vs. regression. First, this work broadly examines types of feature selection and defines RBAs within that context. Next, we introduce the original Relief algorithm and associated concepts, emphasizing the intuition behind how it works, how feature weights generated by the algorithm can be interpreted, and why it is sensitive to feature interactions without evaluating combinations of features. Lastly, we include an expansive review of RBA methodological research beyond Relief and its popular descendant, ReliefF. In particular, we characterize branches of RBA research, and provide comparative summaries of RBA algorithms including contributions, strategies, functionality, time complexity, adaptation to key data characteristics, and software availability.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/CNCC6PRL/Urbanowicz et al. - 2018 - Relief-based feature selection Introduction and r.pdf}
}

@online{UsFairlearnDocumentation,
  title = {About {{Us}} — {{Fairlearn}} 0.8.0 Documentation},
  url = {https://fairlearn.org/v0.8/about/index.html},
  urldate = {2023-06-07},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/QLH87QIC/index.html}
}

@inproceedings{ushioTNERAllRoundPython2021,
  title = {T-{{NER}}: {{An All-Round Python Library}} for {{Transformer-based Named Entity Recognition}}},
  shorttitle = {T-{{NER}}},
  booktitle = {Proceedings of the 16th {{Conference}} of the {{European Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{System Demonstrations}}},
  author = {Ushio, Asahi and Camacho-Collados, Jose},
  date = {2021-04},
  pages = {53--62},
  publisher = {Association for Computational Linguistics},
  location = {Online},
  doi = {10.18653/v1/2021.eacl-demos.7},
  url = {https://aclanthology.org/2021.eacl-demos.7},
  urldate = {2022-11-19},
  abstract = {Language model (LM) pretraining has led to consistent improvements in many NLP downstream tasks, including named entity recognition (NER). In this paper, we present T-NER (Transformer-based Named Entity Recognition), a Python library for NER LM finetuning. In addition to its practical utility, T-NER facilitates the study and investigation of the cross-domain and cross-lingual generalization ability of LMs finetuned on NER. Our library also provides a web app where users can get model predictions interactively for arbitrary text, which facilitates qualitative model evaluation for non-expert programmers. We show the potential of the library by compiling nine public NER datasets into a unified format and evaluating the cross-domain and cross- lingual performance across the datasets. The results from our initial experiments show that in-domain performance is generally competitive across datasets. However, cross-domain generalization is challenging even with a large pretrained LM, which has nevertheless capacity to learn domain-specific features if fine- tuned on a combined dataset. To facilitate future research, we also release all our LM checkpoints via the Hugging Face model hub.},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/KJ8PGIM9/Ushio y Camacho-Collados - 2021 - T-NER An All-Round Python Library for Transformer.pdf}
}

@software{VAE_implementations,
  title = {{{VAE}}\_implementations},
  url = {https://github.com/AntixK/PyTorch-VAE}
}

@article{vajjalaWhatWeReally,
  title = {What Do We {{Really Know}} about {{State}} of the {{Art NER}}?},
  author = {Vajjala, Sowmya and Balasubramaniam, Ramya},
  pages = {11},
  abstract = {Named Entity Recognition (NER) is a well researched NLP task and is widely used in real world NLP scenarios. NER research typically focuses on the creation of new ways of training NER, with relatively less emphasis on resources and evaluation. Further, state of the art (SOTA) NER models, trained on standard datasets, typically report only a single performance measure (F-score) and we don’t really know how well they do for different entity types and genres of text, or how robust are they to new, unseen entities. In this paper, we perform a broad evaluation of NER using a popular dataset, that takes into consideration various text genres and sources constituting the dataset at hand. Additionally, we generate six new adversarial test sets through small perturbations in the original test set, replacing select entities while retaining the context. We also train and test our models on randomly generated train/dev/test splits followed by an experiment where the models are trained on a select set of genres but tested genres not seen in training. These comprehensive evaluation strategies were performed using three SOTA NER models. Based on our results, we recommend some useful reporting practices for NER researchers, that could help in providing a better understanding of a SOTA model’s performance in future.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/6W5B97EJ/Vajjala y Balasubramaniam - What do we Really Know about State of the Art NER.pdf}
}

@online{vajjalaWhatWeReally2022,
  title = {What Do We {{Really Know}} about {{State}} of the {{Art NER}}?},
  author = {Vajjala, Sowmya and Balasubramaniam, Ramya},
  date = {2022-05-04},
  eprint = {2205.00034},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2205.00034},
  urldate = {2022-11-16},
  abstract = {Named Entity Recognition (NER) is a well researched NLP task and is widely used in real world NLP scenarios. NER research typically focuses on the creation of new ways of training NER, with relatively less emphasis on resources and evaluation. Further, state of the art (SOTA) NER models, trained on standard datasets, typically report only a single performance measure (F-score) and we don't really know how well they do for different entity types and genres of text, or how robust are they to new, unseen entities. In this paper, we perform a broad evaluation of NER using a popular dataset, that takes into consideration various text genres and sources constituting the dataset at hand. Additionally, we generate six new adversarial test sets through small perturbations in the original test set, replacing select entities while retaining the context. We also train and test our models on randomly generated train/dev/test splits followed by an experiment where the models are trained on a select set of genres but tested genres not seen in training. These comprehensive evaluation strategies were performed using three SOTA NER models. Based on our results, we recommend some useful reporting practices for NER researchers, that could help in providing a better understanding of a SOTA model's performance in future.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/E8MJ8R3L/Vajjala y Balasubramaniam - 2022 - What do we Really Know about State of the Art NER.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/YVAS6LPA/2205.html}
}

@online{valmeekamPlanBenchExtensibleBenchmark2023,
  title = {{{PlanBench}}: {{An Extensible Benchmark}} for {{Evaluating Large Language Models}} on {{Planning}} and {{Reasoning}} about {{Change}}},
  shorttitle = {{{PlanBench}}},
  author = {Valmeekam, Karthik and Marquez, Matthew and Olmo, Alberto and Sreedharan, Sarath and Kambhampati, Subbarao},
  date = {2023-11-25},
  eprint = {2206.10498},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2206.10498},
  url = {http://arxiv.org/abs/2206.10498},
  urldate = {2024-04-26},
  abstract = {Generating plans of action, and reasoning about change have long been considered a core competence of intelligent agents. It is thus no surprise that evaluating the planning and reasoning capabilities of large language models (LLMs) has become a hot topic of research. Most claims about LLM planning capabilities are however based on common sense tasks-where it becomes hard to tell whether LLMs are planning or merely retrieving from their vast world knowledge. There is a strong need for systematic and extensible planning benchmarks with sufficient diversity to evaluate whether LLMs have innate planning capabilities. Motivated by this, we propose PlanBench, an extensible benchmark suite based on the kinds of domains used in the automated planning community, especially in the International Planning Competition, to test the capabilities of LLMs in planning or reasoning about actions and change. PlanBench provides sufficient diversity in both the task domains and the specific planning capabilities. Our studies also show that on many critical capabilities-including plan generation-LLM performance falls quite short, even with the SOTA models. PlanBench can thus function as a useful marker of progress of LLMs in planning and reasoning.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/YYTQ4M2F/Valmeekam et al. - 2023 - PlanBench An Extensible Benchmark for Evaluating .pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/QUBWYHCG/2206.html}
}

@online{valmeekamPlanBenchExtensibleBenchmark2023a,
  title = {{{PlanBench}}: {{An Extensible Benchmark}} for {{Evaluating Large Language Models}} on {{Planning}} and {{Reasoning}} about {{Change}}},
  shorttitle = {{{PlanBench}}},
  author = {Valmeekam, Karthik and Marquez, Matthew and Olmo, Alberto and Sreedharan, Sarath and Kambhampati, Subbarao},
  date = {2023-11-25},
  eprint = {2206.10498},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2206.10498},
  url = {http://arxiv.org/abs/2206.10498},
  urldate = {2024-04-26},
  abstract = {Generating plans of action, and reasoning about change have long been considered a core competence of intelligent agents. It is thus no surprise that evaluating the planning and reasoning capabilities of large language models (LLMs) has become a hot topic of research. Most claims about LLM planning capabilities are however based on common sense tasks-where it becomes hard to tell whether LLMs are planning or merely retrieving from their vast world knowledge. There is a strong need for systematic and extensible planning benchmarks with sufficient diversity to evaluate whether LLMs have innate planning capabilities. Motivated by this, we propose PlanBench, an extensible benchmark suite based on the kinds of domains used in the automated planning community, especially in the International Planning Competition, to test the capabilities of LLMs in planning or reasoning about actions and change. PlanBench provides sufficient diversity in both the task domains and the specific planning capabilities. Our studies also show that on many critical capabilities-including plan generation-LLM performance falls quite short, even with the SOTA models. PlanBench can thus function as a useful marker of progress of LLMs in planning and reasoning.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/3DGLJC8I/Valmeekam et al. - 2023 - PlanBench An Extensible Benchmark for Evaluating .pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/S3U587LA/2206.html}
}

@online{valmeekamPlanBenchExtensibleBenchmark2023b,
  title = {{{PlanBench}}: {{An Extensible Benchmark}} for {{Evaluating Large Language Models}} on {{Planning}} and {{Reasoning}} about {{Change}}},
  shorttitle = {{{PlanBench}}},
  author = {Valmeekam, Karthik and Marquez, Matthew and Olmo, Alberto and Sreedharan, Sarath and Kambhampati, Subbarao},
  date = {2023-11-25},
  eprint = {2206.10498},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2206.10498},
  urldate = {2024-05-06},
  abstract = {Generating plans of action, and reasoning about change have long been considered a core competence of intelligent agents. It is thus no surprise that evaluating the planning and reasoning capabilities of large language models (LLMs) has become a hot topic of research. Most claims about LLM planning capabilities are however based on common sense tasks–where it becomes hard to tell whether LLMs are planning or merely retrieving from their vast world knowledge. There is a strong need for systematic and extensible planning benchmarks with sufficient diversity to evaluate whether LLMs have innate planning capabilities. Motivated by this, we propose PlanBench, an extensible benchmark suite based on the kinds of domains used in the automated planning community, especially in the International Planning Competition, to test the capabilities of LLMs in planning or reasoning about actions and change. PlanBench provides sufficient diversity in both the task domains and the specific planning capabilities. Our studies also show that on many critical capabilities–including plan generation–LLM performance falls quite short, even with the SOTA models. PlanBench can thus function as a useful marker of progress of LLMs in planning and reasoning.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/MD9C5BTC/Valmeekam et al. - 2023 - PlanBench An Extensible Benchmark for Evaluating .pdf}
}

@article{valmeekamPlanningAbilitiesLarge,
  title = {On the {{Planning Abilities}} of {{Large Language Models}} : {{A Critical Investigation}}},
  author = {Valmeekam, Karthik and Sreedharan, Sarath and Marquez, Matthew and Kambhampati, Subbarao},
  abstract = {Intrigued by the claims of emergent reasoning capabilities in LLMs trained on general web corpora, in this paper, we set out to investigate their planning capabilities. We aim to evaluate (1) the effectiveness of LLMs in generating plans autonomously in commonsense planning tasks and (2) the potential of LLMs as a source of heuristic guidance for other agents (AI planners) in their planning tasks. We conduct a systematic study by generating a suite of instances on domains similar to the ones employed in the International Planning Competition and evaluate LLMs in two distinct modes: autonomous and heuristic. Our findings reveal that LLMs’ ability to generate executable plans autonomously is rather limited, with the best model (GPT-4) having an average success rate of ∼12\% across the domains. However, the results in the heuristic mode show more promise. In the heuristic mode, we demonstrate that LLM-generated plans can improve the search process for underlying sound planners and additionally show that external verifiers can help provide feedback on the generated plans and back-prompt the LLM for better plan generation.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/Y5U63J47/Valmeekam et al. - On the Planning Abilities of Large Language Models.pdf}
}

@online{valmeekamPlanningAbilitiesLarge2023,
  title = {On the {{Planning Abilities}} of {{Large Language Models}} ({{A Critical Investigation}} with a {{Proposed Benchmark}})},
  author = {Valmeekam, Karthik and Sreedharan, Sarath and Marquez, Matthew and Olmo, Alberto and Kambhampati, Subbarao},
  date = {2023-02-13},
  eprint = {2302.06706},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2302.06706},
  url = {http://arxiv.org/abs/2302.06706},
  urldate = {2024-04-26},
  abstract = {Intrigued by the claims of emergent reasoning capabilities in LLMs trained on general web corpora, in this paper, we set out to investigate their planning capabilities. We aim to evaluate (1) how good LLMs are by themselves in generating and validating simple plans in commonsense planning tasks (of the type that humans are generally quite good at) and (2) how good LLMs are in being a source of heuristic guidance for other agents--either AI planners or human planners--in their planning tasks. To investigate these questions in a systematic rather than anecdotal manner, we start by developing a benchmark suite based on the kinds of domains employed in the International Planning Competition. On this benchmark, we evaluate LLMs in three modes: autonomous, heuristic and human-in-the-loop. Our results show that LLM's ability to autonomously generate executable plans is quite meager, averaging only about 3\% success rate. The heuristic and human-in-the-loop modes show slightly more promise. In addition to these results, we also make our benchmark and evaluation tools available to support investigations by research community.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ADFUU2DH/Valmeekam et al. - 2023 - On the Planning Abilities of Large Language Models.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/GGPP6B8M/2302.html}
}

@inproceedings{valmeekamPlanningAbilitiesLarge2023a,
  title = {On the {{Planning Abilities}} of {{Large Language Models}} - {{A Critical Investigation}}},
  author = {Valmeekam, Karthik and Marquez, Matthew and Sreedharan, Sarath and Kambhampati, Subbarao},
  date = {2023-11-02},
  url = {https://openreview.net/forum?id=X6dEqXIsEW},
  urldate = {2024-04-29},
  abstract = {Intrigued by the claims of emergent reasoning capabilities in LLMs trained on general web corpora, in this paper, we set out to investigate their planning capabilities. We aim to evaluate (1) the effectiveness of LLMs in generating plans autonomously in commonsense planning tasks and (2) the potential of LLMs as a source of heuristic guidance for other agents (AI planners) in their planning tasks. We conduct a systematic study by generating a suite of instances on domains similar to the ones employed in the International Planning Competition and evaluate LLMs in two distinct modes: autonomous and heuristic. Our findings reveal that LLMs’ ability to generate executable plans autonomously is rather limited, with the best model (GPT-4) having an average success rate of \textasciitilde 12\% across the domains. However, the results in the heuristic mode show more promise. In the heuristic mode, we demonstrate that LLM-generated plans can improve the search process for underlying sound planners and additionally show that external verifiers can help provide feedback on the generated plans and back-prompt the LLM for better plan generation.},
  eventtitle = {Thirty-Seventh {{Conference}} on {{Neural Information Processing Systems}}},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/FICETC54/Valmeekam et al. - 2023 - On the Planning Abilities of Large Language Models.pdf}
}

@online{vaswaniAttentionAllYou2017,
  title = {Attention {{Is All You Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  date = {2017-12-05},
  eprint = {1706.03762},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1706.03762},
  url = {http://arxiv.org/abs/1706.03762},
  urldate = {2022-11-02},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ELQ2A888/Vaswani et al. - 2017 - Attention Is All You Need.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/U6DY9ABA/1706.html}
}

@online{vaswaniAttentionAllYou2017a,
  title = {Attention {{Is All You Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  date = {2017-12-05},
  eprint = {1706.03762},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1706.03762},
  url = {http://arxiv.org/abs/1706.03762},
  urldate = {2022-11-03},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/6KBERQZQ/Vaswani et al. - 2017 - Attention Is All You Need.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/VLBTXJZK/1706.html}
}

@article{venkateshReviewFeatureSelection2019,
  title = {A {{Review}} of {{Feature Selection}} and {{Its Methods}}},
  author = {Venkatesh, B. and Anuradha, J.},
  date = {2019-03-01},
  journaltitle = {Cybernetics and Information Technologies},
  volume = {19},
  number = {1},
  pages = {3--26},
  issn = {1314-4081},
  doi = {10.2478/cait-2019-0001},
  url = {https://www.sciendo.com/article/10.2478/cait-2019-0001},
  urldate = {2023-08-26},
  abstract = {Nowadays, being in digital era the data generated by various applications are increasing drastically both row-wise and column wise; this creates a bottleneck for analytics and also increases the burden of machine learning algorithms that work for pattern recognition. This cause of dimensionality can be handled through reduction techniques. The Dimensionality Reduction (DR) can be handled in two ways namely Feature Selection (FS) and Feature Extraction (FE). This paper focuses on a survey of feature selection methods, from this extensive survey we can conclude that most of the FS methods use static data. However, after the emergence of IoT and web-based applications, the data are generated dynamically and grow in a fast rate, so it is likely to have noisy data, it also hinders the performance of the algorithm. With the increase in the size of the data set, the scalability of the FS methods becomes jeopardized. So the existing DR algorithms do not address the issues with the dynamic data. Using FS methods not only reduces the burden of the data but also avoids overfitting of the model.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/3KEEXPGN/Venkatesh y Anuradha - 2019 - A Review of Feature Selection and Its Methods.pdf}
}

@online{vieQualitiesChallengesFuture2021,
  title = {Qualities, Challenges and Future of Genetic Algorithms: A Literature Review},
  shorttitle = {Qualities, Challenges and Future of Genetic Algorithms},
  author = {Vie, Aymeric and Kleinnijenhuis, Alissa M. and Farmer, Doyne J.},
  date = {2021-09-13},
  eprint = {2011.05277},
  eprinttype = {arxiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/2011.05277},
  urldate = {2023-09-05},
  abstract = {Genetic algorithms, computer programs that simulate natural evolution, are increasingly applied across many disciplines. They have been used to solve various optimisation problems from neural network architecture search to strategic games, and to model phenomena of adaptation and learning. Expertise on the qualities and drawbacks of this technique is largely scattered across the literature or former, motivating an compilation of this knowledge at the light of the most recent developments of the field. In this review, we present genetic algorithms, their qualities, limitations and challenges, as well as some future development perspectives. Genetic algorithms are capable of exploring large and complex spaces of possible solutions, to quickly locate promising elements, and provide an adequate modelling tool to describe evolutionary systems, from games to economies. They however suffer from high computation costs, difficult parameter configuration, and crucial representation of the solutions. Recent developments such as GPU, parallel and quantum computing, conception of powerful parameter control methods, and novel approaches in representation strategies, may be keys to overcome those limitations. This compiling review aims at informing practitioners and newcomers in the field alike in their genetic algorithm research, and at outlining promising avenues for future research. It highlights the potential for interdisciplinary research associating genetic algorithms to pulse original discoveries in social sciences, open ended evolution, artificial life and AI.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/IA4N8QY5/Vie et al. - 2021 - Qualities, challenges and future of genetic algori.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/VMWY68X2/2011.html}
}

@inproceedings{vignoloEvolutionaryLocalImprovement2017,
  title = {Evolutionary Local Improvement on Genetic Algorithms for Feature Selection},
  booktitle = {2017 {{XLIII Latin American Computer Conference}} ({{CLEI}})},
  author = {Vignolo, Leandro D. and Gerard, Matias F.},
  date = {2017-09},
  pages = {1--8},
  publisher = {IEEE},
  location = {Cordoba},
  doi = {10.1109/CLEI.2017.8226467},
  url = {http://ieeexplore.ieee.org/document/8226467/},
  urldate = {2023-09-18},
  abstract = {Feature selection is an extremely important matter in pattern recognition, particularly when a large set of features is available without knowledge about the discriminative information provided by each element. The key issue is to define a criterion in order to rank the features, discarding those features that are less relevant, redundant, or noisy. This depends on the particular task, the classifier and the properties of the data. A frequent approach consists on the use of genetic algorithms guided by the classification accuracy. However they are often not able to provide a solution with both a considerable reduction of dimensionality and high accuracy rate. Here we propose a modified version of a genetic algorithm, introducing a novel local improvement approach based on evolution, which is able to obtain better dimensionality-accuracy trade-off. Experimental results on different well known datasets show the advantages of our proposal.},
  eventtitle = {2017 {{XLIII Latin American Computer Conference}} ({{CLEI}})},
  isbn = {978-1-5386-3057-0},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/VPYSQCGL/Vignolo y Gerard - 2017 - Evolutionary local improvement on genetic algorith.pdf}
}

@inproceedings{vikharEvolutionaryAlgorithmsCritical2016,
  title = {Evolutionary Algorithms: {{A}} Critical Review and Its Future Prospects},
  shorttitle = {Evolutionary Algorithms},
  booktitle = {2016 {{International Conference}} on {{Global Trends}} in {{Signal Processing}}, {{Information Computing}} and {{Communication}} ({{ICGTSPICC}})},
  author = {Vikhar, Pradnya A.},
  date = {2016-12},
  pages = {261--265},
  doi = {10.1109/ICGTSPICC.2016.7955308},
  abstract = {Evolutionary algorithm (EA) emerges as an important optimization and search technique in the last decade. EA is a subset of Evolutionary Computations (EC) and belongs to set of modern heuristics based search method. Due to flexible nature and robust behavior inherited from Evolutionary Computation, it becomes efficient means of problem solving method for widely used global optimization problems. It can be used successfully in many applications of high complexity. This paper presents a critical overview of Evolutionary algorithms and its generic procedure for implementation. It further discusses the various practical advantages using evolutionary algorithms over classical methods of optimization. It also includes unusual study of various invariants of EA like Genetic Programming (GP), Genetic Algorithm (GA), Evolutionary Programming (EP) and Evolution Strategies (ES). Extensions of EAs in the form of Memetic algorithms (MA) and distributed EA are also discussed. Further the paper focuses on various refinements done in area of EA to solve real life problems.},
  eventtitle = {2016 {{International Conference}} on {{Global Trends}} in {{Signal Processing}}, {{Information Computing}} and {{Communication}} ({{ICGTSPICC}})},
  keywords = {Distributed EAs,Evolutionary Algorithm,Evolutionary computation,Evolutionary Computations,Genetic algorithms,Genetic programming,Memetic Algorithms,Optimization,Programming,Sociology,Statistics}
}

@incollection{vogel-fernandezEsT5sSpanishModel2022,
  title = {{{esT5s}}: {{A Spanish Model}} for {{Text Summarization}}},
  shorttitle = {{{esT5s}}},
  author = {Vogel-Fernandez, Adrian and Calleja, Pablo and Rico, Mariano},
  date = {2022-09-06},
  doi = {10.3233/SSW220020},
  abstract = {Deep Learning models based on the Transformer architecture have revolutionized the state of the art of NLP tasks. As English is the language in which most significant advances are made, languages like Spanish require specific training, but this training has a computational cost so high that only big corporations with servers and GPUs are capable of generating them. This work has explored how to create a model for the Spanish language from a big multilingual model. Specifically, a model aimed at creating text summarization, a very common task in NLP. The results, concerning the quality of the summarization (ROUGE score), point out that these small models, for a specific language, achieve similar results than much bigger models, with a reasonable training in terms of time required and computational power, and are significantly faster at inference.},
  isbn = {978-1-64368-320-1},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/H9C4YQ2Z/Vogel-Fernandez et al. - 2022 - esT5s A Spanish Model for Text Summarization.pdf}
}

@online{wangBitNetScaling1bit2023,
  title = {{{BitNet}}: {{Scaling}} 1-Bit {{Transformers}} for {{Large Language Models}}},
  shorttitle = {{{BitNet}}},
  author = {Wang, Hongyu and Ma, Shuming and Dong, Li and Huang, Shaohan and Wang, Huaijie and Ma, Lingxiao and Yang, Fan and Wang, Ruiping and Wu, Yi and Wei, Furu},
  date = {2023-10-17},
  eprint = {2310.11453},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2310.11453},
  url = {http://arxiv.org/abs/2310.11453},
  urldate = {2024-03-29},
  abstract = {The increasing size of large language models has posed challenges for deployment and raised concerns about environmental impact due to high energy consumption. In this work, we introduce BitNet, a scalable and stable 1-bit Transformer architecture designed for large language models. Specifically, we introduce BitLinear as a drop-in replacement of the nn.Linear layer in order to train 1-bit weights from scratch. Experimental results on language modeling show that BitNet achieves competitive performance while substantially reducing memory footprint and energy consumption, compared to state-of-the-art 8-bit quantization methods and FP16 Transformer baselines. Furthermore, BitNet exhibits a scaling law akin to full-precision Transformers, suggesting its potential for effective scaling to even larger language models while maintaining efficiency and performance benefits.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/Z9GZ2LVC/Wang et al. - 2023 - BitNet Scaling 1-bit Transformers for Large Langu.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/HRFI9S5I/2310.html}
}

@online{wangDataManagementLarge2023,
  title = {Data {{Management For Large Language Models}}: {{A Survey}}},
  shorttitle = {Data {{Management For Large Language Models}}},
  author = {Wang, Zige and Zhong, Wanjun and Wang, Yufei and Zhu, Qi and Mi, Fei and Wang, Baojun and Shang, Lifeng and Jiang, Xin and Liu, Qun},
  date = {2023-12-04},
  eprint = {2312.01700},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2312.01700},
  url = {http://arxiv.org/abs/2312.01700},
  urldate = {2023-12-11},
  abstract = {Data plays a fundamental role in the training of Large Language Models (LLMs). Effective data management, particularly in the formulation of a well-suited training dataset, holds significance for enhancing model performance and improving training efficiency during pretraining and supervised fine-tuning phases. Despite the considerable importance of data management, the current research community still falls short in providing a systematic analysis of the rationale behind management strategy selection, its consequential effects, methodologies for evaluating curated datasets, and the ongoing pursuit of improved strategies. Consequently, the exploration of data management has attracted more and more attention among the research community. This survey provides a comprehensive overview of current research in data management within both the pretraining and supervised fine-tuning stages of LLMs, covering various noteworthy aspects of data management strategy design: data quantity, data quality, domain/task composition, etc. Looking toward the future, we extrapolate existing challenges and outline promising directions for development in this field. Therefore, this survey serves as a guiding resource for practitioners aspiring to construct powerful LLMs through effective data management practices. The collection of the latest papers is available at https://github.com/ZigeW/data\_management\_LLM.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/JBY7SH6Q/Wang et al. - 2023 - Data Management For Large Language Models A Surve.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/4CJX8UI3/2312.html}
}

@online{wangDocLLMLayoutawareGenerative2023,
  title = {{{DocLLM}}: {{A}} Layout-Aware Generative Language Model for Multimodal Document Understanding},
  shorttitle = {{{DocLLM}}},
  author = {Wang, Dongsheng and Raman, Natraj and Sibue, Mathieu and Ma, Zhiqiang and Babkin, Petr and Kaur, Simerjot and Pei, Yulong and Nourbakhsh, Armineh and Liu, Xiaomo},
  date = {2023-12-31},
  eprint = {2401.00908},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2401.00908},
  url = {http://arxiv.org/abs/2401.00908},
  urldate = {2024-01-03},
  abstract = {Enterprise documents such as forms, invoices, receipts, reports, contracts, and other similar records, often carry rich semantics at the intersection of textual and spatial modalities. The visual cues offered by their complex layouts play a crucial role in comprehending these documents effectively. In this paper, we present DocLLM, a lightweight extension to traditional large language models (LLMs) for reasoning over visual documents, taking into account both textual semantics and spatial layout. Our model differs from existing multimodal LLMs by avoiding expensive image encoders and focuses exclusively on bounding box information to incorporate the spatial layout structure. Specifically, the cross-alignment between text and spatial modalities is captured by decomposing the attention mechanism in classical transformers to a set of disentangled matrices. Furthermore, we devise a pre-training objective that learns to infill text segments. This approach allows us to address irregular layouts and heterogeneous content frequently encountered in visual documents. The pre-trained model is fine-tuned using a large-scale instruction dataset, covering four core document intelligence tasks. We demonstrate that our solution outperforms SotA LLMs on 14 out of 16 datasets across all tasks, and generalizes well to 4 out of 5 previously unseen datasets.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/NVQICTQX/Wang et al. - 2023 - DocLLM A layout-aware generative language model f.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/SZJ3LJXJ/2401.html}
}

@article{wangKnowledGPTEnhancingLarge,
  title = {{{KnowledGPT}}: {{Enhancing Large Language Models}} with {{Retrieval}} and {{Storage Access}} on {{Knowledge Bases}}},
  author = {Wang, Xintao and Yang, Qianwen and Qiu, Yongting and Liang, Jiaqing and He, Qianyu and Gu, Zhouhong and Xiao, Yanghua and Wang, Wei},
  abstract = {Large language models (LLMs) have demonstrated impressive impact in the field of natural language processing, but they still struggle with several issues regarding, such as completeness, timeliness, faithfulness and adaptability. While recent efforts have focuses on connecting LLMs with external knowledge sources, the integration of knowledge bases (KBs) remains understudied and faces several challenges. In this paper, we introduce KnowledGPT, a comprehensive framework to bridge LLMs with various knowledge bases, facilitating both the retrieval and storage of knowledge. The retrieval process employs the program of thought prompting, which generates search language for KBs in code format with pre-defined functions for KB operations. Besides retrieval, KnowledGPT offers the capability to store knowledge in a personalized KB, catering to individual user demands. With extensive experiments, we show that by integrating LLMs with KBs, KnowledGPT properly answers a broader range of questions requiring world knowledge compared with vanilla LLMs, utilizing both knowledge existing in widelyknown KBs and extracted into personalized KBs.},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/7AJJPY4F/Wang et al. - KnowledGPT Enhancing Large Language Models with R.pdf}
}

@article{wangMultiobjectiveEvolutionaryAlgorithm2023,
  title = {A Multi-Objective Evolutionary Algorithm with Decomposition and the Information Feedback for High-Dimensional Medical Data},
  author = {Wang, Mingjing and Heidari, Ali Asghar and Chen, Huiling},
  date = {2023-03-01},
  journaltitle = {Applied Soft Computing},
  shortjournal = {Appl. Soft Comput.},
  volume = {136},
  number = {C},
  issn = {1568-4946},
  doi = {10.1016/j.asoc.2023.110102},
  url = {https://doi.org/10.1016/j.asoc.2023.110102},
  urldate = {2023-09-13},
  abstract = {High-dimensional medical data often leads to a phenomenon known as the ”curse of dimensionality,” which causes additional memory and high training costs, as well as degrading the generalization capacity of learning algorithms. To address this issue, a multi-objective evolutionary algorithm that integrates decomposition and the information feedback model (IFMMOEAD) is proposed for high-dimensional medical data. This algorithm not only considers the number of selected features, but also classification accuracy and correlation measures of features when feature dimensionality reduction is executed. The property of IFMMOEAD is first verified by standard benchmarks DTLZ1–DTLZ7. Then, it is used to develop machine learning algorithms for thirty-five high-dimensional cancer gene expression data sets, showing excellent potential for high-dimensional medical machine learning. Finally, the IFMMOEAD is applied to empirical clinical data of multiple myeloma, significantly outperforming existing algorithms in terms of normalized mutual information and adjusted rand index metrics. We suggest that this algorithm could be implemented in medical information systems as a promising technique for high-dimensional medical problems. • The IFMMOEAD is presented for high-dimensional medical data. • Performance of the IFMMOEAD is enhanced by information feedback model. • The efficacy of IFMMOEAD is shown on benchmarks and is much superior to other methods. • IFMMOEAD may be treated as tool for high-dimensional medical data machine learning.},
  keywords = {Cancer gene expression data sets,Evolutionary decomposition algorithm,High-dimensional medical data,Information feedback model,Medical machine learning,Multi objective,Multiple myeloma}
}

@article{wangMultiobjectiveEvolutionaryAlgorithm2023a,
  title = {A Multi-Objective Evolutionary Algorithm with Decomposition and the Information Feedback for High-Dimensional Medical Data},
  author = {Wang, Mingjing and Heidari, Ali Asghar and Chen, Huiling},
  date = {2023-03-01},
  journaltitle = {Applied Soft Computing},
  shortjournal = {Applied Soft Computing},
  volume = {136},
  pages = {110102},
  issn = {1568-4946},
  doi = {10.1016/j.asoc.2023.110102},
  url = {https://www.sciencedirect.com/science/article/pii/S1568494623001205},
  urldate = {2023-09-13},
  abstract = {High-dimensional medical data often leads to a phenomenon known as the ”curse of dimensionality,” which causes additional memory and high training costs, as well as degrading the generalization capacity of learning algorithms. To address this issue, a multi-objective evolutionary algorithm that integrates decomposition and the information feedback model (IFMMOEAD) is proposed for high-dimensional medical data. This algorithm not only considers the number of selected features, but also classification accuracy and correlation measures of features when feature dimensionality reduction is executed. The property of IFMMOEAD is first verified by standard benchmarks DTLZ1–DTLZ7. Then, it is used to develop machine learning algorithms for thirty-five high-dimensional cancer gene expression data sets, showing excellent potential for high-dimensional medical machine learning. Finally, the IFMMOEAD is applied to empirical clinical data of multiple myeloma, significantly outperforming existing algorithms in terms of normalized mutual information and adjusted rand index metrics. We suggest that this algorithm could be implemented in medical information systems as a promising technique for high-dimensional medical problems.},
  keywords = {Cancer gene expression data sets,Evolutionary decomposition algorithm,High-dimensional medical data,Information feedback model,Medical machine learning,Multi objective,Multiple myeloma},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/Y6Y5RNHS/S1568494623001205.html}
}

@article{wangMultiobjectiveEvolutionaryAlgorithm2023b,
  title = {A Multi-Objective Evolutionary Algorithm with Decomposition and the Information Feedback for High-Dimensional Medical Data},
  author = {Wang, Mingjing and Heidari, Ali Asghar and Chen, Huiling},
  date = {2023-03-01},
  journaltitle = {Applied Soft Computing},
  shortjournal = {Appl. Soft Comput.},
  volume = {136},
  number = {C},
  issn = {1568-4946},
  doi = {10.1016/j.asoc.2023.110102},
  url = {https://doi.org/10.1016/j.asoc.2023.110102},
  urldate = {2023-09-13},
  abstract = {High-dimensional medical data often leads to a phenomenon known as the ”curse of dimensionality,” which causes additional memory and high training costs, as well as degrading the generalization capacity of learning algorithms. To address this issue, a multi-objective evolutionary algorithm that integrates decomposition and the information feedback model (IFMMOEAD) is proposed for high-dimensional medical data. This algorithm not only considers the number of selected features, but also classification accuracy and correlation measures of features when feature dimensionality reduction is executed. The property of IFMMOEAD is first verified by standard benchmarks DTLZ1–DTLZ7. Then, it is used to develop machine learning algorithms for thirty-five high-dimensional cancer gene expression data sets, showing excellent potential for high-dimensional medical machine learning. Finally, the IFMMOEAD is applied to empirical clinical data of multiple myeloma, significantly outperforming existing algorithms in terms of normalized mutual information and adjusted rand index metrics. We suggest that this algorithm could be implemented in medical information systems as a promising technique for high-dimensional medical problems. • The IFMMOEAD is presented for high-dimensional medical data. • Performance of the IFMMOEAD is enhanced by information feedback model. • The efficacy of IFMMOEAD is shown on benchmarks and is much superior to other methods. • IFMMOEAD may be treated as tool for high-dimensional medical data machine learning.},
  keywords = {Cancer gene expression data sets,Evolutionary decomposition algorithm,High-dimensional medical data,Information feedback model,Medical machine learning,Multi objective,Multiple myeloma}
}

@online{wangRATRetrievalAugmented2024,
  title = {{{RAT}}: {{Retrieval Augmented Thoughts Elicit Context-Aware Reasoning}} in {{Long-Horizon Generation}}},
  shorttitle = {{{RAT}}},
  author = {Wang, Zihao and Liu, Anji and Lin, Haowei and Li, Jiaqi and Ma, Xiaojian and Liang, Yitao},
  date = {2024-03-08},
  eprint = {2403.05313},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2403.05313},
  urldate = {2024-03-12},
  abstract = {We explore how iterative revising a chain of thoughts with the help of information retrieval significantly improves large language models' reasoning and generation ability in long-horizon generation tasks, while hugely mitigating hallucination. In particular, the proposed method -- *retrieval-augmented thoughts* (RAT) -- revises each thought step one by one with retrieved information relevant to the task query, the current and the past thought steps, after the initial zero-shot CoT is generated. Applying RAT to GPT-3.5, GPT-4, and CodeLLaMA-7b substantially improves their performances on various long-horizon generation tasks; on average of relatively increasing rating scores by 13.63\% on code generation, 16.96\% on mathematical reasoning, 19.2\% on creative writing, and 42.78\% on embodied task planning. The demo page can be found at https://craftjarvis.github.io/RAT},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/4XNCCKDF/Wang et al. - 2024 - RAT Retrieval Augmented Thoughts Elicit Context-A.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/9NGDJBAZ/2403.html}
}

@online{wangSuperNaturalInstructionsGeneralizationDeclarative2022,
  title = {Super-{{NaturalInstructions}}: {{Generalization}} via {{Declarative Instructions}} on 1600+ {{NLP Tasks}}},
  shorttitle = {Super-{{NaturalInstructions}}},
  author = {Wang, Yizhong and Mishra, Swaroop and Alipoormolabashi, Pegah and Kordi, Yeganeh and Mirzaei, Amirreza and Arunkumar, Anjana and Ashok, Arjun and Dhanasekaran, Arut Selvan and Naik, Atharva and Stap, David and Pathak, Eshaan and Karamanolakis, Giannis and Lai, Haizhi Gary and Purohit, Ishan and Mondal, Ishani and Anderson, Jacob and Kuznia, Kirby and Doshi, Krima and Patel, Maitreya and Pal, Kuntal Kumar and Moradshahi, Mehrad and Parmar, Mihir and Purohit, Mirali and Varshney, Neeraj and Kaza, Phani Rohitha and Verma, Pulkit and Puri, Ravsehaj Singh and Karia, Rushang and Sampat, Shailaja Keyur and Doshi, Savan and Mishra, Siddhartha and Reddy, Sujan and Patro, Sumanta and Dixit, Tanay and Shen, Xudong and Baral, Chitta and Choi, Yejin and Smith, Noah A. and Hajishirzi, Hannaneh and Khashabi, Daniel},
  date = {2022-10-24},
  eprint = {2204.07705},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2204.07705},
  url = {http://arxiv.org/abs/2204.07705},
  urldate = {2023-11-20},
  abstract = {How well can NLP models generalize to a variety of unseen tasks when provided with task instructions? To address this question, we first introduce Super-NaturalInstructions, a benchmark of 1,616 diverse NLP tasks and their expert-written instructions. Our collection covers 76 distinct task types, including but not limited to classification, extraction, infilling, sequence tagging, text rewriting, and text composition. This large and diverse collection of tasks enables rigorous benchmarking of cross-task generalization under instructions -- training models to follow instructions on a subset of tasks and evaluating them on the remaining unseen ones. Furthermore, we build Tk-Instruct, a transformer model trained to follow a variety of in-context instructions (plain language task definitions or k-shot examples). Our experiments show that Tk-Instruct outperforms existing instruction-following models such as InstructGPT by over 9\% on our benchmark despite being an order of magnitude smaller. We further analyze generalization as a function of various scaling parameters, such as the number of observed tasks, the number of instances per task, and model sizes. We hope our dataset and model facilitate future progress towards more general-purpose NLP models.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/8IGATA78/Wang et al. - 2022 - Super-NaturalInstructions Generalization via Decl.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/Y5NBFZC6/2204.html}
}

@online{wangSuperNaturalInstructionsGeneralizationDeclarative2022a,
  title = {Super-{{NaturalInstructions}}: {{Generalization}} via {{Declarative Instructions}} on 1600+ {{NLP Tasks}}},
  shorttitle = {Super-{{NaturalInstructions}}},
  author = {Wang, Yizhong and Mishra, Swaroop and Alipoormolabashi, Pegah and Kordi, Yeganeh and Mirzaei, Amirreza and Arunkumar, Anjana and Ashok, Arjun and Dhanasekaran, Arut Selvan and Naik, Atharva and Stap, David and Pathak, Eshaan and Karamanolakis, Giannis and Lai, Haizhi Gary and Purohit, Ishan and Mondal, Ishani and Anderson, Jacob and Kuznia, Kirby and Doshi, Krima and Patel, Maitreya and Pal, Kuntal Kumar and Moradshahi, Mehrad and Parmar, Mihir and Purohit, Mirali and Varshney, Neeraj and Kaza, Phani Rohitha and Verma, Pulkit and Puri, Ravsehaj Singh and Karia, Rushang and Sampat, Shailaja Keyur and Doshi, Savan and Mishra, Siddhartha and Reddy, Sujan and Patro, Sumanta and Dixit, Tanay and Shen, Xudong and Baral, Chitta and Choi, Yejin and Smith, Noah A. and Hajishirzi, Hannaneh and Khashabi, Daniel},
  date = {2022-10-24},
  eprint = {2204.07705},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2204.07705},
  url = {http://arxiv.org/abs/2204.07705},
  urldate = {2024-03-29},
  abstract = {How well can NLP models generalize to a variety of unseen tasks when provided with task instructions? To address this question, we first introduce Super-NaturalInstructions, a benchmark of 1,616 diverse NLP tasks and their expert-written instructions. Our collection covers 76 distinct task types, including but not limited to classification, extraction, infilling, sequence tagging, text rewriting, and text composition. This large and diverse collection of tasks enables rigorous benchmarking of cross-task generalization under instructions -- training models to follow instructions on a subset of tasks and evaluating them on the remaining unseen ones. Furthermore, we build Tk-Instruct, a transformer model trained to follow a variety of in-context instructions (plain language task definitions or k-shot examples). Our experiments show that Tk-Instruct outperforms existing instruction-following models such as InstructGPT by over 9\% on our benchmark despite being an order of magnitude smaller. We further analyze generalization as a function of various scaling parameters, such as the number of observed tasks, the number of instances per task, and model sizes. We hope our dataset and model facilitate future progress towards more general-purpose NLP models.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/G76DGZWS/Wang et al. - 2022 - Super-NaturalInstructions Generalization via Decl.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/96XM72UJ/2204.html}
}

@online{weertsFairlearnAssessingImproving2023,
  title = {Fairlearn: {{Assessing}} and {{Improving Fairness}} of {{AI Systems}}},
  shorttitle = {Fairlearn},
  author = {Weerts, Hilde and Dudík, Miroslav and Edgar, Richard and Jalali, Adrin and Lutz, Roman and Madaio, Michael},
  date = {2023-03-29},
  eprint = {2303.16626},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2303.16626},
  url = {http://arxiv.org/abs/2303.16626},
  urldate = {2023-05-31},
  abstract = {Fairlearn is an open source project to help practitioners assess and improve fairness of artificial intelligence (AI) systems. The associated Python library, also named fairlearn, supports evaluation of a model's output across affected populations and includes several algorithms for mitigating fairness issues. Grounded in the understanding that fairness is a sociotechnical challenge, the project integrates learning resources that aid practitioners in considering a system's broader societal context.},
  pubstate = {preprint},
  keywords = {Computer Science - Computers and Society},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/KBAKWZA4/Weerts et al. - 2023 - Fairlearn Assessing and Improving Fairness of AI .pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/6AYMW438/2303.html}
}

@online{weinbergPhilosophersNextGenerationLarge2023,
  title = {Philosophers on {{Next-Generation Large Language Models}}},
  author = {Weinberg, Justin},
  date = {2023-03-16},
  url = {https://dailynous.com/2023/03/16/philosophers-on-next-generation-large-language-models/},
  urldate = {2023-05-29},
  abstract = {Back in July of 2020, I published a group post entitled “Philosophers on GPT-3.” At the time, most readers of Daily Nous had not heard of GPT-3 and had no idea what a large language model (LLM) is. How times have changed. Over the past few months, with the release of OpenAI’s ChatGPT and Bing’s AI Chatbot “Sydney” (which we learned a few hours after this post originally went up has “secretly” been running GPT-4) (as well as Meta’s Galactica—pulled after 3 days—and Google’s Bard—currently available only to a small number of people), talk of LLMs has exploded. It seemed like a good time for a follow-up to that original post, one in which philosophers could get together to explore the various issues and questions raised by these next-generation large language models. Here it is. As with the previous post on GPT-3, this edition of Philosophers On was put together by guest editor by Annette Zimmermann. I am very grateful to her for all of the work she put into developing and editing this post. Philosophers On is an occasional series of group posts on issues of current interest, with the aim of showing what the careful thinking characteristic of philosophers (and occasionally scholars in related fields) can bring to popular ongoing conversations. The contributions that the authors make to these posts are not fully worked out position papers, but rather brief thoughts that can serve as prompts for further reflection and discussion. The contributors to this installment of “Philosophers On” are:~Abeba Birhane (Senior Fellow in Trustworthy AI at Mozilla Foundation \& Adjunct Lecturer, School of Computer Science and Statistics at Trinity College Dublin, Ireland), Atoosa Kasirzadeh (Chancellor’s Fellow and tenure-track assistant professor in Philosophy \& Director of Research at the Centre for Technomoral Futures, University of Edinburgh), Fintan Mallory (Postdoctoral Fellow in Philosophy, University of Oslo), Regina Rini (Associate Professor of Philosophy \& Canada Research Chair in Philosophy of Moral and Social Cognition), Eric Schwitzgebel (Professor of Philosophy, University of California, Riverside), Luke Stark (Assistant Professor of Information \& Media Studies, Western University), Karina Vold (Assistant Professor of Philosophy, University of Toronto \& Associate Fellow, Leverhulme Centre for the Future of Intelligence, University of Cambridge), and Annette Zimmermann (Assistant..},
  langid = {american},
  organization = {Daily Nous},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/CCUL569D/philosophers-on-next-generation-large-language-models.html}
}

@online{wongDifferenceSpeakingThinking2023,
  title = {The {{Difference Between Speaking}} and {{Thinking}}},
  author = {Wong, Matteo},
  date = {2023-01-31T21:16:25Z},
  url = {https://www.theatlantic.com/technology/archive/2023/01/chatgpt-ai-language-human-computer-grammar-logic/672902/},
  urldate = {2023-02-01},
  abstract = {The human brain could explain why AI programs are so good at writing grammatically superb nonsense.},
  langid = {english},
  organization = {The Atlantic},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/KNDC8ZVQ/672902.html}
}

@inproceedings{wongUnderstandingDataAugmentation2016,
  title = {Understanding {{Data Augmentation}} for {{Classification}}: {{When}} to {{Warp}}?},
  shorttitle = {Understanding {{Data Augmentation}} for {{Classification}}},
  booktitle = {2016 {{International Conference}} on {{Digital Image Computing}}: {{Techniques}} and {{Applications}} ({{DICTA}})},
  author = {Wong, Sebastien C. and Gatt, Adam and Stamatescu, Victor and McDonnell, Mark D.},
  date = {2016-11},
  pages = {1--6},
  publisher = {IEEE},
  location = {Gold Coast, Australia},
  doi = {10.1109/DICTA.2016.7797091},
  url = {http://ieeexplore.ieee.org/document/7797091/},
  urldate = {2023-08-27},
  abstract = {In this paper we investigate the benefit of augmenting data with synthetically created samples when training a machine learning classifier. Two approaches for creating additional training samples are data warping, which generates additional samples through transformations applied in the data-space, and synthetic over-sampling, which creates additional samples in feature-space. We experimentally evaluate the benefits of data augmentation for a convolutional backpropagation-trained neural network, a convolutional support vector machine and a convolutional extreme learning machine classifier, using the standard MNIST handwritten digit dataset. We found that while it is possible to perform generic augmentation in feature-space, if plausible transforms for the data are known then augmentation in data-space provides a greater benefit for improving performance and reducing overfitting.},
  eventtitle = {2016 {{International Conference}} on {{Digital Image Computing}}: {{Techniques}} and {{Applications}} ({{DICTA}})},
  isbn = {978-1-5090-2896-2},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/52LJCU6P/Wong et al. - 2016 - Understanding Data Augmentation for Classification.pdf}
}

@online{wuAutoGenEnablingNextGen2023,
  title = {{{AutoGen}}: {{Enabling Next-Gen LLM Applications}} via {{Multi-Agent Conversation}}},
  shorttitle = {{{AutoGen}}},
  author = {Wu, Qingyun and Bansal, Gagan and Zhang, Jieyu and Wu, Yiran and Li, Beibin and Zhu, Erkang and Jiang, Li and Zhang, Xiaoyun and Zhang, Shaokun and Liu, Jiale and Awadallah, Ahmed Hassan and White, Ryen W. and Burger, Doug and Wang, Chi},
  date = {2023-10-03},
  eprint = {2308.08155},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2308.08155},
  url = {http://arxiv.org/abs/2308.08155},
  urldate = {2023-12-05},
  abstract = {AutoGen is an open-source framework that allows developers to build LLM applications via multiple agents that can converse with each other to accomplish tasks. AutoGen agents are customizable, conversable, and can operate in various modes that employ combinations of LLMs, human inputs, and tools. Using AutoGen, developers can also flexibly define agent interaction behaviors. Both natural language and computer code can be used to program flexible conversation patterns for different applications. AutoGen serves as a generic infrastructure to build diverse applications of various complexities and LLM capacities. Empirical studies demonstrate the effectiveness of the framework in many example applications, with domains ranging from mathematics, coding, question answering, operations research, online decision-making, entertainment, etc.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/NXXFKQ75/Wu et al. - 2023 - AutoGen Enabling Next-Gen LLM Applications via Mu.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/IIZ4URYS/2308.html}
}

@online{wuBloombergGPTLargeLanguage2023,
  title = {{{BloombergGPT}}: {{A Large Language Model}} for {{Finance}}},
  shorttitle = {{{BloombergGPT}}},
  author = {Wu, Shijie and Irsoy, Ozan and Lu, Steven and Dabravolski, Vadim and Dredze, Mark and Gehrmann, Sebastian and Kambadur, Prabhanjan and Rosenberg, David and Mann, Gideon},
  date = {2023-05-09},
  eprint = {2303.17564},
  eprinttype = {arxiv},
  eprintclass = {cs, q-fin},
  doi = {10.48550/arXiv.2303.17564},
  url = {http://arxiv.org/abs/2303.17564},
  urldate = {2023-11-14},
  abstract = {The use of NLP in the realm of financial technology is broad and complex, with applications ranging from sentiment analysis and named entity recognition to question answering. Large Language Models (LLMs) have been shown to be effective on a variety of tasks; however, no LLM specialized for the financial domain has been reported in literature. In this work, we present BloombergGPT, a 50 billion parameter language model that is trained on a wide range of financial data. We construct a 363 billion token dataset based on Bloomberg's extensive data sources, perhaps the largest domain-specific dataset yet, augmented with 345 billion tokens from general purpose datasets. We validate BloombergGPT on standard LLM benchmarks, open financial benchmarks, and a suite of internal benchmarks that most accurately reflect our intended usage. Our mixed dataset training leads to a model that outperforms existing models on financial tasks by significant margins without sacrificing performance on general LLM benchmarks. Additionally, we explain our modeling choices, training process, and evaluation methodology. We release Training Chronicles (Appendix C) detailing our experience in training BloombergGPT.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/XFNYFRPU/Wu et al. - 2023 - BloombergGPT A Large Language Model for Finance.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/WU3CWR4B/2303.html}
}

@online{wuEVAEEvolutionaryVariational2023,
  title = {{{eVAE}}: {{Evolutionary Variational Autoencoder}}},
  shorttitle = {{{eVAE}}},
  author = {Wu, Zhangkai and Cao, Longbing and Qi, Lei},
  date = {2023-01-01},
  eprint = {2301.00011},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2301.00011},
  url = {http://arxiv.org/abs/2301.00011},
  urldate = {2023-08-28},
  abstract = {The surrogate loss of variational autoencoders (VAEs) poses various challenges to their training, inducing the imbalance between task fitting and representation inference. To avert this, the existing strategies for VAEs focus on adjusting the tradeoff by introducing hyperparameters, deriving a tighter bound under some mild assumptions, or decomposing the loss components per certain neural settings. VAEs still suffer from uncertain tradeoff learning.We propose a novel evolutionary variational autoencoder (eVAE) building on the variational information bottleneck (VIB) theory and integrative evolutionary neural learning. eVAE integrates a variational genetic algorithm into VAE with variational evolutionary operators including variational mutation, crossover, and evolution. Its inner-outer-joint training mechanism synergistically and dynamically generates and updates the uncertain tradeoff learning in the evidence lower bound (ELBO) without additional constraints. Apart from learning a lossy compression and representation of data under the VIB assumption, eVAE presents an evolutionary paradigm to tune critical factors of VAEs and deep neural networks and addresses the premature convergence and random search problem by integrating evolutionary optimization into deep learning. Experiments show that eVAE addresses the KL-vanishing problem for text generation with low reconstruction loss, generates all disentangled factors with sharp images, and improves the image generation quality,respectively. eVAE achieves better reconstruction loss, disentanglement, and generation-inference balance than its competitors.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/2RYGPFIF/Wu et al. - 2023 - eVAE Evolutionary Variational Autoencoder.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/EWP7WMQI/2301.html}
}

@online{xiaoFashionMNISTNovelImage2017,
  title = {Fashion-{{MNIST}}: A {{Novel Image Dataset}} for {{Benchmarking Machine Learning Algorithms}}},
  shorttitle = {Fashion-{{MNIST}}},
  author = {Xiao, Han and Rasul, Kashif and Vollgraf, Roland},
  date = {2017-09-15},
  eprint = {1708.07747},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1708.07747},
  url = {http://arxiv.org/abs/1708.07747},
  urldate = {2023-10-03},
  abstract = {We present Fashion-MNIST, a new dataset comprising of 28x28 grayscale images of 70,000 fashion products from 10 categories, with 7,000 images per category. The training set has 60,000 images and the test set has 10,000 images. Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms, as it shares the same image size, data format and the structure of training and testing splits. The dataset is freely available at https://github.com/zalandoresearch/fashion-mnist},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/UJ6KUBLW/Xiao et al. - 2017 - Fashion-MNIST a Novel Image Dataset for Benchmark.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/9C2ADIEB/1708.html}
}

@online{xiePIXIULargeLanguage2023,
  title = {{{PIXIU}}: {{A Large Language Model}}, {{Instruction Data}} and {{Evaluation Benchmark}} for {{Finance}}},
  shorttitle = {{{PIXIU}}},
  author = {Xie, Qianqian and Han, Weiguang and Zhang, Xiao and Lai, Yanzhao and Peng, Min and Lopez-Lira, Alejandro and Huang, Jimin},
  date = {2023-06-08},
  eprint = {2306.05443},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2306.05443},
  url = {http://arxiv.org/abs/2306.05443},
  urldate = {2023-12-04},
  abstract = {Although large language models (LLMs) has shown great performance on natural language processing (NLP) in the financial domain, there are no publicly available financial tailtored LLMs, instruction tuning datasets, and evaluation benchmarks, which is critical for continually pushing forward the open-source development of financial artificial intelligence (AI). This paper introduces PIXIU, a comprehensive framework including the first financial LLM based on fine-tuning LLaMA with instruction data, the first instruction data with 136K data samples to support the fine-tuning, and an evaluation benchmark with 5 tasks and 9 datasets. We first construct the large-scale multi-task instruction data considering a variety of financial tasks, financial document types, and financial data modalities. We then propose a financial LLM called FinMA by fine-tuning LLaMA with the constructed dataset to be able to follow instructions for various financial tasks. To support the evaluation of financial LLMs, we propose a standardized benchmark that covers a set of critical financial tasks, including five financial NLP tasks and one financial prediction task. With this benchmark, we conduct a detailed analysis of FinMA and several existing LLMs, uncovering their strengths and weaknesses in handling critical financial tasks. The model, datasets, benchmark, and experimental results are open-sourced to facilitate future research in financial AI.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/RJLTBGMM/Xie et al. - 2023 - PIXIU A Large Language Model, Instruction Data an.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/AW6UWFEK/2306.html}
}

@online{xieTravelPlannerBenchmarkRealWorld2024,
  title = {{{TravelPlanner}}: {{A Benchmark}} for {{Real-World Planning}} with {{Language Agents}}},
  shorttitle = {{{TravelPlanner}}},
  author = {Xie, Jian and Zhang, Kai and Chen, Jiangjie and Zhu, Tinghui and Lou, Renze and Tian, Yuandong and Xiao, Yanghua and Su, Yu},
  date = {2024-02-05},
  eprint = {2402.01622},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2402.01622},
  urldate = {2024-05-06},
  abstract = {Planning has been part of the core pursuit for artificial intelligence since its conception, but earlier AI agents mostly focused on constrained settings because many of the cognitive substrates necessary for human-level planning have been lacking. Recently, language agents powered by large language models (LLMs) have shown interesting capabilities such as tool use and reasoning. Are these language agents capable of planning in more complex settings that are out of the reach of prior AI agents? To advance this investigation, we propose TravelPlanner, a new planning benchmark that focuses on travel planning, a common real-world planning scenario. It provides a rich sandbox environment, various tools for accessing nearly four million data records, and 1,225 meticulously curated planning intents and reference plans. Comprehensive evaluations show that the current language agents are not yet capable of handling such complex planning tasks—even GPT-4 only achieves a success rate of 0.6\%. Language agents struggle to stay on task, use the right tools to collect information, or keep track of multiple constraints. However, we note that the mere possibility for language agents to tackle such a complex problem is in itself non-trivial progress. TravelPlanner provides a challenging yet meaningful testbed for future language agents.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/L7PFZZ4A/Xie et al. - 2024 - TravelPlanner A Benchmark for Real-World Planning.pdf}
}

@online{xuSurveyResourceefficientLLM2024,
  title = {A {{Survey}} of {{Resource-efficient LLM}} and {{Multimodal Foundation Models}}},
  author = {Xu, Mengwei and Yin, Wangsong and Cai, Dongqi and Yi, Rongjie and Xu, Daliang and Wang, Qipeng and Wu, Bingyang and Zhao, Yihao and Yang, Chen and Wang, Shihe and Zhang, Qiyang and Lu, Zhenyan and Zhang, Li and Wang, Shangguang and Li, Yuanchun and Liu, Yunxin and Jin, Xin and Liu, Xuanzhe},
  date = {2024-01-15},
  eprint = {2401.08092},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2401.08092},
  url = {http://arxiv.org/abs/2401.08092},
  urldate = {2024-03-20},
  abstract = {Large foundation models, including large language models (LLMs), vision transformers (ViTs), diffusion, and LLM-based multimodal models, are revolutionizing the entire machine learning lifecycle, from training to deployment. However, the substantial advancements in versatility and performance these models offer come at a significant cost in terms of hardware resources. To support the growth of these large models in a scalable and environmentally sustainable way, there has been a considerable focus on developing resource-efficient strategies. This survey delves into the critical importance of such research, examining both algorithmic and systemic aspects. It offers a comprehensive analysis and valuable insights gleaned from existing literature, encompassing a broad array of topics from cutting-edge model architectures and training/serving algorithms to practical system designs and implementations. The goal of this survey is to provide an overarching understanding of how current approaches are tackling the resource challenges posed by large foundation models and to potentially inspire future breakthroughs in this field.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Machine Learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/JCJN7LH8/Xu et al. - 2024 - A Survey of Resource-efficient LLM and Multimodal .pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/V663M8KW/2401.html}
}

@online{yangFinBERTPretrainedLanguage2020,
  title = {{{FinBERT}}: {{A Pretrained Language Model}} for {{Financial Communications}}},
  shorttitle = {{{FinBERT}}},
  author = {Yang, Yi and UY, Mark Christopher Siy and Huang, Allen},
  date = {2020-07-08},
  eprint = {2006.08097},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2006.08097},
  url = {http://arxiv.org/abs/2006.08097},
  urldate = {2023-12-04},
  abstract = {Contextual pretrained language models, such as BERT (Devlin et al., 2019), have made significant breakthrough in various NLP tasks by training on large scale of unlabeled text re-sources.Financial sector also accumulates large amount of financial communication text.However, there is no pretrained finance specific language models available. In this work,we address the need by pretraining a financial domain specific BERT models, FinBERT, using a large scale of financial communication corpora. Experiments on three financial sentiment classification tasks confirm the advantage of FinBERT over generic domain BERT model. The code and pretrained models are available at https://github.com/yya518/FinBERT. We hope this will be useful for practitioners and researchers working on financial NLP tasks.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/T2UA4ASC/Yang et al. - 2020 - FinBERT A Pretrained Language Model for Financial.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/ULTMBN8T/2006.html}
}

@online{yangFinGPTOpenSourceFinancial2023,
  title = {{{FinGPT}}: {{Open-Source Financial Large Language Models}}},
  shorttitle = {{{FinGPT}}},
  author = {Yang, Hongyang and Liu, Xiao-Yang and Wang, Christina Dan},
  date = {2023-06-09},
  eprint = {2306.06031},
  eprinttype = {arxiv},
  eprintclass = {cs, q-fin},
  doi = {10.48550/arXiv.2306.06031},
  url = {http://arxiv.org/abs/2306.06031},
  urldate = {2023-11-14},
  abstract = {Large language models (LLMs) have shown the potential of revolutionizing natural language processing tasks in diverse domains, sparking great interest in finance. Accessing high-quality financial data is the first challenge for financial LLMs (FinLLMs). While proprietary models like BloombergGPT have taken advantage of their unique data accumulation, such privileged access calls for an open-source alternative to democratize Internet-scale financial data. In this paper, we present an open-source large language model, FinGPT, for the finance sector. Unlike proprietary models, FinGPT takes a data-centric approach, providing researchers and practitioners with accessible and transparent resources to develop their FinLLMs. We highlight the importance of an automatic data curation pipeline and the lightweight low-rank adaptation technique in building FinGPT. Furthermore, we showcase several potential applications as stepping stones for users, such as robo-advising, algorithmic trading, and low-code development. Through collaborative efforts within the open-source AI4Finance community, FinGPT aims to stimulate innovation, democratize FinLLMs, and unlock new opportunities in open finance. Two associated code repos are \textbackslash url\{https://github.com/AI4Finance-Foundation/FinGPT\} and \textbackslash url\{https://github.com/AI4Finance-Foundation/FinNLP\}},
  pubstate = {preprint},
  keywords = {LLM_finance},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/LUQ87YNX/Yang et al. - 2023 - FinGPT Open-Source Financial Large Language Model.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/BTU5ZHZX/2306.html}
}

@online{yangPLLaMaOpensourceLarge2024,
  title = {{{PLLaMa}}: {{An Open-source Large Language Model}} for {{Plant Science}}},
  shorttitle = {{{PLLaMa}}},
  author = {Yang, Xianjun and Gao, Junfeng and Xue, Wenxin and Alexandersson, Erik},
  date = {2024-01-03},
  eprint = {2401.01600},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2401.01600},
  url = {http://arxiv.org/abs/2401.01600},
  urldate = {2024-04-08},
  abstract = {Large Language Models (LLMs) have exhibited remarkable capabilities in understanding and interacting with natural language across various sectors. However, their effectiveness is limited in specialized areas requiring high accuracy, such as plant science, due to a lack of specific expertise in these fields. This paper introduces PLLaMa, an open-source language model that evolved from LLaMa-2. It's enhanced with a comprehensive database, comprising more than 1.5 million scholarly articles in plant science. This development significantly enriches PLLaMa with extensive knowledge and proficiency in plant and agricultural sciences. Our initial tests, involving specific datasets related to plants and agriculture, show that PLLaMa substantially improves its understanding of plant science-related topics. Moreover, we have formed an international panel of professionals, including plant scientists, agricultural engineers, and plant breeders. This team plays a crucial role in verifying the accuracy of PLLaMa's responses to various academic inquiries, ensuring its effective and reliable application in the field. To support further research and development, we have made the model's checkpoints and source codes accessible to the scientific community. These resources are available for download at \textbackslash url\{https://github.com/Xianjun-Yang/PLLaMa\}.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computational Engineering Finance and Science,Computer Science - Machine Learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/H9NTBPWP/Yang et al. - 2024 - PLLaMa An Open-source Large Language Model for Pl.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/27E9CYPE/2401.html}
}

@online{yangSeqZeroFewshotCompositional2022,
  title = {{{SeqZero}}: {{Few-shot Compositional Semantic Parsing}} with {{Sequential Prompts}} and {{Zero-shot Models}}},
  shorttitle = {{{SeqZero}}},
  author = {Yang, Jingfeng and Jiang, Haoming and Yin, Qingyu and Zhang, Danqing and Yin, Bing and Yang, Diyi},
  date = {2022-05-15},
  eprint = {2205.07381},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2205.07381},
  urldate = {2023-02-17},
  abstract = {Recent research showed promising results on combining pretrained language models (LMs) with canonical utterance for few-shot semantic parsing. The canonical utterance is often lengthy and complex due to the compositional structure of formal languages. Learning to generate such canonical utterance requires significant amount of data to reach high performance. Fine-tuning with only few-shot samples, the LMs can easily forget pretrained knowledge, overfit spurious biases, and suffer from compositionally out-of-distribution generalization errors. To tackle these issues, we propose a novel few-shot semantic parsing method -- SeqZero. SeqZero decomposes the problem into a sequence of sub-problems, which correspond to the sub-clauses of the formal language. Based on the decomposition, the LMs only need to generate short answers using prompts for predicting sub-clauses. Thus, SeqZero avoids generating a long canonical utterance at once. Moreover, SeqZero employs not only a few-shot model but also a zero-shot model to alleviate the overfitting. In particular, SeqZero brings out the merits from both models via ensemble equipped with our proposed constrained rescaling. SeqZero achieves SOTA performance of BART-based models on GeoQuery and EcommerceQuery, which are two few-shot datasets with compositional data split.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/MDFC5GK3/Yang et al. - 2022 - SeqZero Few-shot Compositional Semantic Parsing w.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/U3TBMKB3/2205.html}
}

@online{yaoReActSynergizingReasoning2022,
  title = {{{ReAct}}: {{Synergizing Reasoning}} and {{Acting}} in {{Language Models}}},
  shorttitle = {{{ReAct}}},
  author = {Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  date = {2022-10-06},
  url = {https://arxiv.org/abs/2210.03629v3},
  urldate = {2024-01-12},
  abstract = {While large language models (LLMs) have demonstrated impressive capabilities across tasks in language understanding and interactive decision making, their abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action plan generation) have primarily been studied as separate topics. In this paper, we explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with external sources, such as knowledge bases or environments, to gather additional information. We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines, as well as improved human interpretability and trustworthiness over methods without reasoning or acting components. Concretely, on question answering (HotpotQA) and fact verification (Fever), ReAct overcomes issues of hallucination and error propagation prevalent in chain-of-thought reasoning by interacting with a simple Wikipedia API, and generates human-like task-solving trajectories that are more interpretable than baselines without reasoning traces. On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34\% and 10\% respectively, while being prompted with only one or two in-context examples. Project site with code: https://react-lm.github.io},
  langid = {english},
  organization = {arXiv.org},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/CENBDHKL/Yao et al. - 2022 - ReAct Synergizing Reasoning and Acting in Languag.pdf}
}

@online{yaoReActSynergizingReasoning2023,
  title = {{{ReAct}}: {{Synergizing Reasoning}} and {{Acting}} in {{Language Models}}},
  shorttitle = {{{ReAct}}},
  author = {Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  date = {2023-03-09},
  eprint = {2210.03629},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2210.03629},
  url = {http://arxiv.org/abs/2210.03629},
  urldate = {2023-11-16},
  abstract = {While large language models (LLMs) have demonstrated impressive capabilities across tasks in language understanding and interactive decision making, their abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action plan generation) have primarily been studied as separate topics. In this paper, we explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with external sources, such as knowledge bases or environments, to gather additional information. We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines, as well as improved human interpretability and trustworthiness over methods without reasoning or acting components. Concretely, on question answering (HotpotQA) and fact verification (Fever), ReAct overcomes issues of hallucination and error propagation prevalent in chain-of-thought reasoning by interacting with a simple Wikipedia API, and generates human-like task-solving trajectories that are more interpretable than baselines without reasoning traces. On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34\% and 10\% respectively, while being prompted with only one or two in-context examples. Project site with code: https://react-lm.github.io},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/TXS3DBLZ/Yao et al. - 2023 - ReAct Synergizing Reasoning and Acting in Languag.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/IH5PDLZF/2210.html}
}

@online{yepesFinancialReportChunking2024,
  title = {Financial {{Report Chunking}} for {{Effective Retrieval Augmented Generation}}},
  author = {Yepes, Antonio Jimeno and You, Yao and Milczek, Jan and Laverde, Sebastian and Li, Renyu},
  date = {2024-02-10},
  eprint = {2402.05131},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2402.05131},
  url = {http://arxiv.org/abs/2402.05131},
  urldate = {2024-02-15},
  abstract = {Chunking information is a key step in Retrieval Augmented Generation (RAG). Current research primarily centers on paragraph-level chunking. This approach treats all texts as equal and neglects the information contained in the structure of documents. We propose an expanded approach to chunk documents by moving beyond mere paragraph-level chunking to chunk primary by structural element components of documents. Dissecting documents into these constituent elements creates a new way to chunk documents that yields the best chunk size without tuning. We introduce a novel framework that evaluates how chunking based on element types annotated by document understanding models contributes to the overall context and accuracy of the information retrieved. We also demonstrate how this approach impacts RAG assisted Question \& Answer task performance. Our research includes a comprehensive analysis of various element types, their role in effective information retrieval, and the impact they have on the quality of RAG outputs. Findings support that element type based chunking largely improve RAG results on financial reporting. Through this research, we are also able to answer how to uncover highly accurate RAG.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/SJQTGQK9/Yepes et al. - 2024 - Financial Report Chunking for Effective Retrieval .pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/Z32474WT/2402.html}
}

@online{yuChainofNoteEnhancingRobustness2023,
  title = {Chain-of-{{Note}}: {{Enhancing Robustness}} in {{Retrieval-Augmented Language Models}}},
  shorttitle = {Chain-of-{{Note}}},
  author = {Yu, Wenhao and Zhang, Hongming and Pan, Xiaoman and Ma, Kaixin and Wang, Hongwei and Yu, Dong},
  date = {2023-11-15},
  eprint = {2311.09210},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2311.09210},
  urldate = {2024-01-10},
  abstract = {Retrieval-augmented language models (RALMs) represent a substantial advancement in the capabilities of large language models, notably in reducing factual hallucination by leveraging external knowledge sources. However, the reliability of the retrieved information is not always guaranteed. The retrieval of irrelevant data can lead to misguided responses, and potentially causing the model to overlook its inherent knowledge, even when it possesses adequate information to address the query. Moreover, standard RALMs often struggle to assess whether they possess adequate knowledge, both intrinsic and retrieved, to provide an accurate answer. In situations where knowledge is lacking, these systems should ideally respond with "unknown" when the answer is unattainable. In response to these challenges, we introduces Chain-of-Noting (CoN), a novel approach aimed at improving the robustness of RALMs in facing noisy, irrelevant documents and in handling unknown scenarios. The core idea of CoN is to generate sequential reading notes for retrieved documents, enabling a thorough evaluation of their relevance to the given question and integrating this information to formulate the final answer. We employed ChatGPT to create training data for CoN, which was subsequently trained on an LLaMa-2 7B model. Our experiments across four open-domain QA benchmarks show that RALMs equipped with CoN significantly outperform standard RALMs. Notably, CoN achieves an average improvement of +7.9 in EM score given entirely noisy retrieved documents and +10.5 in rejection rates for real-time questions that fall outside the pre-training knowledge scope.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/JY2DPA4J/Yu et al. - 2023 - Chain-of-Note Enhancing Robustness in Retrieval-A.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/3ZAJCVHJ/2311.html}
}

@inproceedings{yuNamedEntityRecognition2020,
  title = {Named {{Entity Recognition}} as {{Dependency Parsing}}},
  booktitle = {Proceedings of the 58th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Yu, Juntao and Bohnet, Bernd and Poesio, Massimo},
  date = {2020-07},
  pages = {6470--6476},
  publisher = {Association for Computational Linguistics},
  location = {Online},
  doi = {10.18653/v1/2020.acl-main.577},
  url = {https://aclanthology.org/2020.acl-main.577},
  urldate = {2022-11-03},
  abstract = {Named Entity Recognition (NER) is a fundamental task in Natural Language Processing, concerned with identifying spans of text expressing references to entities. NER research is often focused on flat entities only (flat NER), ignoring the fact that entity references can be nested, as in [Bank of [China]] (Finkel and Manning, 2009). In this paper, we use ideas from graph-based dependency parsing to provide our model a global view on the input via a biaffine model (Dozat and Manning, 2017). The biaffine model scores pairs of start and end tokens in a sentence which we use to explore all spans, so that the model is able to predict named entities accurately. We show that the model works well for both nested and flat NER through evaluation on 8 corpora and achieving SoTA performance on all of them, with accuracy gains of up to 2.2 percentage points.},
  eventtitle = {{{ACL}} 2020},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/EYVAXWDS/Yu et al. - 2020 - Named Entity Recognition as Dependency Parsing.pdf}
}

@online{yurochkinTrainingIndividuallyFair2020,
  title = {Training Individually Fair {{ML}} Models with {{Sensitive Subspace Robustness}}},
  author = {Yurochkin, Mikhail and Bower, Amanda and Sun, Yuekai},
  date = {2020-03-13},
  eprint = {1907.00020},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1907.00020},
  urldate = {2023-06-05},
  abstract = {We consider training machine learning models that are fair in the sense that their performance is invariant under certain sensitive perturbations to the inputs. For example, the performance of a resume screening system should be invariant under changes to the gender and/or ethnicity of the applicant. We formalize this notion of algorithmic fairness as a variant of individual fairness and develop a distributionally robust optimization approach to enforce it during training. We also demonstrate the effectiveness of the approach on two ML tasks that are susceptible to gender and racial biases.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/4UPVYMQY/Yurochkin et al. - 2020 - Training individually fair ML models with Sensitiv.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/AFPMCLF5/1907.html}
}

@online{yuWhiteBoxTransformersSparse2023,
  title = {White-{{Box Transformers}} via {{Sparse Rate Reduction}}: {{Compression Is All There Is}}?},
  shorttitle = {White-{{Box Transformers}} via {{Sparse Rate Reduction}}},
  author = {Yu, Yaodong and Buchanan, Sam and Pai, Druv and Chu, Tianzhe and Wu, Ziyang and Tong, Shengbang and Bai, Hao and Zhai, Yuexiang and Haeffele, Benjamin D. and Ma, Yi},
  date = {2023-11-21},
  eprint = {2311.13110},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2311.13110},
  url = {http://arxiv.org/abs/2311.13110},
  urldate = {2023-11-23},
  abstract = {In this paper, we contend that a natural objective of representation learning is to compress and transform the distribution of the data, say sets of tokens, towards a low-dimensional Gaussian mixture supported on incoherent subspaces. The goodness of such a representation can be evaluated by a principled measure, called sparse rate reduction, that simultaneously maximizes the intrinsic information gain and extrinsic sparsity of the learned representation. From this perspective, popular deep network architectures, including transformers, can be viewed as realizing iterative schemes to optimize this measure. Particularly, we derive a transformer block from alternating optimization on parts of this objective: the multi-head self-attention operator compresses the representation by implementing an approximate gradient descent step on the coding rate of the features, and the subsequent multi-layer perceptron sparsifies the features. This leads to a family of white-box transformer-like deep network architectures, named CRATE, which are mathematically fully interpretable. We show, by way of a novel connection between denoising and compression, that the inverse to the aforementioned compressive encoding can be realized by the same class of CRATE architectures. Thus, the so-derived white-box architectures are universal to both encoders and decoders. Experiments show that these networks, despite their simplicity, indeed learn to compress and sparsify representations of large-scale real-world image and text datasets, and achieve performance very close to highly engineered transformer-based models: ViT, MAE, DINO, BERT, and GPT2. We believe the proposed computational framework demonstrates great potential in bridging the gap between theory and practice of deep learning, from a unified perspective of data compression. Code is available at: https://ma-lab-berkeley.github.io/CRATE .},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/VRY5PXRP/Yu et al. - 2023 - White-Box Transformers via Sparse Rate Reduction .pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/QYCGLLLH/2311.html}
}

@online{zagoruykoWideResidualNetworks2017,
  title = {Wide {{Residual Networks}}},
  author = {Zagoruyko, Sergey and Komodakis, Nikos},
  date = {2017-06-14},
  eprint = {1605.07146},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1605.07146},
  url = {http://arxiv.org/abs/1605.07146},
  urldate = {2023-10-03},
  abstract = {Deep residual networks were shown to be able to scale up to thousands of layers and still have improving performance. However, each fraction of a percent of improved accuracy costs nearly doubling the number of layers, and so training very deep residual networks has a problem of diminishing feature reuse, which makes these networks very slow to train. To tackle these problems, in this paper we conduct a detailed experimental study on the architecture of ResNet blocks, based on which we propose a novel architecture where we decrease depth and increase width of residual networks. We call the resulting network structures wide residual networks (WRNs) and show that these are far superior over their commonly used thin and very deep counterparts. For example, we demonstrate that even a simple 16-layer-deep wide residual network outperforms in accuracy and efficiency all previous deep residual networks, including thousand-layer-deep networks, achieving new state-of-the-art results on CIFAR, SVHN, COCO, and significant improvements on ImageNet. Our code and models are available at https://github.com/szagoruyko/wide-residual-networks},
  pubstate = {preprint},
  keywords = {Computer Science - Neural and Evolutionary Computing},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/H3SCHZ5I/Zagoruyko y Komodakis - 2017 - Wide Residual Networks.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/7Q95Z7ZQ/1605.html}
}

@online{zaratianaHierarchicalTransformerModel2022,
  title = {Hierarchical {{Transformer Model}} for {{Scientific Named Entity Recognition}}},
  author = {Zaratiana, Urchade and Holat, Pierre and Tomeh, Nadi and Charnois, Thierry},
  date = {2022-03-28},
  eprint = {2203.14710},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2203.14710},
  urldate = {2022-11-08},
  abstract = {The task of Named Entity Recognition (NER) is an important component of many natural language processing systems, such as relation extraction and knowledge graph construction. In this work, we present a simple and effective approach for Named Entity Recognition. The main idea of our approach is to encode the input subword sequence with a pre-trained transformer such as BERT, and then, instead of directly classifying the word labels, another layer of transformer is added to the subword representation to better encode the word-level interaction. We evaluate our approach on three benchmark datasets for scientific NER, particularly in the computer science and biomedical domains. Experimental results show that our model outperforms the current state-of-the-art on SciERC and TDM datasets without requiring external resources or specific data augmentation. Code is available at \textbackslash url\{https://github.com/urchade/HNER\}.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/2Q3UT4F9/Zaratiana et al. - 2022 - Hierarchical Transformer Model for Scientific Name.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/S7LALJ28/2203.html}
}

@article{zebariComprehensiveReviewDimensionality2020,
  title = {A {{Comprehensive Review}} of {{Dimensionality Reduction Techniques}} for {{Feature Selection}} and {{Feature Extraction}}},
  author = {Zebari, Rizgar and Abdulazeez, Adnan and Zeebaree, Diyar and Zebari, Dilovan and Saeed, Jwan},
  date = {2020-05-15},
  journaltitle = {Journal of Applied Science and Technology Trends},
  shortjournal = {JASTT},
  volume = {1},
  number = {2},
  pages = {56--70},
  issn = {2708-0757},
  doi = {10.38094/jastt1224},
  url = {https://jastt.org/index.php/jasttpath/article/view/24},
  urldate = {2023-08-26},
  abstract = {Due to sharp increases in data dimensions, working on every data mining or machine learning (ML) task requires more efficient techniques to get the desired results. Therefore, in recent years, researchers have proposed and developed many methods and techniques to reduce the high dimensions of data and to attain the required accuracy. To ameliorate the accuracy of learning features as well as to decrease the training time dimensionality reduction is used as a pre-processing step, which can eliminate irrelevant data, noise, and redundant features. Dimensionality reduction (DR) has been performed based on two main methods, which are feature selection (FS) and feature extraction (FE). FS is considered an important method because data is generated continuously at an ever-increasing rate; some serious dimensionality problems can be reduced with this method, such as decreasing redundancy effectively, eliminating irrelevant data, and ameliorating result comprehensibility. Moreover, FE transacts with the problem of finding the most distinctive, informative, and decreased set of features to ameliorate the efficiency of both the processing and storage of data. This paper offers a comprehensive approach to FS and FE in the scope of DR. Moreover, the details of each paper, such as used algorithms/approaches, datasets, classifiers, and achieved results are comprehensively analyzed and summarized. Besides, a systematic discussion of all of the reviewed methods to highlight authors' trends, determining the method(s) has been done, which significantly reduced computational time, and selecting the most accurate classifiers. As a result, the different types of both methods have been discussed and analyzed the findings.},
  langid = {english},
  keywords = {fs_desafios},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/EEYN9SK9/Zebari et al. - 2020 - A Comprehensive Review of Dimensionality Reduction.pdf}
}

@online{zelikmanQuietSTaRLanguageModels2024,
  title = {Quiet-{{STaR}}: {{Language Models Can Teach Themselves}} to {{Think Before Speaking}}},
  shorttitle = {Quiet-{{STaR}}},
  author = {Zelikman, Eric and Harik, Georges and Shao, Yijia and Jayasiri, Varuna and Haber, Nick and Goodman, Noah D.},
  date = {2024-03-18},
  eprint = {2403.09629},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2403.09629},
  urldate = {2024-03-22},
  abstract = {When writing and talking, people sometimes pause to think. Although reasoning-focused works have often framed reasoning as a method of answering questions or completing agentic tasks, reasoning is implicit in almost all written text. For example, this applies to the steps not stated between the lines of a proof or to the theory of mind underlying a conversation. In the Self-Taught Reasoner (STaR, Zelikman et al. 2022), useful thinking is learned by inferring rationales from few-shot examples in question-answering and learning from those that lead to a correct answer. This is a highly constrained setting – ideally, a language model could instead learn to infer unstated rationales in arbitrary text. We present Quiet-STaR, a generalization of STaR in which LMs learn to generate rationales at each token to explain future text, improving their predictions. We address key challenges, including 1) the computational cost of generating continuations, 2) the fact that the LM does not initially know how to generate or use internal thoughts, and 3) the need to predict beyond individual next tokens. To resolve these, we propose a tokenwise parallel sampling algorithm, using learnable tokens indicating a thought’s start and end, and an extended teacher-forcing technique. Encouragingly, generated rationales disproportionately help model difficult-to-predict tokens and improve the LM’s ability to directly answer difficult questions. In particular, after continued pretraining of an LM on a corpus of internet text with Quiet-STaR, we find zero-shot improvements on GSM8K (5.9\%→10.9\%) and CommonsenseQA (36.3\%→47.2\%) and observe a perplexity improvement of difficult tokens in natural text. Crucially, these improvements require no fine-tuning on these tasks. Quiet-STaR marks a step towards LMs that can learn to reason in a more general and scalable way.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/MLCCJUCU/Zelikman et al. - 2024 - Quiet-STaR Language Models Can Teach Themselves t.pdf}
}

@online{zhangERNIEEnhancedLanguage2019,
  title = {{{ERNIE}}: {{Enhanced Language Representation}} with {{Informative Entities}}},
  shorttitle = {{{ERNIE}}},
  author = {Zhang, Zhengyan and Han, Xu and Liu, Zhiyuan and Jiang, Xin and Sun, Maosong and Liu, Qun},
  date = {2019-06-04},
  eprint = {1905.07129},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1905.07129},
  urldate = {2022-11-02},
  abstract = {Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better language understanding. We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves significant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The source code of this paper can be obtained from https://github.com/thunlp/ERNIE.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/H6QNR4Y5/Zhang et al. - 2019 - ERNIE Enhanced Language Representation with Infor.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/RB76GE3C/1905.html}
}

@article{zhangFeatureSelectionMultiview2019,
  title = {Feature Selection with Multi-View Data: {{A}} Survey},
  shorttitle = {Feature Selection with Multi-View Data},
  author = {Zhang, Rui and Nie, Feiping and Li, Xuelong and Wei, Xian},
  date = {2019-10},
  journaltitle = {Information Fusion},
  shortjournal = {Information Fusion},
  volume = {50},
  pages = {158--167},
  issn = {15662535},
  doi = {10.1016/j.inffus.2018.11.019},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1566253518303841},
  urldate = {2023-08-26},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/RK3N8NV6/Zhang et al. - 2019 - Feature selection with multi-view data A survey.pdf}
}

@online{zhangImproveDiverseText2019,
  title = {Improve {{Diverse Text Generation}} by {{Self Labeling Conditional Variational Auto Encoder}}},
  author = {Zhang, Yuchi and Wang, Yongliang and Zhang, Liping and Zhang, Zhiqiang and Gai, Kun},
  date = {2019-03-26},
  eprint = {1903.10842},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1903.10842},
  url = {http://arxiv.org/abs/1903.10842},
  urldate = {2023-09-29},
  abstract = {Diversity plays a vital role in many text generating applications. In recent years, Conditional Variational Auto Encoders (CVAE) have shown promising performances for this task. However, they often encounter the so called KL-Vanishing problem. Previous works mitigated such problem by heuristic methods such as strengthening the encoder or weakening the decoder while optimizing the CVAE objective function. Nevertheless, the optimizing direction of these methods are implicit and it is hard to find an appropriate degree to which these methods should be applied. In this paper, we propose an explicit optimizing objective to complement the CVAE to directly pull away from KL-vanishing. In fact, this objective term guides the encoder towards the "best encoder" of the decoder to enhance the expressiveness. A labeling network is introduced to estimate the "best encoder". It provides a continuous label in the latent space of CVAE to help build a close connection between latent variables and targets. The whole proposed method is named Self Labeling CVAE\textasciitilde (SLCVAE). To accelerate the research of diverse text generation, we also propose a large native one-to-many dataset. Extensive experiments are conducted on two tasks, which show that our method largely improves the generating diversity while achieving comparable accuracy compared with state-of-art algorithms.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/QB6ERJAW/Zhang et al. - 2019 - Improve Diverse Text Generation by Self Labeling C.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/Y4IX8L7G/1903.html}
}

@online{zhangInterpretableUnifiedLanguage2023,
  title = {Interpretable {{Unified Language Checking}}},
  author = {Zhang, Tianhua and Luo, Hongyin and Chuang, Yung-Sung and Fang, Wei and Gaitskell, Luc and Hartvigsen, Thomas and Wu, Xixin and Fox, Danny and Meng, Helen and Glass, James},
  date = {2023-04-07},
  eprint = {2304.03728},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2304.03728},
  urldate = {2023-05-30},
  abstract = {The claim mentions global warming is due to other cause than solar variations. Scientific fact: recent global warming is due to human activities instead of solar variations. Conclusion: It is fair to say that.},
  langid = {english},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/MT8WEKHT/2304.pdf}
}

@online{zhaoDeeperUnderstandingVariational2017,
  title = {Towards {{Deeper Understanding}} of {{Variational Autoencoding Models}}},
  author = {Zhao, Shengjia and Song, Jiaming and Ermon, Stefano},
  date = {2017-02-28},
  eprint = {1702.08658},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1702.08658},
  urldate = {2023-09-24},
  abstract = {We propose a new family of optimization criteria for variational auto-encoding models, generalizing the standard evidence lower bound. We provide conditions under which they recover the data distribution and learn latent features, and formally show that common issues such as blurry samples and uninformative latent features arise when these conditions are not met. Based on these new insights, we propose a new sequential VAE model that can generate sharp samples on the LSUN image dataset based on pixel-wise reconstruction loss, and propose an optimization criterion that encourages unsupervised learning of informative latent features.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/LY8L9IWR/Zhao et al. - 2017 - Towards Deeper Understanding of Variational Autoen.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/VQMM2EWN/1702.html}
}

@online{zhaoRevolutionizingFinanceLLMs2024,
  title = {Revolutionizing {{Finance}} with {{LLMs}}: {{An Overview}} of {{Applications}} and {{Insights}}},
  shorttitle = {Revolutionizing {{Finance}} with {{LLMs}}},
  author = {Zhao, Huaqin and Liu, Zhengliang and Wu, Zihao and Li, Yiwei and Yang, Tianze and Shu, Peng and Xu, Shaochen and Dai, Haixing and Zhao, Lin and Mai, Gengchen and Liu, Ninghao and Liu, Tianming},
  date = {2024-01-21},
  eprint = {2401.11641},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2401.11641},
  urldate = {2024-01-30},
  abstract = {In recent years, Large Language Models (LLMs) like ChatGPT have seen considerable advancements and have been applied in diverse fields. Built on the Transformer architecture, these models are trained on extensive datasets, enabling them to understand and generate human language effectively. In the financial domain, the deployment of LLMs is gaining momentum. These models are being utilized for automating financial report generation, forecasting market trends, analyzing investor sentiment, and offering personalized financial advice. Leveraging their natural language processing capabilities, LLMs can distill key insights from vast financial data, aiding institutions in making informed investment choices and enhancing both operational efficiency and customer satisfaction. In this study, we provide a comprehensive overview of the emerging integration of LLMs into various financial tasks. Additionally, we conducted holistic tests on multiple financial tasks through the combination of natural language instructions. Our findings show that GPT-4 effectively follow prompt instructions across various financial tasks. This survey and evaluation of LLMs in the financial domain aim to deepen the understanding of LLMs' current role in finance for both financial practitioners and LLM researchers, identify new research and application prospects, and highlight how these technologies can be leveraged to solve practical challenges in the finance industry.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/FHCCBSEF/Zhao et al. - 2024 - Revolutionizing Finance with LLMs An Overview of .pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/U8CM3Q3I/2401.html}
}

@article{zhaoSpectralFeatureSelection,
  title = {Spectral {{Feature Selection}} for {{Data Mining}}},
  author = {Zhao, Zheng Alan and Liu, Huan},
  langid = {english},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/V7I76BY7/Zhao y Liu - Spectral Feature Selection for Data Mining.pdf}
}

@online{zhengTakeStepBack2023,
  title = {Take a {{Step Back}}: {{Evoking Reasoning}} via {{Abstraction}} in {{Large Language Models}}},
  shorttitle = {Take a {{Step Back}}},
  author = {Zheng, Huaixiu Steven and Mishra, Swaroop and Chen, Xinyun and Cheng, Heng-Tze and Chi, Ed H. and Le, Quoc V. and Zhou, Denny},
  date = {2023-10-09},
  eprint = {2310.06117},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2310.06117},
  urldate = {2023-12-26},
  abstract = {We present Step-Back Prompting, a simple prompting technique that enables LLMs to do abstractions to derive high-level concepts and first principles from instances containing specific details. Using the concepts and principles to guide the reasoning steps, LLMs significantly improve their abilities in following a correct reasoning path towards the solution. We conduct experiments of Step-Back Prompting with PaLM-2L models and observe substantial performance gains on a wide range of challenging reasoning-intensive tasks including STEM, Knowledge QA, and Multi-Hop Reasoning. For instance, Step-Back Prompting improves PaLM-2L performance on MMLU Physics and Chemistry by 7\% and 11\%, TimeQA by 27\%, and MuSiQue by 7\%.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/AD72ZB9R/Zheng et al. - 2023 - Take a Step Back Evoking Reasoning via Abstractio.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/3CFTQ2NK/2310.html}
}

@online{zhengTakeStepBack2023a,
  title = {Take a {{Step Back}}: {{Evoking Reasoning}} via {{Abstraction}} in {{Large Language Models}}},
  shorttitle = {Take a {{Step Back}}},
  author = {Zheng, Huaixiu Steven and Mishra, Swaroop and Chen, Xinyun and Cheng, Heng-Tze and Chi, Ed H. and Le, Quoc V. and Zhou, Denny},
  date = {2023-10-09},
  eprint = {2310.06117},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2310.06117},
  urldate = {2024-01-26},
  abstract = {We present Step-Back Prompting, a simple prompting technique that enables LLMs to do abstractions to derive high-level concepts and first principles from instances containing specific details. Using the concepts and principles to guide the reasoning steps, LLMs significantly improve their abilities in following a correct reasoning path towards the solution. We conduct experiments of Step-Back Prompting with PaLM-2L models and observe substantial performance gains on a wide range of challenging reasoning-intensive tasks including STEM, Knowledge QA, and Multi-Hop Reasoning. For instance, Step-Back Prompting improves PaLM-2L performance on MMLU Physics and Chemistry by 7\% and 11\%, TimeQA by 27\%, and MuSiQue by 7\%.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/9MXY5LWT/Zheng et al. - 2023 - Take a Step Back Evoking Reasoning via Abstractio.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/3Y8MIMPX/2310.html}
}

@online{zhouSelfDiscoverLargeLanguage2024,
  title = {Self-{{Discover}}: {{Large Language Models Self-Compose Reasoning Structures}}},
  shorttitle = {Self-{{Discover}}},
  author = {Zhou, Pei and Pujara, Jay and Ren, Xiang and Chen, Xinyun and Cheng, Heng-Tze and Le, Quoc V. and Chi, Ed H. and Zhou, Denny and Mishra, Swaroop and Zheng, Huaixiu Steven},
  date = {2024-02-05},
  eprint = {2402.03620},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2402.03620},
  url = {http://arxiv.org/abs/2402.03620},
  urldate = {2024-02-09},
  abstract = {We introduce SELF-DISCOVER, a general framework for LLMs to self-discover the task-intrinsic reasoning structures to tackle complex reasoning problems that are challenging for typical prompting methods. Core to the framework is a self-discovery process where LLMs select multiple atomic reasoning modules such as critical thinking and step-by-step thinking, and compose them into an explicit reasoning structure for LLMs to follow during decoding. SELF-DISCOVER substantially improves GPT-4 and PaLM 2's performance on challenging reasoning benchmarks such as BigBench-Hard, grounded agent reasoning, and MATH, by as much as 32\% compared to Chain of Thought (CoT). Furthermore, SELF-DISCOVER outperforms inference-intensive methods such as CoT-Self-Consistency by more than 20\%, while requiring 10-40x fewer inference compute. Finally, we show that the self-discovered reasoning structures are universally applicable across model families: from PaLM 2-L to GPT-4, and from GPT-4 to Llama2, and share commonalities with human reasoning patterns.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/Z4GDDENL/Zhou et al. - 2024 - Self-Discover Large Language Models Self-Compose .pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/BW99TP6W/2402.html}
}

@inproceedings{zhuTATQAQuestionAnswering2021,
  title = {{{TAT-QA}}: {{A Question Answering Benchmark}} on a {{Hybrid}} of {{Tabular}} and {{Textual Content}} in {{Finance}}},
  shorttitle = {{{TAT-QA}}},
  booktitle = {Proceedings of the 59th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} and the 11th {{International Joint Conference}} on {{Natural Language Processing}} ({{Volume}} 1: {{Long Papers}})},
  author = {Zhu, Fengbin and Lei, Wenqiang and Huang, Youcheng and Wang, Chao and Zhang, Shuo and Lv, Jiancheng and Feng, Fuli and Chua, Tat-Seng},
  editor = {Zong, Chengqing and Xia, Fei and Li, Wenjie and Navigli, Roberto},
  date = {2021-08},
  pages = {3277--3287},
  publisher = {Association for Computational Linguistics},
  location = {Online},
  doi = {10.18653/v1/2021.acl-long.254},
  url = {https://aclanthology.org/2021.acl-long.254},
  urldate = {2023-12-24},
  abstract = {Hybrid data combining both tabular and textual content (e.g., financial reports) are quite pervasive in the real world. However, Question Answering (QA) over such hybrid data is largely neglected in existing research. In this work, we extract samples from real financial reports to build a new large-scale QA dataset containing both Tabular And Textual data, named TAT-QA, where numerical reasoning is usually required to infer the answer, such as addition, subtraction, multiplication, division, counting, comparison/sorting, and the compositions. We further propose a novel QA model termed TAGOP, which is capable of reasoning over both tables and text. It adopts sequence tagging to extract relevant cells from the table along with relevant spans from the text to infer their semantics, and then applies symbolic reasoning over them with a set of aggregation operators to arrive at the final answer. TAGOP achieves 58.0\% inF1, which is an 11.1\% absolute increase over the previous best baseline model, according to our experiments on TAT-QA. But this result still lags far behind performance of expert human, i.e.90.8\% in F1. It is demonstrated that our TAT-QA is very challenging and can serve as a benchmark for training and testing powerful QA models that address hybrid form data.},
  eventtitle = {{{ACL-IJCNLP}} 2021},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/JGMMSFLP/Zhu et al. - 2021 - TAT-QA A Question Answering Benchmark on a Hybrid.pdf}
}

@online{zliobaiteLearningConceptDrift2010,
  title = {Learning under {{Concept Drift}}: An {{Overview}}},
  shorttitle = {Learning under {{Concept Drift}}},
  author = {Žliobaitė, Indrė},
  date = {2010-10-22},
  eprint = {1010.4784},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1010.4784},
  url = {http://arxiv.org/abs/1010.4784},
  urldate = {2023-09-22},
  abstract = {Concept drift refers to a non stationary learning problem over time. The training and the application data often mismatch in real life problems. In this report we present a context of concept drift problem 1. We focus on the issues relevant to adaptive training set formation. We present the framework and terminology, and formulate a global picture of concept drift learners design. We start with formalizing the framework for the concept drifting data in Section 1. In Section 2 we discuss the adaptivity mechanisms of the concept drift learners. In Section 3 we overview the principle mechanisms of concept drift learners. In this chapter we give a general picture of the available algorithms and categorize them based on their properties. Section 5 discusses the related research fields and Section 5 groups and presents major concept drift applications. This report is intended to give a bird's view of concept drift research field, provide a context of the research and position it within broad spectrum of research fields and applications.},
  pubstate = {preprint},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/4K5MWPKQ/Žliobaitė - 2010 - Learning under Concept Drift an Overview.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/TUIFHJAQ/1010.html}
}

@online{zolkepliLargeMalaysianLanguage2024,
  title = {Large {{Malaysian Language Model Based}} on {{Mistral}} for {{Enhanced Local Language Understanding}}},
  author = {Zolkepli, Husein and Razak, Aisyah and Adha, Kamarul and Nazhan, Ariff},
  date = {2024-02-04},
  eprint = {2401.13565},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2401.13565},
  urldate = {2024-04-07},
  abstract = {In this paper, we present significant advancements in the pretraining of Mistral 7B, a large-scale language model, using a dataset of 32.6 GB, equivalent to 1.1 billion tokens. We explore the impact of extending the context length, releasing models with context lengths of 4096 and 32768 tokens, and further refining performance with a specialized 16384 context length instruction-tuned model, we called it Malaysian Mistral. Our experiments demonstrate the efficacy of continue pretraining and the influence of extended context lengths on Mistral 7B's language understanding capabilities. Additionally, we release a model specifically tuned with a 16384 context length instruction, showcasing its potential for capturing nuanced language intricacies. Furthermore, our research contributes to the benchmarking of Malaysian Mistral against prominent language models, including ChatGPT3.5 and Claude 2. We present compelling results indicating Malaysian Mistral's superior performance on Tatabahasa (Malay grammar) test set, particularly when fine-tuned with instructions. All models released at https://huggingface.co/collections/mesolitica/malaysian-mistral-7b-6528f2ec825f4bba46c1700c},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/JXQUIN5Z/Zolkepli et al. - 2024 - Large Malaysian Language Model Based on Mistral fo.pdf;/home/sebacastillo/snap/zotero-snap/common/Zotero/storage/RHD9LG9W/2401.html}
}

@report{zotero-75,
  type = {report}
}

@book{zotero-79,
  type = {book}
}

@video{zotero-812,
  entrysubtype = {video}
}
