# Los modelos clásicos y su aplicación al espacio completo de características {#sec-Capitulo2}

En este capítulo revisaremos el desempeño de *algoritmos clásicos* en la solución de los problemas elegidos para nuestra investigación, tomando como campo de búsqueda el espacio completo de características de los datasets. El objetivo de esta exploración es doble: por un lado contar con métricas de base para comparar el desempeño de nuestras soluciones, y por otro, identificar los modelos más apropiados para emplear como función de aptitud en nuestro algoritmo genético. Al mismo tiempo, revisaremos las características de los datasets elegidos para nuestro estudio, procurando identificar aquellos rasgos que puedan influir en el desempeño de los modelos. Particularmente, nos centraremos en la alta dimensionalidad y la escasez muestral, el desbalance de clases y el ruido.

## Datos elegidos en nuestro estudio

El conjunto de datos elegidos en este trabajo incluye cinco datasets: *Madelon*, *Gisette*, *Leukemia*, *GCM* y *All Leukemia*. El último de ellos, *All Leukemia*, es un dataset introducido en este trabajo iniciada la etapa de experimentación de integración entre *algoritmos genéticos y autocodificadores variacionales*. Por esa razón, no está incluido en la revisión de desempeño de los algoritmos clásicos que presentaremos en este capítulo. No obstante ello, se incluye en el detalle de los datasets para que el lector tenga una idea de la variedad de problemas que se tuvieron en cuenta para validar los resultados de nuestra propuesta.

Como veremos a continuación, cada dataset plantea desafíos distintos en términos de aprendizaje, y posee distintos niveles de complejidad en su composición. El dataset *Madelon* es un conjunto artificial de datos con 2000 observaciones y 500 características (2000x500), donde el objetivo es resolver un problema XOR multidimensional con 5 características relevantes y 15 características corresponden a combinaciones lineales de aquellas (i.e. 15 características redundantes). Las otras 480 características fueron generadas aleatoriamente (no tienen poder predictivo). Madelon es un problema de clasificación de dos clases con variables de entrada binarias dispersas. Las dos clases están equilibradas, y los datos se dividen en conjuntos de entrenamiento y prueba. Fue creado para el desafío de Selección de Características [NIPS_2003](http://clopinet.com/isabelle/Projects/NIPS2003/), y está disponible en el Repositorio [UCI](https://archive.ics.uci.edu/dataset/171/madelon). Los datos están divididos en un conjunto de entrenamiento y un conjunto de testeo. 

Como es fácil de advertir, este es un problema donde la información relevante está presente junto a información redundante y otra sin valor predictivo. Es decir, existe un alto nivel de ruido en los datos, planteando importantes desafíos para los algoritmos de aprendizaje, y uno particularmente interesante para el problema de selección de características. Respecto de las dimensiones del problema, no se estaría en una situación crítica de alta dimensionalidad y escasez muestral, ya que el número de observaciones es mayor que el de características. Sin perjuicio de ello, aún queda por determinar si la cantidad de patrones disponibles es suficiente para que los algoritmos de aprendizaje puedan encontrar una solución en un contexto tan ruidoso.

El dataset *Gisette* es un dataset creado para trabajar el problema de reconocimiento de dígitos escritos a mano [@isabelleguyonGisette2004]. Este conjunto de datos forma parte de los cinco conjuntos utilizados en el desafío de selección de características NIPS 2003. Tiene 13500 observaciones y 5000 atributos (13500x5000). El desafío radica en diferenciar los dígitos '4' y '9', que suelen ser fácilmente confundibles entre sí. Los dígitos han sido normalizados en tamaño y centrados en una imagen fija de 28x28 píxeles. Además, se crearon nuevas características como combinación de las existentes para construir un espacio de mayor dimensión. También se añadieron características distractoras denominadas "sondas", que no tienen poder predictivo. El orden de las características y patrones fue aleatorizado. Los datos están divididos en un conjunto de entrenamiento y un conjunto de testeo.

En este caso, nos encontramos en un escenario similar al de *Madelon*, con un dataset ruidoso e información redundante. La particularidad de *Gisette* es que, pese a mantener una relación positiva entre obervaciones y características (las primeras son más que las segundas), posee un espacio de búsqueda sensiblemente más grande y, eventualmente, más complejo que el de *Madelon*. Por esa razón, esperamos que este dataset sea computacionalmente más exigente que el anterior.

El dataset *Leukemia* es un análisis de datos de expresión genética obtenidos de microarreglos de ADN, se estudia en Golub [-@golubMolecularClassificationCancer1999] para la clasificación de tipos de cáncer. Se construyó un conjunto de datos con 72 observaciones y 7129 mediciones (72x7129) de las clases ALL (leucemia linfocítica aguda) y AML (leucemia mielogénica aguda). El problema es distinguir entre estas dos variantes de leucemia (ALL y AML). Los datos se dividen originalmente en dos subconjuntos: un conjunto de entrenamiento de 38 observaciones y un conjunto de testeo de 34 observaciones.

Con este dataset nos encontramos, precisamente, en el escenario de alta dimensionalidad y escasez muestral. El número de observaciones es menor que el de características, y las dimensiones del problema son significativamente más altas que en los casos anteriores. Además, el dataset está desbalanceado, con 27 observaciones de la clase ALL y 11 de la clase AML en la partición de entrenamiento, lo que plantea un desafío adicional para los algoritmos de aprendizaje.

El dataset *All Leukemia* es un estudio de pacientes pediátricos con leucemia linfoblástica aguda (LLA). Incluye 327 muestras con información de 12600 genes (327x12600). Está compuesto por 14 clases desequilibradas. Fue compilado por Yeoh et al., en [link](https://www.cell.com/cancer-cell/fulltext/S1535-6108(02)00032-6?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS1535610802000326%3Fshowall%3Dtrue). 

Este caso es, sin duda, uno de los más complejos de todos, y plantea un desafío computacional significativo. El número de observaciones es significativamente menor que el de características, y las dimensiones del problema son significativamente más altas que en los casos anteriores. Además, el dataset está desbalanceado, con multiples clases desequilibradas, planteando no solo el desafío de las diversas fronteras de decisión que se deben encontrar, sino también el problema de posibles ambigüedades entre clases. Como vimos en el capítulo anterior, el desafío de procesar información genética es significativo considerando la alta correlación entre genes, y la gran cantidad de información redundante.

Finalmente, el dataset *GCM* fue compilado en Ramaswamy [-@ramaswamyMulticlassCancerDiagnosis2001] y contiene los perfiles de expresión de muestras de tumores que representan 14 clases comunes de cáncer humano. El dataset está compuesto por 190 muestras y 16063 atributos (biomarcadores), distribuidos en clases desequilibradas. Los datos están divididos en un conjunto de entrenamiento y un conjunto de testeo.

En GCM, como en el caso de *All Leukemia*, nos encontramos en un escenario de alta dimensionalidad y escasez muestral. El número de observaciones es significativamente menor que el de características, y las dimensiones del problema son significativamente más altas que en todos los casos anteriores. Además, el dataset está desbalanceado, eventualmente contiene abundante información ruidosa y redundante.

Entendemos que esta variedad de datasets cubre un amplio espectro de problemas de aprendizaje, y que los resultados obtenidos en cada uno de ellos nos permitirán evaluar el desempeño de nuestros algoritmos en contextos distintos.

## El desempeño de algoritmos clásicos

Pasando a la evaluación de los modelos clásicos, hemos seleccionado una serie de modelos ampliamente usados en el campo del aprendizaje automático para tomar su desempeño como indicador. Entre ellos, encontramos modelos lineales, basados en árboles, de Naive Bayes, de vecinos más cercanos, de redes neuronales y de Máquinas de Soporte Vectorial. A fin de estandarizar la implementación de estos algoritmos, hemos empleado la librería `scikit-learn` que provee abstracciones convenientes para nuestro entorno de experimentación.

Los modelos lineales se basan en la premisa de que la variable objetivo puede expresarse como una función lineal de los predictores o características. Normalmente asumen que, para cada observación, la suma ponderada de las características (potencialmente con un término independiente o “bias”) determina la respuesta. Entre los modelos lineales que incluimos en nuestro estudio se encuentran: el Análisis Discriminante Lineal (LDA), el Análisis Discriminante Cuadrático (QDA), la Regresión de Cresta (Ridge), y el Descenso de Gradiente Estocástico (SGD) [@hastieElementStatisticalLearning2009]. El Análisis Discriminante Lineal (LDA) asume que cada clase proviene de una distribución normal multivariada con igual matriz de covarianzas y distinta media, y busca el hiperplano que maximiza la separabilidad entre clases proyectando los datos a un subespacio. El Análisis Discriminante Cuadrático (QDA) relaja el supuesto de matriz de covarianzas compartida, permitiendo que cada clase tenga su propia matriz y mejorando así la capacidad de modelar fronteras de decisión más complejas, aunque con un mayor riesgo de sobreajuste cuando se cuenta con poca muestra. La Regresión de Cresta (Ridge) introduce una penalización L2 sobre los coeficientes para controlar la varianza de la solución y mitigar la multicolinealidad, lo cual es especialmente útil si existe una gran correlación entre características. El Descenso de Gradiente Estocástico (SGD), por su parte, consiste en un procedimiento incremental de optimización que actualiza los parámetros de un modelo lineal luego de cada observación (o mini-batch), resultando muy eficiente en problemas de alta dimensión o grandes volúmenes de datos.

En el caso de los modelos basados en árboles, todos comparten la idea de ir dividiendo recursivamente el espacio de características en regiones homogéneas. Este proceso se materializa en un árbol de decisión que, en cada nodo, escoge un umbral o criterio de partición para una característica. Los modelos incluidos en nuestro estudio son: Arbol de decisión clásico (DTC), AdaBoost, Bagging, Extra Trees Ensemble, Gradient Boosting, Random Forest, ETC, y Arboles Extremadamente Aleatorizados (ETC) [@hastieElementStatisticalLearning2009]. El Árbol de Decisión Clásico (Decision Tree Classifier, DTC) utiliza criterios como la ganancia de información o la reducción de la impureza para decidir la partición óptima en cada nivel, siendo fácilmente interpretable aunque con tendencia al sobreajuste si no se regula su profundidad. Algunas variantes se basan en la combinación de múltiples árboles. Bagging, por ejemplo, entrena árboles independientes a partir de muestras “bootstrap” y agrega las predicciones para reducir la varianza del modelo. Random Forest amplía esta idea, incorporando además la selección aleatoria de características en cada división, con lo cual reduce la correlación entre árboles y mejora la capacidad generalizadora. Extra Trees Ensemble adopta una estrategia aún más aleatoria, ya que define umbrales de corte aleatorios, lo que tiende a una mayor diversidad entre árboles y puede favorecer la reducción de la varianza. AdaBoost, en contraposición, entrena secuencialmente modelos débiles (a menudo árboles de baja profundidad) poniendo más peso en las observaciones mal clasificadas en iteraciones previas, de modo que cada nuevo modelo aprenda de los errores acumulados. Gradient Boosting también combina modelos débiles, pero en su caso cada etapa del entrenamiento se orienta a predecir el error residual del ensamble previo, optimizando una función de costo de forma aditiva y generalmente logrando modelos muy potentes. Cuando se habla de ETC (Extremely Randomized Trees Classifier), se hace referencia a un enfoque similar a Random Forest, pero que enfatiza la aleatorización tanto en la selección de subconjuntos de características como en los umbrales de partición, mejorando la diversidad de los árboles y mitigando así la varianza global.

Los modelos de Naive Bayes se basan en el teorema de Bayes para predecir la probabilidad de pertenencia a cada clase, asumiendo independencia condicional de las características [@hastieElementStatisticalLearning2009]. Aun cuando esta suposición rara vez se cumple por completo en problemas reales, la simplicidad computacional y la eficacia empírica suelen convertirlos en una elección sólida, especialmente en problemas de alta dimensión. En su versión Bernoulli (BNB), se asume que las variables predictoras son binarias, lo que se ajusta bien a datos dispersos donde cada característica indica la presencia o ausencia de cierta propiedad. En la versión Gaussiana (GNB), se asume que cada característica sigue una distribución normal, estimando media y varianza por clase para luego combinar esas estimaciones en la regla de decisión bayesiana.

En cuanto a los métodos basados en vecinos más cercanos, el clasificador K-Vecinos Más Cercanos (KNN) ejemplifica la estrategia de aprendizaje por vecindad, ya que no construye un modelo explícito durante la etapa de entrenamiento. En su lugar, para clasificar una nueva observación, identifica los K vecinos más cercanos en el espacio de características y asigna la clase mayoritaria de ese entorno local [@hastieElementStatisticalLearning2009]. Este enfoque es intuitivo y puede capturar relaciones complejas en los datos, aunque su desempeño se degrada en alta dimensión y requiere un costo computacional alto en predicción, pues debe calcular distancias a todos los puntos de entrenamiento.

Entre los modelos de redes neuronales, el Perceptrón Multicapa (MLP) es una arquitectura de red con múltiples capas densamente conectadas y funciones de activación no lineales [@hastieElementStatisticalLearning2009]. Su capacidad de aproximar funciones complejas lo convierte en un modelo flexible, pero también más exigente en términos de datos y calibración de hiperparámetros. Aunque en su versión más simple puede considerarse un “clásico”, el MLP con técnicas de regularización y optimización robustas forma parte fundamental de las estrategias de aprendizaje profundo.

Por último, las Máquinas de Soporte Vectorial (SVM) parten del principio de encontrar un hiperplano (en el caso lineal) u “frontera” (en el caso con núcleos no lineales) que maximice el margen de separación entre clases [@hastieElementStatisticalLearning2009]. En contextos de alta dimensión y con un número moderado de muestras, las SVM suelen mostrar un desempeño notable por su capacidad para controlar el sobreajuste mediante el parámetro de regularización y el uso de núcleos apropiados. Su versión lineal (LSVC) se centra en resolver una optimización con un límite que separa las clases en un espacio original de altas dimensiones sin necesidad de mapeos adicionales, resultando eficiente en muchos casos de datos dispersos. La variante NuSVC introduce un parámetro $nu$ que controla tanto el número de vectores de soporte como la proporción máxima de errores permitidos, proporcionando una forma alternativa de regularización y definición de la frontera de decisión. Estas particularidades hacen que las SVM sean especialmente populares en problemas donde la dimensionalidad de las características es grande con respecto al número de muestras disponibles.

### Configuración de los Modelos

Para evaluar los modelos clásicos hemos decidido su configuración a partir de la búsqueda de la mejor combinación de parámetros. A tal fin, hemos seleccionado aquellos parámetros más importantes en cada modelo y establecimos una búsqueda en grilla de sus respectivos valores. Hemos seleccionado para parámetros numéricos un mínimo de 3 valores y máximo de 20, y para no numéricos hemos decidido la configuración estándar según cada modelo. 

Las particiones originales de los datasets fueron concatenadas en un solo conjunto de datos, y luego se dividió en conjuntos de entrenamiento y testeo en proporción 80/20. 

## Resultados Obtenidos

En la siguiente tabla resumimos los resultados en el dataset de testeo para cada modelo y dataset.  


| Modelo           | Leukemia Test    | Madelon Test   | Gisette Test      | GCM Test       |
|------------------|------------------|----------------|-------------------|----------------|
| LDA              | 0.85            | 0.60           | 0.96              | -              |
| QDA              | 0.50            | 0.66           | 0.70              | -              |
| Ridge            | 0.99            | 0.60           | 0.97              | -              |
| SGD              | 0.98            | 0.64           | 0.99              | 0.71           |
|------------------|------------------|----------------|-------------------|----------------|
| AdaBoost         | 0.91            | 0.84           | 0.99              | -              |
| Bagging          | **1.00**        | **0.91**       | -                 | -              |
| DTC              | 0.72            | 0.64           | 0.92              | 0.53           |
| ETC              | 0.54            | 0.57           | 0.94              | 0.48           |
| Ext.Trees.Ens.   | **1.00**        | 0.71           | 0.99              | 0.57           |
| Gradient Boost.  | 0.99            | 0.82           | **1.00**          | 0.58           |
| Random Forest    | **1.00**        | 0.78           | 0.99              | 0.62           |
|------------------|------------------|----------------|-------------------|----------------|
| LSVC             | 0.99            | 0.62           | 0.99              | 0.62           |
| NuSVC            | **1.00**        | 0.61           | 0.99              | 0.58           |
| SVC              | **1.00**        | 0.61           | 0.99              | 0.58           |
|------------------|------------------|----------------|-------------------|----------------|
| BNB              | 0.89            | 0.63           | 0.94              | -              |
| GNB              | 0.91            | 0.65           | 0.85              | -              |
|------------------|------------------|----------------|-------------------|----------------|
| KNN              | 0.86            | 0.65           | 0.99              | -              |
|------------------|------------------|----------------|-------------------|----------------|
| MLP              | 0.96            | 0.58           | 0.99              | **0.68**       |


El gráfico completo de resultados en las particiones de entrenamiento y testeo puede verse en la siguiente figura:  


![algoritmosclasicos](model_performance_heatmap_grouped.png)


[DESARROLLAR]Podría resaltarse en estos resultados que hay problemas en los datasets desbalanceados (que es un poco la hipótesis de trabajo de la tesis: los VAEs pueden ayudar a balancear de forma efectiva los conjuntos de datos para que las tareas posteriores se realizan de forma correcta)













## El uso de Autocodificadores Variacionales como técnica de aumentación


La aplicación de AVs como técnica de aumentación de datos en el contexto de distintos problemas de aprendizaje automático es extendida fuera del campo de la selección de características. Se aplica al tratamiento de imágenes [@fajardoOversamplingImbalancedData2021; @aiGenerativeOversamplingImbalanced2023; @khmaissiaConfidenceGuidedDataAugmentation2023; @kwarciakDeepGenerativeNetworks2023], texto [@zhangImproveDiverseText2019] , habla [@blaauwModelingTransformingSpeech2016; @latifVariationalAutoencodersLearning2020] y música [@robertsHierarchicalLatentVector2019], y distintos formatos de datos: tabulares [@leelarathnaEnhancingRepresentationLearning2023], longitudinales [@ramchandranLearningConditionalVariational2022] y grafos [@liuConstrainedGraphVariational2018]. En lo que sigue repasaremos las experiencias más afines a nuestro enfoque sobre el impacto de la aumentación en el aprendizaje y la selección de características.


En @fajardoOversamplingImbalancedData2021 se investiga si los AVs y las redes generativas antagónicas (GAN) pueden aumentar datos desbalanceados vía sobremuestreo de las clases minoritarias, y mejorar así el rendimiento de un clasificador. Para ello se crean versiones desbalanceadas de reconocidos datos multiclases tales como MNIST [@lecunGradientBasedLearningApplied1998] y Fashion MNIST [@xiaoFashionMNISTNovelImage2017], a los cuales, posteriormente, se los re-balancea agregándoles muestras sintéticas generadas por un AV condicionado por clase (AV Condicional). Para la tarea de clasificación se emplea un Perceptrón Multicapa (MLP), y se evalúa su desempeño promediando métricas de precisión, exhaustividad [controlar-concepto] y F1 score sobre distintos experimentos. La evaluación incluye la comparación de resultados del clasificador con datos aumentados por sobre-muestreo aleatorio, mediante SMOTE [@blagusSMOTEHighdimensionalClassimbalanced2013], GAN y AVs. El resultado muestra a los AVs -en su versión condicional- como el mejor modelo generativo para resolver el problema de datos desbalanceados mediante sobre-muestreo de las clases minoritarias.


@aiGenerativeOversamplingImbalanced2023 vuelve sobre los problemas planteados en @fajardoOversamplingImbalancedData2021, proponiendo una nueva metodología que superaría sus resultados. La propuesta en esta oportunidad plantea la aumentación de datos de la clase minoritaria condicionada a las características de la distribución que tienen los datos de la clase mayoritaria. El método se llama AV-Guiado-por-la-Mayoría (*Majority-Guided VAE* o MGVAE) y procura incorporar en la generación no solo información intra-clase sino también inter-clase, con el fin de propagar la diversidad y riqueza de la mayoría en la minoría, y mitigar así riesgos de sobre-ajuste en los modelos. Este modelo se pre-entrena utilizando muestras de la clase mayoritaria, y luego se ajusta con datos de la clase minoritaria para retener el aprendizaje de la etapa previa [@kirkpatrickOvercomingCatastrophicForgetting2017]. Para evaluar la eficacia de MGVAE, se realizaron experimentos en varios conjuntos de datos de imágenes y tabulares, utilizando diversas métricas de evaluación como Precisión Balanceada (B-ACC), Precisión Específica Promedio por Clase (ACSA) y Media Geométrica (GM). Los resultados muestran que MGVAE supera a otros métodos de sobre-muestreo en tareas de clasificación.


Un problema diferente es tratado en @khmaissiaConfidenceGuidedDataAugmentation2023 donde se emplean AVs para aumentar datos en una tarea de clasificación con enfoque semi-supervisado. Aquí el desafío no pasa por el desbalance entre clases, sino en la búsqueda de mejorar el clasificador en regiones del espacio de características con bajo desempeño (ratios de error altos). Para eso, se mapea el espacio de características entrenando un modelo de WideResNet [@zagoruykoWideResidualNetworks2017] y luego se seleccionan las muestras mal clasificadas o con bajo nivel de confianza en la clasificación. Estas muestras se utilizan para entrenar un AV y generar datos sintéticos. Finalmente, las imágenes sintéticas se usan junto con las imágenes originales etiquetadas para entrenar un nuevo modelo de manera semi-supervisada. Se evalúan los resultados sobre STL10 y CIFAR-100 obteniendo mejoras en la clasificación de imágenes en comparación con los enfoques supervisados.


Finalmente, antecedente interesante es el presentado por @martinsVariationalAutoencodersEvolutionary2022b, pues pese a no estar directamente vinculado a la aumentación de datos, incluye la generación sintética de muestras mediante AV y la selección de características por AG. En efecto, el artículo propone la generación de individuos y optimización de características orientados al diseño de proteínas (específicamente variantes de Luciferasa bacteriana *luxA*). Partiendo de muestras de ADN de proteínas obtenidas de un subconjunto de datos de la base InterPro (identificados bajo el código "IPR011251") se generan conjuntos de individuos combinando datos originales, datos muestreados de la capa latente -*encoder*- del AV (configurado como MSA-AV para procesar sequencias alineadas de ADN) y datos optimizados por aplicación del AG. En el caso del algoritmo genético se emplean dos enfoques de optimización: de objetivo único y multiobjetivos, con funciones asociadas a la búsqueda de propiedades deseables en las muestras de ADN (solubilidad, síntesis, estabilidad y agregación de proteínas). El resultado de los experimentos realizados muestra que el diseño de proteínas guiado por la optimización mediante AG resultó en mejores soluciones que las obtenidas mediante muestreo directo, y que por su parte la optimización multiobjetivos permitió la selección de proteínas con el mejor conjunto de propiedades.


Los casos mencionados en el apartado nos ofrecen un conjunto de experiencias significativas a considerar al momento de resolver el problema planteado en este trabajo. Otras experiencias, como por ejemplo la configuración evolutiva de un AV [@wuEVAEEvolutionaryVariational2023], el ensamble de AVs [@leelarathnaEnhancingRepresentationLearning2023], por mencionar algunas novedosas, escapan al recorte que hemos fijado.