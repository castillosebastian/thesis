### Desafios, cosas que no funcionaron y aprendizajes



Efectivamente aumentar los datos sintéticos en GCM dió buen resultado. Llevé el dataset de entrenamiento con datos sintéticos a 3000 observaciones. El dataset está balanceado, cada clase con 214 observaciones. Aquí obtuve los mejores resultados igulando la performance del MLP entrenado con datos reales.  En este caso, también probé con 6000 datos y en este experimento los resultados finales volvieron a bajar (vean tercera fila de la próxima tabla, expN48). Entiendo que puede haber un umbral de eficacia en incrementar la cantidad de observaciones, superado el cual el CVAE empieza a generar ruido, es decir muchas observaciones empiezan a solapar sus fronteras de decisión, haciendo crecer el error. 






Datos Originales 
Datos Sintéticos
CVAE
1400 
Training samples
expN45


 Original Data Model Performance:
              precision    recall  f1-score   support

           0       0.14      0.25      0.18         4
           1       0.00      0.00      0.00         1
           2       1.00      1.00      1.00         3
           3       1.00      0.33      0.50         6
           4       0.89      1.00      0.94         8
           5       0.40      0.67      0.50         3
           6       0.80      0.80      0.80         5
           7       0.50      0.75      0.60         4
           8       0.33      0.25      0.29         4
           9       0.25      0.67      0.36         3
          10       1.00      0.25      0.40         4
          11       1.00      0.67      0.80         3
          12       1.00      0.25      0.40         4
          13       1.00      0.20      0.33         5

    accuracy                           0.54        57
   macro avg       0.67      0.51      0.51        57
weighted avg       0.74      0.54      0.56        57

Accuracy: 0.5439




  Synthetic Data Model Performance:
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         4
           1       0.00      0.00      0.00         1
           2       1.00      1.00      1.00         3
           3       0.30      0.50      0.38         6
           4       1.00      1.00      1.00         8
           5       1.00      0.33      0.50         3
           6       1.00      0.20      0.33         5
           7       0.00      0.00      0.00         4
           8       0.00      0.00      0.00         4
           9       0.16      1.00      0.27         3
          10       0.00      0.00      0.00         4
          11       0.50      0.67      0.57         3
          12       1.00      0.25      0.40         4
          13       0.33      0.40      0.36         5

    accuracy                           0.42        57
   macro avg       0.45      0.38      0.34        57
weighted avg       0.50      0.42      0.39        57

Accuracy: 0.4211



CVAE
3000 
Training samples
expN47


             precision    recall  f1-score   support

           0       1.00      0.25      0.40         4
           1       0.00      0.00      0.00         1
           2       1.00      0.67      0.80         3
           3       1.00      0.17      0.29         6
           4       1.00      1.00      1.00         8
           5       0.43      1.00      0.60         3
           6       1.00      0.80      0.89         5
           7       0.10      0.25      0.14         4
           8       0.67      0.50      0.57         4
           9       0.50      0.33      0.40         3
          10       0.00      0.00      0.00         4
          11       1.00      0.67      0.80         3
          12       1.00      0.75      0.86         4
          13       0.21      0.60      0.32         5

    accuracy                           0.54        57
   macro avg       0.64      0.50      0.50        57
weighted avg       0.70      0.54      0.55        57

Accuracy: 0.5439
CVAE
6000 
Training samples
expN48


              precision    recall  f1-score   support

           0       0.50      0.25      0.33         4
           1       0.00      0.00      0.00         1
           2       0.00      0.00      0.00         3
           3       1.00      0.17      0.29         6
           4       1.00      0.88      0.93         8
           5       0.09      1.00      0.16         3
           6       0.00      0.00      0.00         5
           7       0.00      0.00      0.00         4
           8       0.00      0.00      0.00         4
           9       0.00      0.00      0.00         3
          10       0.00      0.00      0.00         4
          11       0.00      0.00      0.00         3
          12       0.00      0.00      0.00         4
          13       0.00      0.00      0.00         5

    accuracy                           0.21        57
   macro avg       0.18      0.16      0.12        57
weighted avg       0.29      0.21      0.19        57

Accuracy: 0.2105




L1_loss

	Lo probé un experimento (expN46) con GCM y no obtuve diferencias relevantes respecto de MSE.

dropout_rate

Probé un hiperaparámetro con este componente, en el rango de 0.05 a 0.5. Hice dos experimentos con GCM generando dataset balanceado de 214 observaciones por clase. Las arquitectures que utilice fue un CVAE de capas chicas (entre 100 y 500 neuronas, ver expN59)  y otro de capas grandes (entre 1000 y 7000 neuronas, ver expN50). Obtuve un resultado ‘interesante’ en el CVAE más chico, con Accuracy de ’0.38’ en el clasificador MLP, pero que se encuentran por debajo de nuestro mejor experimento. Creo que no utilizaría este parámetro. 

En el caso de las pruebas realizadas sobre L1_loss y drop out, entiendo que es posible que la falta de variación en los resultados que estoy obteniendo se deba a que los estoy probando en configuraciones que de CVAE ya validadas por varios experimentos, y cuyos resultados son buenos. Y que por eso, estos cambios no generan impacto positivo, sino al contrario degradan los resultados. 

