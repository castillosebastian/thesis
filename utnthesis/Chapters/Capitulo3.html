<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.0.37">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>capitulo3</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>


<script src="Capitulo3_files/libs/clipboard/clipboard.min.js"></script>
<script src="Capitulo3_files/libs/quarto-html/quarto.js"></script>
<script src="Capitulo3_files/libs/quarto-html/popper.min.js"></script>
<script src="Capitulo3_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Capitulo3_files/libs/quarto-html/anchor.min.js"></script>
<link href="Capitulo3_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Capitulo3_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Capitulo3_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Capitulo3_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Capitulo3_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">



<section id="sec-Capitulo3" class="level1">
<h1>Algoritmos Genéticos y Autoencoder Variacionales</h1>
<p>En este capítulos presentaremos la arquitectura de nuestro modelo de Algoritmo Genético alimentado con datos sintéticos generados mediante Autoencoder Variacionales (VAE). Expondremos brevemente los pasos seguidos en su construcción y las características de la solución. En el capítulo siguiente nos enfocaremos en los resultados obtenidos en los distintos experimentos realizados.</p>
<section id="algoritmos-genéticos" class="level2">
<h2 class="anchored" data-anchor-id="algoritmos-genéticos">Algoritmos Genéticos</h2>
<p>Los algoritmos genéticos (en adelante AG) son métodos de optimización inspirados en la evolución natural, diseñados para encontrar soluciones en espacios de búsqueda complejos <span class="citation" data-cites="vignoloEvolutionaryLocalImprovement2017">[@vignoloEvolutionaryLocalImprovement2017]</span>. A diferencia de los métodos de optimización exhaustivos (ej. métodos enumerativos<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>), los AG son particularmente efectivos en espacios de búsqueda discretos, ruidosos, cuando la función objetivo no puede describirse mediante una ecuación o la misma no es diferenciable <span class="citation" data-cites="goldbergdavide.GeneticAlgorithmsSearch1989">[@goldbergdavide.GeneticAlgorithmsSearch1989]</span>. Utilizando principios basados en la evolución, estos algoritmos generan iterativamente soluciones a partir de una población de candidatos, de manera similar a cómo la evolución natural optimiza características biológicas a lo largo de generaciones en función de las condiciones del entorno. En contextos de aplicación sus resultados regularmente conducen a soluciones cercanas al óptimo, capaces de mantener un buen compromiso en la satisfacción de múltiples requerimientos <span class="citation" data-cites="jiaoSurveyEvolutionaryMultiobjective2023">[@jiaoSurveyEvolutionaryMultiobjective2023]</span>. Por eso, los AG son eficaces para atacar tanto problemas de objetivo único, como problemas multiobjetivo.</p>
<p>La robustez de los AG está determinada, como bien sostiene Goldberg <span class="citation" data-cites="goldbergdavide.GeneticAlgorithmsSearch1989">[-@goldbergdavide.GeneticAlgorithmsSearch1989]</span>, por una serie de características distintivas, que fortalecen su configuración de búsqueda, a saber: a) operan sobre un espacio <em>codificado</em> del problema y no sobre el espacio en su representación original; b) realizan la exploración evaluando una <em>población de soluciones</em> y no soluciones individuales; c) tienen como guía una <em>función objetivo</em> (también llamada <em>función de aptitud</em>) que no requiere derivación u otras funciones de cálculo; y d) suponen <em>métodos probabilísticos de transición</em> (operadores estocásticos) y no reglas determinísticas. Estas características permiten a los AG superar restricciones que tienen otros métodos de optimización, condicionados -por ejemplo- a espacios de búsqueda continuos, diferenciables o unimodales. Por ello, su aplicación se ha difundido notablemente, trascendiendo los problemas clásicos de optimización, aplicándose en distintas tareas <span class="citation" data-cites="vieQualitiesChallengesFuture2021">[@vieQualitiesChallengesFuture2021]</span> y a lo largo de diversas industrias <span class="citation" data-cites="jiaoSurveyEvolutionaryMultiobjective2023">[@jiaoSurveyEvolutionaryMultiobjective2023]</span>.</p>
<p>La importancia de los AGs como herramientas de optimización, adquiere especial preeminencia en el problema de <em>selección de características</em> <span class="citation" data-cites="jiaoSurveyEvolutionaryMultiobjective2023">[@jiaoSurveyEvolutionaryMultiobjective2023]</span>, por lo que en este trabajo dirigiremos la atención en esa dirección<em>.</em> La <em>selección de características</em> (en adelante SC) representa un desafío de optimización combinatoria complejo, que despierta interés en el universo del aprendizaje automático debido a su impacto en el rendimiento de los modelos y la posibilidad de reducir la complejidad computacional de ciertos problemas. Tal desafío está determinado por varios factores. En primer lugar encontramos que, en espacios de alta dimensionalidad, la cardinalidad del conjunto de soluciones candidatas crece de manera exponencial, y los problemas se vuelven computacionalmente intratables debido a la extensión del espacio de búsqueda.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> En segundo lugar, junto con la alta dimensionalidad, aparece el problema de las interacciones entre características. Aquí, el prolífico espectro de dependencias que pueden establecer los atributos plantea normalmente vínculos difíciles de modelar atento a que se multiplican de la mano de la dimensionalidad.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> Por último, aunque no por ello menos importante, aparece el carácter multiobjetivo de los problema de SC, donde no solo interesa maximizar la eficacia de los modelos sino también que sean eficientes. Eficiencia que implica -generalmente- la necesidad de minimizar la cantidad de atributos seleccionados para resolver un problema <span class="citation" data-cites="jiaoSurveyEvolutionaryMultiobjective2023">[@jiaoSurveyEvolutionaryMultiobjective2023]</span>.</p>
<p>Estos desafíos son abordados por los AGs de manera conveniente y creativa.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> En el marco de este algoritmo cada individuo (muestra) representa una solución candidata, con un perfil genético particular determinado por un subconjunto de características. La búsqueda de las mejores soluciones comienza con la selección de una población inicial de individuos y un subconjunto de características generados aleatoriamente. Este subconjunto se evalúa utilizando una función de aptitud, y los individuos con mejor rendimiento (puntaje) son seleccionados para la reproducción. Este proceso continúa durante un cierto número de generaciones hasta que se cumple una condición de terminación <span class="citation" data-cites="goldbergdavide.GeneticAlgorithmsSearch1989">[@goldbergdavide.GeneticAlgorithmsSearch1989]</span>.</p>
<p>Este mecanismo simple constituye un eficaz método de selección en contextos de alta dimensionalidad y bajo número de muestras. Esa eficacia se debe a la capacidad de explorar el problema dividiéndolo en subespacios de características y, al mismo tiempo, explotar las regiones de mayor valor en cada subespacio <span class="citation" data-cites="goldbergdavide.GeneticAlgorithmsSearch1989">[@goldbergdavide.GeneticAlgorithmsSearch1989]</span>.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
<p>Dicho lo anterior, no es menos cierto que la capacidad de selección de los AGs depende de la evaluación de aptitud que orienta la búsqueda de las mejores soluciones, y tal evaluación descansa -finalmente- en la disponibilidad de datos. En efecto, la existencia y número de individuos condiciona la función objetivo y por esa vía también al proceso de selección de características de los AGs. La disponibilidad de datos resulta así un factor clave para la selección. Este requerimiento, vinculado particularmente a la función objetivo, se presenta no solo cuando se utiliza como evaluador a modelos complejo de aprendizaje automático (que demandan una cantidad creciente de muestras de entrenamiento)<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>, sino también cuando se trabaja sobre datos cuyas clases se encuentran desbalanceadas <span class="citation" data-cites="fajardoOversamplingImbalancedData2021 blagusSMOTEHighdimensionalClassimbalanced2013">[@fajardoOversamplingImbalancedData2021; @blagusSMOTEHighdimensionalClassimbalanced2013]</span>. En ambos escenarios, la falta de información suficiente degrada la capacidad informativa de la función objetivo <span class="citation" data-cites="hastieElementStatisticalLearning2009">[@hastieElementStatisticalLearning2009]</span>, afectando gravemente el proceso de selección de características.</p>
<p>En esa línea, el problema de la disponibilidad de datos en los proyecto de selección de características -sea dentro o fuera del campo de los AGs-, ha encontrado en las estrategias de aumentación una posible solución <span class="citation" data-cites="gmComprehensiveSurveyAnalysis2020">[@gmComprehensiveSurveyAnalysis2020]</span>. Entre esas estrategias, los Autoencoders Variacionales (en adelante AV) han adquirido popularidad, superando a métodos tradicionales (ej. sobremuestreo <span class="citation" data-cites="blagusSMOTEHighdimensionalClassimbalanced2013">[@blagusSMOTEHighdimensionalClassimbalanced2013]</span>) y -en ciertos casos- también a otro modelos generativos basados de redes neuronales profundas <span class="citation" data-cites="fajardoOversamplingImbalancedData2021">[@fajardoOversamplingImbalancedData2021]</span>.</p>
<p>Los AVs constituyen modelos generativos<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> capaces de aprender una representación latente de datos observados y producir nuevas muestras con las mismas características fundamentales<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> que las observaciones <span class="citation" data-cites="kingmaIntroductionVariationalAutoencoders2019">[@kingmaIntroductionVariationalAutoencoders2019]</span>. Esa capacidad resulta particularmente efectiva por el hecho de que prescinde de fuertes supuestos estadísticos a los que adscriben otros modelos generativos y también por su escalabilidad.<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> Hoy los AVs son ampliamente utilizados en biología molecular, química, procesamiento de lenguaje natural, astronomía, entre otros <span class="citation" data-cites="ramchandranLearningConditionalVariational2022">[@ramchandranLearningConditionalVariational2022]</span>.</p>
<p>Por todo lo visto hasta aquí advertimos que la posibilidad de expandir el conjunto de datos mediante el uso de AVs abre nuevas alternativas para afrontar el problema de la selección de características aplicando AGs. Estas alternativas no solo parecen prometedoras como estrategias orientadas a la multiplicación de muestras de entrenamiento para mejorar el desempeño de la función objetivo, sino también como partes funcionales de sus operadores de variación.<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a> De este modo, la integración de ambas tecnologías ofrece un enfoque provechoso para abordar el problema de selección de características en distintos escenarios que enfrentan los AGs.</p>
<p>A la fecha de publicación del presente trabajo no hemos encontrado experiencias de aplicación de AVs en el ámbito de selección de características mediante AGs. En la medida que esto sea así creemos que nuestro aporte a la comunidad de investigadores y practicantes de la disciplina estará en proveer información y experimentación sobre la combinación de ambos algoritmos. Dicho aporte tendría un alcance nacional a todos aquellos equipos dedicados al problema de selección de características aplicando computación evolutiva.</p>
</section>
<section id="ag-version-2" class="level2">
<h2 class="anchored" data-anchor-id="ag-version-2">AG version 2</h2>
<p>Para el presente trabajo usaremos algoritmos genéticos (AGs) como método de búsqueda<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a> debido a la posibilidad que brindan de emplear codificación binaria y permitir así una representación intuitiva del espacio de características <span class="citation" data-cites="vignoloEvolutionaryLocalImprovement2017">[@vignoloEvolutionaryLocalImprovement2017]</span>. Para aumentación de datos utilizaremos <em>autoencoders variacionales</em> (AVs) como instancia generativa <span class="citation" data-cites="kingmaIntroductionVariationalAutoencoders2019">[@kingmaIntroductionVariationalAutoencoders2019]</span>.</p>
<p>Los AGs constituyen una de las herramientas más estudiadas e implementadas dentro de los métodos evolutivos <span class="citation" data-cites="goldbergdavide.GeneticAlgorithmsSearch1989">[@goldbergdavide.GeneticAlgorithmsSearch1989, @kramerGeneticAlgorithmEssentials2017]</span>, dada su capacidad para encontrar soluciones en espacios de búsqueda complejos <span class="citation" data-cites="vignoloEvolutionaryLocalImprovement2017">[@vignoloEvolutionaryLocalImprovement2017]</span>. El procedimiento de búsqueda de los AGs opera evolucionando una población de individuos que consisten en cromosomas que codifican el espacio de soluciones. Dicha evolución -al igual que la evolución natural- sucede a través de operadores (funciones) de selección, variación (mutación y cruce) y reemplazo que transforman el material genético disponible: los individuos más aptos sobreviven y se reproducen, mientras que los menos aptos desaparecen<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a>. Esta aptitud -que imita la presión selectiva de un entorno natural- se evalúa mediante la aplicación de una función objetivo (específica del problema) a cada individuo a partir de la información decodificada de sus cromosomas. Dicha función objetivo puede asumir múltiples formas <span class="citation" data-cites="jiaoSurveyEvolutionaryMultiobjective2023">[@jiaoSurveyEvolutionaryMultiobjective2023]</span>, pero en nuestro trabajo nos centraremos en el uso de modelos de aprendizaje automático, particularmente Maquinas de Soporte Vectorial <span class="citation" data-cites="boserTrainingAlgorithmOptimal1992">[@boserTrainingAlgorithmOptimal1992]</span> y Bosques Aleatorios <span class="citation" data-cites="breimanRandomForests2001">[@breimanRandomForests2001]</span>. Este método heurístico de búsqueda tendrá en nuestro trabajo dos configuraciones: una <em>clásica</em> sin aumentación de datos y una <em>novedosa</em> con aumentación de datos aplicando <em>autoencoders variacionales</em> (AV)<em>.</em></p>
</section>
<section id="autoencoders-variacionales" class="level2">
<h2 class="anchored" data-anchor-id="autoencoders-variacionales">Autoencoders Variacionales</h2>
<p>Para aumentar el conjunto de datos que empleará la función de aptitud de los AGs emplearemos <em>autoencoders variacionales</em> (AVs). Los AVs son modelos generativos implementados por redes neuronales profundas con arquitectura <em>encoder-decoder</em> capaces de aprender una representación latente de datos disponibles y generar nuevas muestras de similares características a los datos originales <span class="citation" data-cites="kingmaIntroductionVariationalAutoencoders2019">[@kingmaIntroductionVariationalAutoencoders2019]</span>. Estos modelos se basan en el supuesto de que cualquier dato disponible, por ejemplo <span class="math inline">\(x\)</span>, se genera mediante un proceso aleatorio que involucra una variable latente <span class="math inline">\(z\)</span>. Bajo ese supuesto, el modelo procede tomando como muestra una observación de <span class="math inline">\(z\)</span> de la distribución de probabilidad <em>a priori</em> <span class="math inline">\(p_\theta(z)\)</span>, que luego se utiliza para tomar una observación de <span class="math inline">\(x\)</span> de la distribución condicional <span class="math inline">\(p_\theta(x|z)\)</span>. El objetivo del modelo es obtener <em>estimaciones de máxima verosimilitud</em> del parámetro <span class="math inline">\(\theta\)</span> en situaciones donde tanto la verosimilitud marginal <span class="math inline">\(p_\theta(x) = \int p_\theta(z)p_\theta(x|z) dz\)</span> como la probabilidad <em>a posteriori</em> <span class="math inline">\(p_\theta(x|z)\)</span> son intratables<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a>. Para eso, utiliza la distribución <span class="math inline">\(q_\phi(z|x)\)</span> como una aproximación al intratable <span class="math inline">\(p_\theta(x|z)\)</span>, maximizando el <em>límite inferior variacional</em><a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a> para <span class="math inline">\(p_\theta(x)\)</span>. El objetivo de aprendizaje del AV se da entonces por:</p>
<blockquote class="blockquote">
<p><span class="math inline">\(\mathcal{L}_{AV}(x; \theta, \phi) = \max(\phi,\theta) \left( E_{z \sim q_\phi(z|x)} [\log p_\theta (x|z)] - \text{KL}(q_\phi(z|x) \| p_\theta (z)) \right),\)</span></p>
</blockquote>
<p>donde <span class="math inline">\(\text{KL}(q(\cdot) \| p(\cdot))\)</span> denota la divergencia de Kullback–Liebler entre dos distribuciones <span class="math inline">\(q(\cdot)\)</span> y <span class="math inline">\(p(\cdot)\)</span>. Una vez que el AV está entrenado, una observación sintética <span class="math inline">\(x'\)</span> se genera tomando primero <span class="math inline">\(z \sim p_\theta(z)\)</span> y posteriormente tomando <span class="math inline">\(x'\)</span> de la probabilística condicional entrenada por el modelo <span class="math inline">\(p_\theta(x|z)\)</span>.</p>
</section>
</section>


<div id="quarto-appendix" class="default"><section class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1" role="doc-endnote"><p><span class="citation" data-cites="goldbergdavide.GeneticAlgorithmsSearch1989">@goldbergdavide.GeneticAlgorithmsSearch1989</span>, p.4.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>Cabe destacar que para un conjunto de <code>n</code> características es posible determinar un total de <code>n2</code> posibles soluciones, espacio que constituye un dominio de búsqueda difícil de cubrir aún con <code>n</code> conservadores. Por ejemplo para un conjunto de 20 características (atributos) el número total de subconjuntos a evaluar supera el millón de posibles candidatos, específicamente: 1.048.576.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>Por ejemplo, dos características con alto valor discriminatorio para resolver un problema de clasificación pueden ser redundantes debido a su correlación y exigir criterios inteligentes de inclusión-exclusión. A la inversa, características que individualmente consideradas pueden carecer de valor discriminatorio, debido a su complementariedad pueden ser esenciales para resolver un problema y por lo tanto exigir criterios complejos de evaluación y búsqueda.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>Ciertamente, no son sus atributos aislados los que le dan esa posibilidad, sino la interacción de sus componentes.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p>Ambas funciones -exploración y explotación- permiten al algoritmo reconfigurar el espacio de búsqueda y poner a prueba sus complejas dependencias. Como vimos, el procedimiento es orientado por una función de aptitud que evalúa las distintas posibilidades combinatorias encontradas por el algoritmo y retroalimenta el proceso exploratorio. La dinámica completa tiene como resultado un procedimiento experimental de búsqueda y selección capaz de reconocer soluciones próximas al óptimo.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><ol class="example" type="1">
<li></li>
</ol>
<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></li>
<li id="fn7" role="doc-endnote"><p>Redes neuronales profundas con arquitectura <em>encoder-decoder</em> <span class="citation" data-cites="kingmaIntroductionVariationalAutoencoders2019">[@kingmaIntroductionVariationalAutoencoders2019]</span>. Estos modelos pueden presentar distintas configuraciones según el problema tratado y el objetivo particular de la implementación <span class="citation" data-cites="wuEVAEEvolutionaryVariational2023">[@wuEVAEEvolutionaryVariational2023]</span>.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p>Similar distribución conjunta de probabilidad.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p>El modelo emplea <em>retropropagación</em> como estrategia de optimización <span class="citation" data-cites="kingmaIntroductionVariationalAutoencoders2019">[@kingmaIntroductionVariationalAutoencoders2019]</span><a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10" role="doc-endnote"><p>Así, la integración de los AVs en el contexto de los AGs podría dirigirse no solo a la multiplicación general de datos, sino también a la multiplicación selectiva de ciertos subconjuntos de características valiosas<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11" role="doc-endnote"><p>Otros métodos robustos, como por ejemplo el <em>enjambre de partículas</em> (PSO) y <em>optimización de colonia de hormigas</em> (ACO), típicamente utilizan codificación basada en números reales por lo que constituyen opciones menos adecuadas al problema que enfrentaremos en este trabajo.<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12" role="doc-endnote"><p>Como su nombre lo indica el operador de selección determina la elegibilidad de un individuo para sobrevivir y reproducirse en función de su aptitud para resolver un problema. En el contexto de los AGs esta aptitud no es otra cosa que el puntaje que obtiene un individuo evaluado en una función objetivo. Por su parte los operadores de variación tienen como función combinar la información genética de individuos (cruce) y alterar aleatoriamente sus cromosomas (mutación), promoviendo transformaciones en el material genético global con sesgo hacia mejorar la aptitud poblacional para resolver un problema. La variación equivale a la búsqueda natural por mejorar las adaptaciones de los individuos a su entorno. Finalmente el operador de reemplazo mantiene la población constante, sustituyendo individuos poco aptos por aquellos de mayor aptitud. Estos operadores se combinan en ciclos iterativos que se repiten hasta satisfacer un criterio de terminación deseado (por ejemplo, un número predefinido de generaciones o un valor de aptitud) <span class="citation" data-cites="vignoloEvolutionaryLocalImprovement2017">[@vignoloEvolutionaryLocalImprovement2017]</span>.<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13" role="doc-endnote"><p>Son intratables porque <span class="math inline">\(z\)</span> es una variable latente, no observada, y el cómputo de probabilidad que la incluya -en este caso <span class="math inline">\(x\)</span> - debe <em>marginalizar</em> (integrar) todo sus posibles valores, situación computacionalmente costosa en el contexto del modelos analizado.<a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14" role="doc-endnote"><p>Limite obtenido a través de una función auxiliar conocida como función <em>ELBO.</em><a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>