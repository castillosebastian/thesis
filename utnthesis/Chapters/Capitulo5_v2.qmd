# Conclusiones y trabajos futuros {#sec-Capitulo5}

A partir de los resultados obtenidos en los experimentos, se torna evidente que la aumentación de datos mediante AV y su combinación con AG es una estrategia prometedora en la selección de características. Para maximizar el potencial de este enfoque, es posible avanzar en varias direcciones, tanto en términos de optimización de los modelos AV y AVC, como en la integración y encadenamiento de modelos más complejos. En este capítulo, repasamos las conclusiones de nuestro trabajo y presentamos los próximos pasos para continuar mejorando los modelos aquí estudiados.

## Conclusiones

En esta tesis, abordamos los desafíos que la alta dimensionalidad y escasez muestral, el desbalance de clases y el ruido, plantean a los modelos de aprendizaje automático y, en particular, en los métodos de selección de características basados en Algoritmos Genéticos (AG). Siguiendo los objetivos presentados en el Capítulo 1, propusimos como contribución principal de nuestro trabajo abordar dichos problemas considerando la generación sintética de datos mediante Autocodificadores Variacionales (AV) como estrategia para asistir el proceso de selección de características con AG, con el objetivo de mejorar la capacidad de búsqueda y mitigar los efectos negativos de la falta de datos, el ruido y el desbalance.  

Los experimentos descriptos en el Capítulo 3 pusieron en evidencia la eficacia de los AV/AVC para capturar la estructura subyacente de distintos conjuntos de datos, manteniendo la propiedades estadísticas necesarias para que los modelos predictivos entrenados con dichas muestras sintéticas alcanzaran rendimientos comparables —o incluso superiores— a los entrenados con datos reales. Este hallazgo fue especialmente valioso en conjuntos de datos de alta dimensionalidad y pocas observaciones, donde la generación de muestras sintéticas logró resultados positivos en términos de precisión y reducción del impacto negativo del ruido.

Posteriormente, tal como se detalla en el Capítulo 4, integramos este enfoque de aumentación de datos con un AG destinado a la selección de características. En un escenario sin aumentación, el desempeño de los AG puede verse restringido por la falta de datos suficientes para evaluar la calidad de cada subconjunto de variables, agravando el riesgo de convergencia prematura o sobreajuste a muestras escasas. Sin embargo, los experimentos realizados demuestran que la estrategia de aumentar los datos con muestras sintéticas generadas mediante AV/AVC aporta beneficios tanto en el rendimiento final como en la estabilidad de la búsqueda cuando el problema es realmente desafiante.  

En efecto, en escenarios con métricas cercanas a saturación (Leukemia y Gisette), donde los modelos sin aumentación ya logran una alta precisión, la generación de datos sintéticos no produjo mejoras estadísticamente significativas en la exactitud. Sin embargo, sí mostró una ventaja en la estabilidad (disminución de la varianza de los resultados) y en la eficiencia de la selección, traducida en subconjuntos de características levemente más compactos.

Sin embargo, en escenarios particularmente complejos o ruidosos (Madelon, GCM y All-Leukemia) el uso de datos aumentados generó mejoras sustanciales. En *Madelon*, la precisión aumentó más de un 10%, atribuido a la capacidad de los AV para generar ejemplos sintéticos que contribuye a resaltar las pocas características realmente útiles y compensan la gran proporción de ruido. En *GCM*, caracterizado por el desbalance de múltiples clases y la alta dimensionalidad, la estrategia de aplicar AV sobre subespacios de características previamente seleccionados por un AG propició un salto del 9% en la exactitud promedio. Este flujo de trabajo —encadenando selección, generación y nueva selección— resultó clave para gestionar la complejidad y mejorar la representatividad de las muestras sintéticas.  La confirmación de esta aproximación vino dada por el dataset *All-Leukemia*, donde se observó nuevamente que la combinación de AV y AG incrementa la precisión de manera consistente cuando el número de variables se reduce agresivamente, y el problema está lejos de estar “resuelto” por un modelo simple.

Se identificó un umbral más allá del cual continuar generando muestras puede llevar a un sobreajuste del modelo, por ende, perjudicar la clasificación. Así, no se trata solo de una relación lineal donde "más datos" se traduce siempre como "mejores resultados". La pertinencia de la cantidad y diversidad de los ejemplos debe calibrarse cuidadosamente según la complejidad del problema y la calidad de la reconstrucción lograda por el AV.

Por otro lado, a través de la exploración de hiperparámetros, comprobamos que arquitecturas sencillas (por ejemplo, redes de tres capas) o espacios latentes de dimensión moderada pueden ser tan efectivas como configuraciones más complejas o espacios latentes más extensos. En algunos casos, una dimensionalidad excesiva aumenta la redundancia y el ruido, reduciendo la capacidad de generalización de los modelos.

En lo que respecta a consideraciones metodológicas, la experiencias en *GCM* y *All-Leukemia* ilustran que el orden en el flujo de trabajo (primero seleccionar un subconjunto de características y luego generar datos sintéticos) puede marcar diferencias importantes en el rendimiento final. Esto sugiere que la sinergia entre selección de características y AV es un campo fértil para investigar configuraciones híbridas y ciclos iterativos adicionales (p.ej., retroalimentar el AV con características cada vez más relevantes).  
   
En conjunto, los resultados presentados confirman la validez de la propuesta: **la combinación de Autocodificadores Variacionales y Algoritmos Genéticos puede asistir y mejorar la selección de características, sobre todo en escenarios con alta complejidad, número limitado de muestras y distribuciones desequilibradas**. Esto hallazgo cierra nuestra propuesta de investigación mostrando que la generación sintética de datos no solo añade ejemplos a la base de entrenamiento, sino que, al interactuar con el proceso iterativo de un AG, amplía el espacio de exploración efectivo y mejora la confiabilidad en la evaluación de los subconjuntos de variables. De esta forma, la tesis aporta una estrategia integral que une la generación sintética y la selección de características para escenarios de aprendizaje automático complejo.  

Los resultados también sugieren que existe un espacio amplio para la creatividad y mejora mediante la optimización de los modelos AV y AVC, la optimización de la integración AV-AG, y la exploración de arquitecturas más avanzadas basadas en encadenamientos y ensambles de modelos. Considerando la complejidad de los dataset reales, quizás los próximos pasos deberían priorizar la construcción de soluciones más robustas y adaptativas, capaces de abordar la complejidad de los problemas con la menor cantidad de presupuestos posibles.  

## Trabajos futuros

### Optimización de modelos AV y AVC

Entendemos que uno de los primeros pasos para mejorar la calidad de los datos sintéticos generados pasa por optimizar los modelos AV y AVC. Aunque las versiones creadas en el marco de la presente investigación han mostrado ser efectivas en los contextos de experimentación planteados, como en *Madelon* y en *GCM*, es necesario optimizar su capacidad para capturar mejor las estructuras subyacentes de los datos reales. Para lograr esto, se proponen dos líneas de trabajo:

#### Mejora en la función de pérdida

La función de pérdida del AV/AVC desempeña un papel fundamental en la calidad de las muestras generadas. Como vimos en los experimentos de GCM, la divergencia KL puede dominar el proceso de regularización del espacio latente, lo que lleva a una reconstrucción insuficiente de los datos originales. Para mitigar este problema, propondríamos -tal cual lo adelantado en el Capítulo 4- una modificación de la función de pérdida, donde se ajusten los pesos entre la pérdida de reconstrucción y la divergencia KL, dando mayor importancia a la precisión en la reconstrucción. Adicionalmente, se pueden explorar técnicas como la Inferencia Variacional Recocida (*Annealed Variational Inference*, @huangImprovingExplorabilityVariational2018 ), que ajusta gradualmente el peso de la divergencia KL durante el entrenamiento, permitiendo una transición más suave y efectiva en la regularización del espacio latente.

#### Uso de AV jerárquicos

Otra línea de trabajo posible es la utilización de Autocodificadores Variacionales Jerárquicos (@vahdatNVAEDeepHierarchical2020). Estos modelos permiten la representación de características en múltiples niveles de abstracción, lo que podría ser particularmente útil para capturar relaciones complejas en conjuntos de datos como *GCM*. Al incorporar un nivel adicional de complejidad, los HVAEs podrían generar datos sintéticos que no solo preserven mejor la estructura de los datos originales, sino que también mejoren la capacidad del AG para identificar características relevantes en escenarios de alta dimensionalidad.

### Integración AV-AG optimizada

Aunque los resultados iniciales con la integración AV-AG son alentadores, es posible explorar maneras más eficientes de combinar ambos modelos. El flujo de trabajo encadenado que involucra *selección-generación-selección* mostró ser efectivo en los experimentos con *GCM*, pero podría beneficiarse sustancialmente con ciertos ajustes adicionales en su implementación.

#### Selección dinámica de características

Así, una opción es, en lugar de aplicar el AG sobre la totalidad de las características de manera uniforme, podríamos implementar un proceso dinámico de selección de características en múltiples etapas. En este enfoque, el AG se aplicaría inicialmente sobre subconjuntos reducidos de características, optimizando en función de la estabilidad y relevancia de los atributos seleccionados. Finalmente, se combinarían los subconjuntos con mejor desempeño, para formar un dataset de baja dimensiones y alto contenido informativo. Posteriormente, los AV generarían datos sintéticos sólo tomando como inputs este último dataset, reduciendo aún más el ruido y permitiendo una exploración más eficiente del espacio de búsqueda. Todo esto, alineado con la técnica implementada en este trabajo, pero radicalizada en su intención y objetivo.

#### Optimización conjunta de AV y AG

En los experimentos actuales, el AV y el AG se entrenan de manera secuencial y separada, lo que puede limitar la sinergia entre ambos modelos. Un enfoque alternativo sería la optimización conjunta, donde los parámetros de ambos modelos se ajusten simultáneamente durante el entrenamiento. De esta forma, el AV/AVC podría generar muestras sintéticas que maximicen directamente la eficacia del AG en la selección de características, permitiendo una retroalimentación continua entre ambos procesos y una mejora en la calidad del conjunto de datos aumentado.

Reconocemos que, según la experiencia ganada en esta investigación, ajustar los parámetros del AVC y AG, aún de forma independiente, no es un proceso trivial. Particularmente la cantidad de muestras sintéticas en la etapa generativa y el tamaño del cromosoma activo en la etapa de selección resultan parámetros de un impacto crítico en los resultados de la arquitectura. 

Pero advertimos también que, en el diseño donde el AV genera muestras sintéticas que luego son utilizadas por el AG para la selección, los modelos no comparten información durante sus respectivas fases de entrenamiento. La optimización conjunta permitiría entrenar ambos modelos de forma simultánea, posibilitando una retroalimentación directa y continua entre los procesos de generación de datos sintéticos (por el AV) y la selección de características (por el AG). Es decir, se ajustaría el proceso de generación de datos en función de la capacidad del AG para seleccionar características relevantes, logrando que el AV genere datos específicamente diseñados para maximizar el rendimiento del AG.

Aunque esta propuesta entaña desafíos inocultables (diseño de una función de pérdida, coordinación entre los procesos de optimización, capacidad computacional, por mencionar algunas), también ofrecería beneficios de gran valor. En particular, podríamos disponer de una mayor sinergia entre generación y selección. Esto se produciría a través de una retroalimentación directa entre los modelos, haciendo que el AV se adapte mejor a las necesidades del AG, generando datos que aborden mejor los desafíos específicos de selección de características en cada problema. Al entrenar el AV para generar datos que optimicen el desempeño del AG, el proceso de búsqueda de características relevantes podría volverse más eficiente. El AG podría explorar de manera más efectiva el espacio de características, identificando subconjuntos más precisos y reduciendo la dimensionalidad sin perder información relevante.

### Exploración de encadenamientos y stacks de modelos

Los resultados obtenidos sugieren que una única iteración del proceso AV-AG puede no ser suficiente para capturar completamente las relaciones entre características en problemas altamente complejos. En este contexto, la construcción de arquitecturas más complejas mediante el encadenamiento de varios modelos (stacks) o la integración de ensambles, similar a los Bosques Aleatorios, se presenta como una vía interesante de investigación.

Una posibilidad es el diseño de un *stack* de AV y AG, donde varias instancias de ambos modelos se encadenen de manera secuencial o paralela. En este esquema, por ejemplo, una primer secuencia AG-AV generaría un conjunto de datos sintéticos, que luego alimentaría a una segunda secuencia de AG-AG con configuraciones más específicas. Este proceso de encadenamiento podría permitir una mayor concentración de la generación y selección, especialmente en conjuntos de datos donde las relaciones entre las características son extremadamente complejas.

Al igual que los Bosques Aleatorios combinan múltiples árboles de decisión para mejorar la precisión y la robustez del modelo, se puede explorar la creación de un ensamble de AV y AG. Este enfoque involucraría el entrenamiento de múltiples AV y AG con diferentes configuraciones y subconjuntos de datos, cuyas salidas se combinarían para producir una solución más robusta. Los ensambles suelen ser efectivos para reducir la varianza de los modelos individuales, lo que podría resultar en una selección de características más estable y en un rendimiento más consistente.

### Exploración de arquitecturas híbridas y meta-aprendizaje

Por último, se abre la posibilidad de explorar arquitecturas híbridas que combinen AV y AG con otros enfoques de aprendizaje automático, como los algoritmos de meta-aprendizaje. Estos modelos podrían ser entrenados para aprender a seleccionar automáticamente los mejores hiperparámetros y configuraciones para cada conjunto de datos, adaptándose dinámicamente a las características específicas del problema.

En lugar de fijar los parámetros del AG a priori, el meta-aprendizaje permitiría que el AG aprenda automáticamente cuáles son los mejores parámetros en función de la estructura de los datos. Este enfoque podría incluir la selección adaptativa del tamaño del cromosoma activo, las tasas de mutación y cruce, y el número de generaciones, optimizando el rendimiento del AG en cada iteración.

